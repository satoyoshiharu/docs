<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="This site is to promote the thought that uses the daily behavior of people across the human-machine interactions.">
    <meta name="author" content="Yoshiharu Sato">
	<title>ヒトと機械のコミュニケーション</title>
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Josefin+Slab:100,300,400,600,700,100italic,300italic,400italic,600italic,700italic" rel="stylesheet" type="text/css">

<style>
p { line-height: 1.5;  }
li { line-height: 1.7;  }
table { margin: auto; }
.pagebreak { break-before: page; }
.printfriendlyblock { page-break-inside: avoid; }
</style>
	
</head>

<body>
<h1>ヒトと機械のコミュニケーション</h1>
<hr>

<details open><summary>目次</summary>
	<!--https://shu-sait.com/mokuji-jidou-seisei/-->
	<div id="toc" class="l-toc"></div>
</details>

<div class="toc-contents"> <!--Start of TOC areas-->

<div class="pagebreak"><hr><h2>1. はじめに</h2>

	<details open><summary><strong>本文書の想定読者</strong></summary>
		<p>
			本文書は、以下の方々を読者として想定し、一般向けではない。
			<ul>
				<li>これからITを志す若者</li>
				<li>IT技術分野で現在活躍しているプロフェッショナル</li>
				<li>ITに関するインフルエンサー</li>
			</ul>
			ただ、本文書の扱うトピックおよび主張は、IT技術に関心のある人すべてが興味を持たれると思う。
		</p>
	</details>

	<details open><summary><strong>道具がヒトの能力と調和したとき、ヒトの能力を拡大する</strong></summary>
		<p>
			ヒトは、その能力によって道具を発明し、自分ができることを拡大してきた。
			例えば、ヒトは、文字と紙という道具を発明した。
			それによって、ヒトは、記憶したり伝達したりする能力を、拡張した。
			また、ヒトは、紙という平面の物体に、ペンを操り、3Dの物体の見取り図を表現する。
			これは生身の目では見通せない俯瞰的な視覚である。
			最近では、顕微鏡や望遠鏡が、見えるものを広げた。
			車が、ヒトの移動距離を変えた。
			インターネットが、コミュニケーションする集団の規模を変えた。
			これらすべてヒト能力の拡張である。
		</p>
		<p>
			紙に文字や図を書くとき、ヒトは、器用な手指を操作する。
			高性能な目で指の軌跡を確認する。
			手指の内部的な感覚とともに動きに修正をかける。
			そういったことを、瞬時に連続的に繰り返し行っている。
			ヒトは、その高度な目の機能と手指の器用さによって、道具を使いこなしている。
			このように、道具が人の能力と調和したとき、道具は有効なものとなる。
			そして、有効な道具は、ヒトの能力を拡大する。
			さらに、拡大されたヒトの能力によって、道具は一層高度になる。
			道具とヒト能力の相乗効果は、石器時代の昔か、ヒト社会を変えてきた。
		</p>
	</details>

	<details open><summary><strong>コンピュータという道具は、ヒトの能力と調和していない</strong></summary>
		<p>
			しかし、現在のヒトとコンピュータの間の関係はどうか。
			<ul>
				<li>
					例えば、ヒトは、ハサミを難なく使える。
					それに対して、コンピュータは、マニュアルを読まないと使えない。
					マニュアルに書いてある、人工的な抽象物の建築中の歩き方を習熟してからでないと、何をどうするか見当もつかない。
					つまり、コンピュータがもたらす概念体系は、ヒトの頭に素直に自然と入ってくるもので、ない。
				</li>
				<li>
					例えば、ヒトは、意識せずに歩くことができる。
					また、自転車に乗ったり、自動車のハンドルを操作するのに、少し訓練すれば、あとはほとんど無意識的に筋肉が動いてくれる。
					一方、コンピュータは、少し慣れたあとでも、操作する際、これをやれば何が起きるかと、常に知的な緊張を強いられる。
					つまり、ヒトが難なく自然と覚える運動パターンとして、吸収できるもので、ない。
				</li>
				<li>
					例えば、子供から成長するにつれて、ほとんどのヒトは社会的教育によって、言葉をしゃべり、文字を書くことができるようになる。
					一方、コンピュータは、情報を流通するツールとしても、誰でも使えるものでない。
					つまり、人が社会の教育的環境の中で身に着けられる、ヒト文化の一部では、ない。
				</li>
			</ul>
			以上のことから、現状のコンピュータの技術は、ヒトの日常的な能力と調和していない、といえるのではないか。
		</p>
	</details>

	<details open><summary><strong>コンピュータの違和感</strong></summary>
		<p>
			コンピュータは、ものであり、道具である。
			しかし、ハサミのような単機能の道具と比べると、はるかに抽象的な事柄を扱う。
			コンピュータの処理対象は情報であり、コンピュータの機能は計算や情報の加工である。
			どちらもヒトの抽象物である点が、日常で見る道具とは、異なる。
		</p>
		<p>
			しかも、コンピュータは、ほかの抽象物とは異なる点がある。
			例えば、建築物の構造、都市の道路や建物の配列など、また経済活動の貨幣は、人の抽象物であり。
			しかしこれらは、ヒトの生活や身体と密接に関連している。
			一方、コンピュータの扱う抽象物は、ヒトの身体と物理的な交渉がない。
			純粋に抽象的な、神話や数学などに近い。
			頭の中だけにあって、人の身体や生活と関わらない。
		</p>
		<p>
			コンピュータは、人の頭が生み出した道具である。
			しかし、すでにいろいろなモノの中に組み込まれ浸透している。
			移動したり暇なときにはほとんど持っているスマホ、自動車、電子レンジ・洗濯機などの家電、などである。
			通信を介してコントロールされているものを含めたら、いろいろな社会インフラを支える装置もそうである。
			ヒトの能力と調和していない、純粋抽象物が、これほど、どこにでもある存在になってしまっている。
			歪んでいる。
		</p>
		<p>
			ところで、コンピュータは、もともとエリートの知能の拡張のための道具であった。
			それが、スマホの時代になって、だれでも使う道具になってしまった。
			コンピュータユーザーのペルソナが根本的に変質した。
			コンピュータにある抽象物は、今のペルソナに合っていない。
			それが違和感の原因である。
		</p>
	</details>
	
	<details open><summary><strong>操作とコミュニケーション</strong></summary>
		<p>
			ところで、ヒトはモノ道具を操作し、ヒトとコミュニケーションする。
			今、操作とコミュニケーションという、異なる二つの関係性に注目してみる。
			それぞれ操作モデル、コミュニケーションモデルと呼ぶことにする。
		</p>
		<p>
			コンピュータは、モノ道具の一つとして生まれた。
			ヒトが操作するものである限り、ヒトの指示に従うだけの存在である。
			ハサミなどは、ヒトが指示するときは、ヒトが生得的な能力でコントロールできた。
			しかし、コンピュータは複雑な抽象から構成されているため、ヒトの生得的な能力とギャップがある。
			そのギャップのため、ヒトが誰でも操作できるものでなくなった。
			このギャップの部分は、従来ユーザーインターフェイスと言われてきた。
			違和感はそこにある。
		</p>
			一方、ヒト相手のコミュニケーションではどうか。
		</p>
			ヒト相手に話をするときは、詳細な指示を出す関係ではなく、意図を伝え、依頼し、反応をみて、さらに対話する。
			ヒトの意図レベルで、やり取りをする。
			そこに、コンピュータ相手のコマンドをくみ上げるような抽象的で難解なプロセスはない。
			ヒトが頭で文章を考え、しゃべる、という生得的な能力ですむ。
			自然で誰でもできる行為ですむ。
		</p>
		<p>
			そして、意図を伝えるために、互いの視線を意識したり、指さしや表情を見合ったりする。
			見て聞く。
			指さしも、表情も、生得的な行為である。
			ヒトは、生得的な能力で、身体を使って、コミュニケーションする。
		</p>
		<p>
			ヒトとコンピュータは、モノ道具を操作するという関係性のままだった。
			そのために、ユーザー・インターフェイスにギャップがあることを、看過してきた。
			ギャップをなくすには、コミュニケーションモデルでインターフェイスを設計したほうがよい。
			意図レベルで、ヒトの身体ごとのやりとりにする。
			身体性を取り戻す。
			ヒトがコンピュータに合わせるのでなく、コンピュータがヒトに合わせる。
			そのとき、コンピュータはヒトと調和する。
		</p>
	</details>

	<details open><summary><strong>必要なこと</strong></summary>
		<p>
			ヒト同士のコミュニケーションを、ユーザー・インターフェイスの理想とする考えは昔からあった。
			人工知能の中の対話ボットなどである。
			すると、もっとハイテクを駆使しないと、コミュニケーションのモデルにできないのか？
			そうではない。
			コンピュータを作る人、アプリを作る人が、すでにある技術をちょっと視点を変えてデザインをすればよい。
			少なくとも、技術はあって、くみ上げ方を変えればよい。
		</p>
		<p>
			現在のコンピュータ・ユーザー・インターフェイスの歪みを意識し、克服しようとした考えは昔からあった。
			例えば、石井裕のタンジブルビッツである(<a href="#rIY">[rIY]</a>)。
			豊かなサイバー空間の世界を、モニターとマウス越しでしかインターフェイスしないことに異を唱え、
			環境自体をインターフェイスにしようとした。
			形のない情報というものを、より実態のあるもので表現しようとした。
			環境という物理的な実体で、サイバー空間の情報を表現しようとした。
			すると、環境を進化させないと、現在のコンピュータ・ユーザー・インターフェイスの歪みは解決しないのか？
			いや。
			サイバーの一部であるコンピュータが、豊かな人体能力を尊重するように変わればよい。
			環境ごと変わる必要はない。
			コンピュータが変われば済む。
			豊かなサイバー空間をいとおしがるよりも、豊かなヒト能力をいとおしがる。
			環境をユーザー・インターフェイスにするというより、ヒトのユーザー・インターフェイスにする。
		</p>
		<p>
			また、坂村健やマーク・ワイザーによるユビキュタス・コンピューティングという考えもあった。
			Internet Of Things という考えにもつながる考えである。
			コンピュータがいずれ、いろんな所に埋め込まれて、それらが協調動作する。
			ハイテク家電委はすでに小さなコンピュータが組み込まれている。
			それらよりも格段に多く、様々な物に、コンピュータを埋め込む。
			そうすることで、ヒトはコンピュータを意識しなくても、いろんなことができる社会が実現すると。
			ユーザー・インターフェイスは消えるべきであるという考えもある。
			すると、コンピュータがいろんなものに埋め込まれるまで待たなければならないのか？
			そうではない。	
			コンピュータに作りこむアプリのデザインの発想を変えればいい。
			または画面付きスマートスピーカーとか、対話ロボットとか、今、出てきているコンピュータの形態のままで、
			アプリ機能をくみ上げればよい。		
		</p>
	</details>

	<details open><summary><strong>本文書の構成</strong></summary>
		<p>
			本文書の前半では、ヒトの身体機能を概観し、それと接する機械がどうあるべきかの参考にする。
			後半では、ヒトの身体に向き合い、意図レベルで、やり取りするようなコンピュータの具体的なイメージを説く。
			それは、ハイテクである必要はないことを説明する。
		</p>
	</details>

</div>

<div class="pagebreak"><hr><h2>2. ヒト生体の情報処理</h2>

	<div><h3>2.1 概観</h3>

		<details open><summary><strong>ヒトの生体機能を見ていく理由</strong></summary>
			<p>
				コンピュータは、従来のヒトと道具操作のモデルでは、問題が解決しない。
				ヒトとコミュニケーションするときのことをモデルにして、ユーザインターフェイスを構成したほうが良い。
				ヒトのカラダの能力を、そのまま受け止め、それに反応してほしい。
				ここでは、まず、ヒトが生物として世界に対処するときの、生体情報処理の特徴を見ていく。
			</p>
		</details>

		<details open><summary><strong>ヒトは8つの感覚器と2つの作用効果器で情報処理している</strong></summary>
			<p>
					ポール・ナースによれば（<a href="#rPN">[rPN]</a>）、「あらゆる生命には、自分と子孫を永続させるという目的がある。
					あらゆる生命の中心には、情報がある。
					目的のための行動に、情報は利用される。」
				</p>
				<p>
					生体は、外の世界と自分の体の内側の世界との両方に関して、情報を絶えず集めて利用している。
					内外の環境の状況を把握するものを<a href="#receptor"><strong>受容器官</strong></a>という。
					それらに応じて外部に働きかけるものを<a href="#effector"><strong>効果器官</strong></a>という。
					受容器官と効果器官とを連結し統括するものは、<a href="#brain"><strong>脳・神経系</strong></a>である。
			</p>
			<p>
				受容器官は、特殊感覚と体制感覚がある。
				<strong>特殊感覚</strong>は、特定の刺激に対して、特定の場所にある器官が反応する。
				<strong>体性感覚</strong>は、身体に分散して存在し環境への反応を助ける。
				一般的に五感と言われるものは、平衡感覚と固有感覚を除外した、視覚、味覚、嗅覚、聴覚、触覚である。
				一方、ヒトの効果器官には、機械系と音響系がある。
			</p>
			<p>
				<ul>
				<li>受容器官</li>
					<ul>
					<li>特殊感覚器官</li>
						<ul>
						<li>視覚器</li>
						<li>味覚器</li>
						<li>嗅覚器</li>
						<li>平衡・聴覚器（組織的に同居）</li>
						</ul>
					<li>体性感覚器官</li>
						<ul>
						<li>外部から受容する皮膚感覚</li>
						<li>筋、腱、関節内で感知する固有感覚</li>
						</ul>
					</ul>
				<li>効果器官</li>	
					<ul>
					<li>筋肉や骨格からなる手指や身体の機械的運動系</li>
					<li>発声器官</li>
					</ul>
				</ul>
			</p>
		</details>

		<details open><summary><strong>情報媒体は、光、振動、科学的・物理的刺激である</strong></summary>
			<p>
				視覚は、光という電磁波を感知する。
				聴覚は、ヒトを含む陸生動物の場合、空気振動を感知する。
				触覚（皮膚感覚）は物理的刺激を感知する。
				そして味覚と嗅覚は化学的物質を感知する。
				運動系は物理的な効果を持つ。
				音声発生は、空気振動を起こす。
			</p>
			<div class="printfriendlyblock">
				<p>
				<table border="1">
				<tr><td>受容器官</td><td>特殊感覚</td><td>視覚</td><td>光</td></tr>
				<tr><td></td><td></td><td>味覚</td><td>化学的物質</td></tr>
				<tr><td></td><td></td><td>嗅覚</td><td>化学的物質</td></tr>
				<tr><td></td><td></td><td>平衡・聴覚</td><td>重力、空気振動</td></tr>
				<tr><td></td><td>体性感覚</td><td>皮膚感覚</td><td>物理的</td></tr>
				<tr><td></td><td></td><td>筋、腱、関節内固有感覚</td><td>物理的</td></tr>
				<tr><td>効果器官</td><td></td><td>機械的運動系</td><td>物理的</td></tr>
				<tr><td></td><td></td><td>発声</td><td>空気振動</td></tr>
				</table>
				</p>
			</div>
		</details>

		<details open><summary><strong>近接感覚と遠隔感覚がある</strong></summary>
			<p>
				感覚には、遠くからのことを感知するものと、近いもことを感知するものと、どこでも偏在することを感知するものがある。
			</p>
			<p>
				どんな生物も、例外なく、遠近に関係なく偏在する、重力を感じる。
				動物は自分の体の傾きを、平衡器官で感知している
				（<a href="#rIN">[rIN]</a>）。
			</p>
			<p>
				味覚、接触感覚は、近くのもののの感覚である。
				動物の進化の中で、これらの近接感覚がまずあったと思われる。
				味覚は、化学物質を感知する。
				接触感覚は物理的な圧力を感知する。
				これらが、まずは、食べ物を識別し、仲間と生殖・交信するためにあったと思われる。
				また、運動するために、体の状態を感知する体性感覚も必須だったろう。
			</p>
			<p>
				一方、生物が行動範囲を広げる際に、より広い環境を感知し、よりうまく生存・生殖したい。
				嗅覚は、遠くからの化学物質を感知する。
				聴覚は、遠くからの水・空気振動を感知する。
				視覚は、遠くからの光電磁波刺激を感知する。
			</p>

			<div class="printfriendlyblock">
			<p>
				<table border="1">
				<tr><td>受容器官</td><td>特殊感覚</td><td>視覚</td><td>遠隔</td></tr>
				<tr><td></td><td></td><td>味覚</td><td>近接</td></tr>
				<tr><td></td><td></td><td>嗅覚</td><td>遠隔</td></tr>
				<tr><td></td><td></td><td>平衡、聴覚（器官的に同居している）</td><td>平衡感覚は偏在、聴覚は遠隔</td></tr>
				<tr><td></td><td>体性感覚</td><td>皮膚感覚</td><td>近接</td></tr>
				<tr><td></td><td></td><td>筋、腱、関節内固有感覚</td><td>近接</td></tr>
				<tr><td>効果器官</td><td></td><td>機械的運動系</td><td>近接</td></tr>
				<tr><td></td><td></td><td>発声</td><td>遠隔</td></tr>
				</table>
				</p>
			</div>
		</details>

		<details open id=通信容量><summary><strong>それぞれの器官の通信容量</strong></summary>
			<p>
				人間の全受容器から、感覚神経を経由して中枢神経系へ伝送される情報量は、10の9乗ビット/秒と言われる。
				うち、視覚は、10の6から8乗ビット/秒、聴覚は10の4から6乗/秒、触覚は10の6乗/秒と言われる。
				一方、中枢神経系から、運動神経を経由して効果器へ伝送される情報量は、10の7乗ビット/秒と言われる
				（<a href="#rSO">[rSO]</a>、<a href="#rFT">[rFT]</a>、<a href="#n01">[脚注01]</a>）。
				また、視覚は人間の情報獲得の80%ともいわれる（<a href="#n02">[脚注02]</a>）。
			</p>

			<div class="printfriendlyblock">
				<p>
				<table border="1">
				<tr><td>受容器官</td><td></td><td></td><td>1000000000 bit/sec</td></tr>
				<tr><td></td><td>特殊感覚</td><td>視覚</td><td>100000000 bit/sec</td></tr>
				<tr><td></td><td></td><td>味覚</td><td>10000 bit/sec</td></tr>
				<tr><td></td><td></td><td>嗅覚</td><td>100000 bit/sec</td></tr>
				<tr><td></td><td></td><td>聴覚</td><td>100000 bit/sec</td></tr>
				<tr><td></td><td>体性感覚</td><td>皮膚感覚</td><td>1000000 bit/sec</td></tr>
				<tr><td></td><td></td><td>筋、腱、関節内固有感覚</td><td></td></tr>
				<tr><td>効果器官</td><td></td><td></td><td>10000000 bit/sec</td></tr>
				<tr><td></td><td></td><td>機械的運動系</td><td></td></tr>
				<tr><td></td><td></td><td>発声</td><td></td></tr>
				</table>
				</p>
			</div>
			<p>
				ヒトは環境を認識するのに、主に視覚を使っている。
				また、環境に対する反応の情報量は、感覚よりも桁違いに小さい。
				ヒトという生物は、環境から多くの情報を仕入れて、生存・繁殖に有効なものを選んで反応し、環境に働きかけている。
			</p>
		</details>

		<details open><summary><strong>感覚、知覚、認知の違い</strong></summary>
			<p>
				受容器官に刺激が与えら脳に伝えられたもの感覚という。
				熱いとか、音が聞こえるとかである。
			</p>
			<p>
				感覚に、対象の構造や特徴が加えられて、意識されたものが知覚である。
				長いとか、強いとか。
				感覚はその一部が知覚となる。
				意識に上らないことは多い。
				無意識の過程により、あるものは無意識的な反応として行動に現れ、あるものはエネルギーを節約するために意識を向けられずにフィルターされる。
			</p>
			<p>
				さらに、知覚が過去の経験や学習に基づいて解釈されたものが認知である。
				犬であるとか、母であるとか
				認知になると、文化や社会の影響が濃厚に出る。
				社会の文化によって、虫の鳴き声を、雑音と感じるか、秋の風情と感じるか、が異なってくる。	
			</p>
			<p>
					感覚、知覚、認知は、ヒトが環境から情報を仕入れる、階層的な分類である。
					反応に関しての分類は、どうか？ 不随的・随意的、無意識的・意図的などの分類がある。
			</p>

		</details>

	</div>

	<div id=receptor class="pagebreak"><hr><h3>2.2 受容器官</h3>

		<div><h4>2.2.1 視覚</h4>

			<details open><summary><strong>人は視覚的動物である</strong></summary>

				<p>
					ここでは、ヒトの視覚が、優れた能力を持つことを示す。
					コンピュータ・ユーザー・インターフェイスでは、視覚を重宝する。
				</p>
				<p>
					人の得る情報の80%は視覚からと言われ、ヒトは視覚的動物である。
				</p>
				<p>
					光という情報媒体は、遠くまで届く、高速に伝わる、という特徴を持つ。
					生物が光を感知できるとしたら、瞬時に、遠方まで、敵ないし見方、餌を識別でき、生存に有利である。
					光は高速なので、どこに物があっても瞬時に把握できるという意味で、ほかの感覚と比べ、距離に左右されない。
				</p>
				<p>
					生物史から振り返る。
					地球史の中に、カンブリア紀という、その時代からいきなり化石が出始めた時代がある。
					英人生物学者のアンドリュー・パーカー（Andrew Parker、1967～）は、2003年、「光スイッチ説」を唱えた。
					カンブリア紀に登場した三葉虫は、目を進化させた結果、食べ、食べられる関係で優位に立った。
					それが、淘汰圧として、ほかの生物の多様な進化を促した、と主張した（<a href="#rMK">[rMK]</a>）。
					それまでは、化石になるような骨や外殻がない生物しか存在していなかったが、
					視覚の登場が生存競争・選択淘汰を激烈にし、
					骨や外殻を備えた多様な生物がこのときに生まれたという。
				</p>
				<p>
					その後、生物の長い歴史の中、器官の発達とともに、視覚は機能的に進化してきた。
					まず、原始的な生物は、明暗識別ができた。
					ついで、明暗の方向視、形態視、動きの感知、色認識、そして、両眼視による遠近を含む探索・位置同定、ができるようになった。
				</p>

				<p>
					一方で、光は他のものによって遮られるという欠点がある。また、夜には光がなくなる。
					そのため、光あふれた昼間、地表での生存競争を避けた生物は、別の感覚を伸ばす必要があった。
					化学物質である臭いは、風に左右されるが、昼夜を問わず、どんな隙間にも入り込む。 
					中生代の恐竜の全盛期には、ヒトの先祖である哺乳類は、夜に活動し、光のないところで嗅覚を発達させて、生き延びた。
					陸上動物だけでなく、海生動物を含めても、視覚器が退化した動物は多いが、聴覚器を持たない動物は少ないという。
					それ以降、動物は、ヒトのような視覚型と、イヌのような嗅覚型に大別される（<a href="#rIN">[rIN]</a>）。
				</p>
				<p>
					やがて、恐竜がいなくなり、類人猿が森から草原に降りてきた。
					そのころ、ヒトの先祖である狭鼻猿類は、それまでの赤・青の2色視でなく、
					赤・青・緑の三色視ができるように進化し、弁別できる色情報を格段に増やし優位に立った
					（<a href="#rMK">[rMK]</a>）。
				</p>
			</details>

			<details open><summary><strong>ヒトの視覚の高性能の仕組み</strong></summary>
				<p>
					光刺激を瞬時に処理するため、ヒトの視覚は、情報圧縮と並列処理を活用している。
				</p>
				<p>まず情報圧縮である。</p>
				<ul>
					<li>
						脊椎動物の視細胞には、錐体(cone)と粁体(rod)という2種類がある。
						粁体(rod)は明暗に反応し、錐体は異なる波長の光(色)に反応する。
						ヒトでは、網膜に中心窩(fovea)と呼ばれる錐体だけが密集した部位があり、この部分での視覚が視野の中心部となる。
						人間には錐体が約600万個、 粁体が約1億2000万個存在する。
						一方、視細胞の情報を受け取る視神経は約100万個である。
						従って網膜は光刺激の情報を1/100ほどに圧縮して脳に送っていることになる（<a href="#rST">[rST]</a>）。
					</li>
					<li>
						視覚は、光刺激を電気信号へ変換して処理する。刺激が同じならば、神経内で電気信号が発火されない。
						つまり、同じ映像であるかぎり、刺激としての画像情報は消える。
						そこで、眼球を不随意に微動させて、注視したときの網膜像を絶えずリフレッシュしている。
						そして、網膜像の時間的差分だけを脳へ送るというデータ圧縮を行っている（<a href="#rSO">[rSO]</a>）。
					</li>
				</ul>
				<p>ヒトは瞬時に目から多くの情報を把握できるが、いくつかの並列処理を行っている。</p>
				<ul>
					<li>
						視細胞のレベルでは、錐体は色や空間的情報処理、杆体は明暗情報処理･時間的情報処理を分担している。
						また、注目しているところの注目視と、別に周辺視が、独立に機能している。
						歩きながらスマホを見ることができるのもそのせいである。
						明暗の変化や運動など時間的な変化を伴うものが、周辺視野で感知される。
						その後、注意すべきかどうかの判断のために、眼球運動で注目視し、知覚・認知が行われて、対処が判断される
						（<a href="#rFT">[rFT]</a>）。
						周辺視野には以下の特徴がある。
						<ul>
							<li>
								周辺視野は、素早く反応する。
								恐ろしい物体を中心視野で観察すると脳が反応するまでに140-190ミリ秒、周辺視野では80ミリ秒かかるという（<a href="rSW">[rSW]</a>）。
							</li>
							<li>
								周辺視野は、詳細認識ではなく、状況の概略を把握するのに使われる。
								台所の写真で、写真の周辺部を隠すとどこの写真かわからなくなるが、中央部を隠してもどこの写真が想像できる（<a href="rSW">[rSW]</a>）。
							</li>
						</ul>
					</li>
					<li>
						さらに、視覚情報は、3つルートで処理される。まずは大きく2つに分かれる。
						<ul>
							<li>
								一つは、脳へ情報が送られて眼球運動を制御するのに使われる。
							</li>
							<li>
								もう一つは、パターン認知に使うため脳（大脳皮質第1視覚野、視覚前野）へ送られる。
								後者は、網膜上の位置に依存した情報抽出を行ったあと、位置に依存しない空間・携帯情報を抽出する。
								まず、線分の方位、長さ、色、動き、両眼視差などの特徴に選択的に反応し、網膜上の位置に依存した要素情報を抽出する。
								そして、そこから更に二つのルートに分割され、信号が送られる。
								<ul>
									<li>空間知覚処理部（側頭連合野）</li>
									<li>形態知覚処理部（頭頂連合野）</li>
								</ul>
								そこでは、位置に依存しない、人の顔の認識などパターン処理が行われる。
							</ul>
						</ul>
					</li>
					<p>
						このように、視細胞から大脳にかけて、階層的な処理が並行して動く
						（<a href="#rSO">[rSO]</a>）。
					</p>
				</ul>

			</details>

			<details open><summary><strong>認知的な効率化</strong></summary>
				<p>
					視覚認知レベルでも、効率化の仕組みを持っている。
				</p>
				<p>
					以下にルビンの壺という絵がある。これは、図と地の分化という現象を示す。
					1つのまとまりのある形として認識される部分を「図」、図の周囲にある背景を「地」と呼ぶ。
					この絵は、両側をまとまりととらえるか、中央部をまとまりととらえるかで、全く異なる物体に見える。
					ヒトは、複数の解釈が可能な画像でも、必ずある特定の解釈をとる。
					そして、いったん解釈を決めた場合、その記憶の影響を受ける。
					<p>
						<div align="center">
							<img width=20% src="rubins_vase.png"> 
							<p>[https://ja.wikipedia.org/wiki/ルビンの壺 より]</p>
						</div>
					</p>
				</p>
				<p>
					以下にカニッツアの三角形という図がある。
					ヒトは、知覚した情報を処理する際、すでに記憶に持っている認知パターン分類で解釈する（<a href="rSW">[rSW]</a>）。
					素早く対象を理解するための効率化である。
				</p>
				<p>
					<div align="center">
						<img width=２0% src="Kanizsa_triangle.png"> 
						<p>[https://ja.wikipedia.org/wiki/カニッツァの三角形より]</p>
					</div>
				</p>
				<p>
					また、ヒトは、実世界の3D物体を、すでに記憶している基本的な立体（ジオン）パターンを組み合わせて識別しているという（<a href="rSW">[rSW]</a>）。
				</p>
				<p>
					また、視覚は、高度な知的処理と相互作用の結果得られる近くである。
					下の図は、同じ画像でも、コンテキストによって、Hだったり、Aだったりに見える。
					文脈効果と呼ばれる。
					<p>
						<div align="center">
							<img width=２0% src="context_effect.png"> 
							<p>[https://maruhi.heteml.net/chikakuninchi/?page_id=648 より]</p>
						</div>
					</p>
				</p>
			</details>

			<details open id=eyeball_movement><summary><strong>眼球の動き</strong></summary>
				<p>
					眼球は、直径24mmから25mmの球体である。
					眼窩の中で、脂肪に囲まれて、3対6種類の筋肉で支えられ、上下、左右、視軸回りの回転運動を行う（<a href="#rFT">[rFT]</a>）。
				</p>
				<p>
					<div align="center">
						<img width=80% src="eyeball_movement.jpg"> 
						<p>[https://plaza.umin.ac.jp/jikei-np/symptoms/01_01_13.htmlより]</p>
					</div>
				</p>
				<p>
					目の筋肉は、何種類かの運動をして、形態視、動体視、立体視、位置同定などの機能をはたしている
					（<a href="#rFT">[rFT]</a>、<a href="#rSO">[rSO]</a>）。
					<ul>
						<li>
							中心視をするために，左右の眼は連動して動く。
							2種類の連動運動がある。
							<ul>
								<li>
									一つは、移動する対象を追う運動で、両眼は同じ方向へ運動する（共同運動、conjugate）。
									これには滑らかな成分（最高25から30度/秒）と跳躍性の運動成分（ザッカード、300から600度/秒）がある。
									視覚は主に空間的情報を感知する。
									さらに、対象の動きという時間的な情報も感知する。
									雲は風に流される。遠くから見ればその動きは微々たるものである。
									しかし、ヒトの目は、雲が連続的に確実に動いていると感知する。
								</li>
								<li>
									もう一方の連動運動は、両眼が逆方向に運動する（幅そう運動、disjunctive, vergence）。
									これは、左右のわずかに異なった像を融合して一つの像として知覚し、
									立体視のデータを得るためにある。
									ヒトは、三次元の世界に住んでいるのである。				
								</li>
							</ul>
						</li>
						<li>
							一方、眼球は、固視微動といって、注目視野内の微小な不随意の動きを行い、静止した物体の網膜像が消えないようにしている。
						</li>	
					</ul>
				</p>
				<p>
					ヒトの睡眠には、レム睡眠という、夢を見て、目を激しく動かす時間帯があり、
					脳の中を整理しているらしい（<a href="#rYT">[rYT]</a>）。
					ヒトは、頭を整理するために、目を動かす。
					そのくらい、ヒトは視覚的動物だということだろうか。
				</p>
			</details>

			<details open id=fast_eye_sight><summary><strong>視線は速い</strong></summary>
				<p>
					ヒトが、随意的に中心視野を動かすのは、一瞬である。
					ヒトがあるものに注目するとき、それに対する手足の動作を起こす前に、目はすでにそれを見ている。
					手足の関節を動かすよりも、小さな局所的な筋肉の動きで眼球はすでに反応している。
					ヒトの効果器のどれよりも、眼のほうで早く位置情報を認知している。
					ほかの手段のおよそ倍、速いといわれる（<a href="#rKK">[rKK]</a>）。
				</p>
			</details>

			<details open id=three_d_space><summary><strong>2次元と3次元</strong></summary>
				<p>
					ヒトは、3次元の住民である。
					ヒトが観察する世界は、3次元の立体である。
					立体視の仕組みには、単眼での情報と両眼視によるものとがある。
				</p>
				<p>
					単眼視による手がかりとしては以下のものなどがある（<a href="#rCP">[rCP]</a>）。
					<ul>
						<li>
							物体の重なりから前後を見て取る。
						</li>
						<li>
							大きさから距離を感じる。
						</li>
						<li>
							平行線は遠ざかるほど幅が狭くなる。
						</li>
						<li>
							一定の模様は、遠いほどきめが細かくなる。
						</li>
						<li>
							遠くの景色ほど、ぼやけたりかすんで見える。
						</li>
					</ul>
				</p>
				<p>
					一方、両眼視によって、両眼網膜視差をもとに、脳内で3次元イメージを構築する。
					その3次元の世界は、自分の位置を変えれば、同じものでも、刻々と異なって見えてくる。
					異なった3次元の外見のものを同一の物体だとみなせるのは、ヒトの抽象化能力のためである。
				</p>
				<p>
					一方、ヒトは、3次元に現象する物体を、紙という道具の2次元空間に表現したりもする。
					3次元のものを相手にするより、2次元のものを相手にするほうが、認知エネルギーは小さい。
					それで、紙を持ち歩いたり、別のところで3次元を再現したりする。
					見た心象を、2次元空間に表現して、絵、漫画、浮世絵などとして、仲間に感情を伝えたりもする。
					そこでは、ヒトは、認知的に楽な情報を通して、実は高度な精神活動をしている。
				</p>
				<p>
					現在のコンピュータは、モニターやタッチ画面という2次元空間を利用する。
					ヒトは2次元を通して高度な精神活動を行うことができる。
					一方で、日常の生活空間は、3次元の豊かさを備えていることに、気を留めよう。
				</p>
			</details>

			<details open><summary><strong>文字の読み取り速度がすごい</strong></summary>

				<p>
					ヒトの視覚は、その神経の高速並列処理と機敏な眼球筋肉のおかげで、言語認知で高度なパフォーマンスを示す。
				</p>
				<p>
					注目視野は、20から30ビットを一度に把握できると言われる。
					これはアルファベットは5文字、ひらがなは4文字、漢字は2文字に相当する
					（<a href="#rFT">[rFT]</a>）。
					英語の場合、一度に、15文字を読み進むという。
					先頭の1から7文字で意味を取り、次の8-15文字は周辺視野でみている、あるいは予測しているという
					（<a href="#rSW">[rSW]</a>）。
					またヒトは、聞き取りであれば1分間に160語ほどを把握できるが、読み取りは1分間に300語ほど把握できる。
				</p>
				<p>
					一方、耳で聞き取るためには、音は時系列で並んでいるので、それらを逐次処理しないといけない。
					聞き取りが、読み取りよりも遅い主因である。
				</p>
			</details>

			<details open id=space_memory><summary><strong>空間的に記憶できる</strong></summary>
				<p>
					動物は、餌の場所や住処をめぐって行動する。
					そのために、周囲の空間と自身を関連付ける認知機能、つまり空間記憶がある（<a href="#rUT">[rUT]]</a>）。
					聞いたことを記憶するのと比べて、見えたものは繰り返し確認できる。それが記憶保持を助ける。
				</p>
				<p>
					色分けした表紙のファイルを見て、どのファイルがどの内容のファイルだったかわかる。
					ある事柄が、本の分厚い厚みの中でどのあたりのページのどのあたりに書いてあったか、覚えている。
					机の上に、いくつも書類が乱雑に積み重なって置かれているが、どこに何があるか思い出すことができる。
					ピアノである曲を暗譜で弾くことが出来る。
				<p>
					このような空間記憶は、連想記憶にも似ている。
					キーボード操作に慣れた人は、キーボードを見なくても操作できる。
					しかし、キーボードがないところで、キーボードのキー配列を思い出そうとするとできない。
					つまり、頭にそのまま記憶しているのではないのである。
					しかし、キーボードを見ると、指が覚えていたかのように、すぐに上手にタイプできる。
					ここには視覚的な連想記憶が働いている。
					記憶は神経細胞の結合パターンとして保持される。
					何度もキーボードを見て触っていると、神経細胞結合の発火の痕跡が残る。
					キーボードを見たという刺激だけで、あるキーがこの辺にあったよなという残りの記憶が活性化される。
					認知心理学では、先行刺激が後続刺激への処理影響を与えることを、プライミング効果という（<a href="#rCP">[rCP]</a>）。
					ある視覚刺激が、長期記憶から別のことを想起させた。
					これが、ドナルド・ノイマンが「外部知識」と呼んだもの（<a href="#rDN">[rDN]</a>）の正体である。
				</p>
			</details>

			<details open id=structure><summary><strong>構造を把握できる</strong></summary>
				<p>
					空間記憶と関連して、視覚は、いくつかの情報を同時に把握できるという能力がある。
					そのため、ヒトの抽象的な概念のうち、構造的な情報を認知できる。
				</p>
				<p>
					例えば、一つの画面に、やることのTODOリストがあるとする。
					1個目と2個目を比べて、どっちを先にやるか考えているとき、目は二つの項目を認知し、作業記憶の中において比べている。
					例えば、来週の出張の飛行機を予約しているとする。
					WEBの画面を見て、日時と概略出発時刻を入力し、どの会社のどのフライトにするか選択肢がでて、どれにするか検討しているとする。
					ヒトの頭の中では、日時と概略出発時刻とともに、飛行機会社のブランド名も一緒に意識している。
				</p>
				<p>
					もっとも、この視覚は構造を把握できるために、視覚向けにデザインされた下手な情報は、複雑になってしまうこともある。
				</p>
			</details>

			<details open id=visual_symbol><summary><strong>象徴を認識できる</strong></summary>
				<p>
					ヒトは言語を駆使する。音響の連鎖が、音響言語として、複雑な概念を伝える。
				</p>
				<p>
					一方で、ヒトは、視覚的な形状でほかの何かを象徴することも行ってきた。
					壁画、象形文字、表意文字、アイコン、ピクトグラムなどである。
					表意文字が言語の要素であるように、視覚的な象徴の表現力は、言語に比べて、限られている。
					言語は、感覚を指示したり、実在物を指示したり、環境を自在に利用できる。
					言語は、構文構成で概念を自在に組み合わせる表現力がある。
					しかし、視覚的な象徴は、写実画とかでもなければ、あるいは明示的な固有名詞の文字列でなければ、特定の実在物を指示する力はない。
					概念の組み合わせも、並置くらいしかできない。
					視覚的な象徴は、表現力が限定される。
					視覚的な象徴は、間接的である。
					コンピュータのアイコンも間接的であるが、その限界が忘れられている。
				</p>
			</details>

		</div>

		<div><h4>2.2.2 聴覚</h4>

			<details open><summary><strong>聴覚の能力</strong></summary>
				<p>
					ヒトの聴覚は、空気の振動を感知する遠隔感覚である。 空気の振動は、距離によって、また障害物があると減衰しやすい。
				</p>
				<p>
					ヒトの聴覚受容細胞の数は23,500個（視細胞は1億以上）、聴神経は3万本（視神経は100万本）である
					（<a href="#rHK">[rHK]</a>）。
				</p>
				<p>
					視覚がおおむね空間情報を処理するのに対し、聴覚はおおむね時間的情報を処理する。
					会話の相手の話し声、赤ちゃんの泣き声、音楽のリズムやメロディ鳥の鳴き声、など、時間的な流れの中に存在する。
				</p>
				<p>
					聴覚は、空間的情報も知覚する。
					精度は視覚より低いが、両耳により、距離と方向を感知する音源定位ができる。
					車を運転中に、サイレンの音が聞こえる。どちらの方向からを確かめるために、よく聞こうとする。
					野鳥の鳴き声がきこえてきたら、どこにいるか方角の見当をつけて探す。
					ただ、目でそれを確かめないと、満たされない気がする。
					聴覚は視覚に引きずられもする（<a href="#n03">[脚注03]</a>）。
				</p>
			</details>

			<details open><summary><strong>聴覚は発話に連動する</strong></summary>
				<p>
					聴覚に障害のある人は発話障害を伴うことが多い。
					情報は、言葉を聞く聴覚器官から、発話するための調音器官へ流れ、自分の音声を聞きながら発話する
					（<a href="#rSO">[rSO]</a>）。
					目から得た情報に基づき、手指が動くように、聞いた音に基づき、発話するのである。
					ヒトの聴覚は、音から危険を察したり気配を感じたりもするが、発話と一体となって音響言語を駆使するコミュニケーションの場面が、
					主な活躍場所に見える。
				</p>
				<p>
					コンピュータユーザー・インターフェイスでは、聴覚および音響的言語は、ほとんど活用されていない。
					一方、ヒトとヒトのコミュニケーションでは、聴覚および音響的言語が大きな役割を果たしている。
				</p>
			</details>

			<details open id=anti_structure ><summary><strong>聴覚認知は構造保持が苦手</strong></summary>
				<p>
					視覚は、空間記憶ができ（<a href="#space_memory">[空間的に記憶できる]</a>）、構造の把握ができる（<a href="#structure">[構造を把握できる]</a>）。
					聴覚は、それらが苦手な点で、対照的である。
				</p>
				<p>
					音響的な言語情報は、時系列情報である。そして、音声は消え去る。
					短期記憶に入っても、再確認できないし、しばらくたつと消える。
					そのため、ヒトは、聴覚からは、少ない量しか情報を把握できない。
					複数の情報を安定的に保持できない。
					そのため、聴覚は、フォームや手順といった複数の情報からなる構造の把握が苦手である。
				</p>
			</details>
		</div>

		<div><h4>2.2.3 嗅覚</h4>

			<details open><summary><strong>ヒトは嗅覚を退化させた</strong></summary>
				<p>
					嗅覚は、揮発性ないし水溶性の化学物質を感知する。味覚は、同じ化学物質でも接触感覚である。
					触覚という物理的な刺激に比べて、分子の組み合わせレベルの感覚であるため、嗅覚が発達すれば識別できる種類は膨大になる。
					しかし、ヒトは視覚という、より遠方まで感知する感覚を優先した。
				</p>
				<p>
					ヒトの嗅覚受容体数（種類数）は396個あり、その組み合わせで数十万種類のにおいを感知する。
					遺伝子レベルで見ると、哺乳類の嗅覚に関係する遺伝子は大きなファミリーをなしていて、動物にとって環境探知の重要な手段であることが示されている。
					また、匂い情報は、大脳の感情や記憶をつかさどる部分に流れ、内分泌で即座に反応できるようになっている。
					素早い反応によって生存するために重要な機能を果たしていた時代の名残である。
					その由来によって、匂いは長期記憶を呼び覚ます
					（<a href="#rTK">[rTK]</a>）。
				</p>
			</details>
		</div>

		<div><h4>2.2.4 体性感覚</h4>

			<details open><summary><strong>内外を感知する</strong></summary>
				<p>
					体性感覚器は外部を感知するものと内部の固有の情報を感知するものに大別される。 
				</p>
				<ul>
					<li>
						外部を感知するものは皮膚感覚である。
						ヒトの場合、皮膚は1.8平方メートルもあり、皮膚感覚の受容器は散在している。
						皮膚表面には触覚があり、皮膚の深部には圧力を感じる圧覚がある。
						その他、温覚、冷覚、痛覚の受容器がある
						（<a href="#rIN">[rIN]</a>）。
					</li>
					<li>	
						一方、筋、腱、関節などに、自分の状態を感知する固有受容器がある。
						筋がどれだけ伸びているか、どれだけの力で引っ張られているか、角度はどうか、を感知している。
						これは姿勢を制御したり体を動かすためにある
						（<a href="#rIN">[rIN]</a>）。
					</li>
				</ul>
			</details>
			
			<details open><summary><strong>指先は鋭い</strong></summary>
				<p>
					皮膚感覚受容器は10の7乗個あり、神経は10の6乗個ある。指先には1平方ミリメートル当たりに1個の神経線維が大脳に接続している。
					2点を弁別する能力は、手のひらでは1センチメールだが、指先は2ミリメートルである
					（<a href="#rMS">[rMS]</a>）。
				</p>
				<p>
					このような手指の神経の細かさが、ヒトが箸やハサミを上手に扱う基礎となっている。
					また、あとで<a href="#penfield_map">[手は第2の脳]</a>に示すように、
					体性感覚および運動制御の中で、手指に関する脳機能は大きな部分を占めている。
				</p>
			</details>

		</div>

	</div>

	<div id=effector  class="pagebreak"><hr><h3>2.3 効果器官</h3>

		<div><h4>2.3.1 手、骨、筋</h4>

			<details open id=hand_and_brain><summary><strong>手と脳の進化の相乗効果</strong></summary>
				<p>
					手、骨、筋という効果器官は、内部状態を感知しつつ、機械動作する。
					手には優れた皮膚感覚がある。
					一方で、視覚は手の動き周辺を観察するのに強力な機能を備えている。
				</p>
				<p>
					手の重要な役割は、人類史から見ると理解できる（<a href="#rCL">[rCL]</a>）。
				</p>
				<p>
					320万年ほど前、ルーシーと呼ばれる化石により、類人猿が二足歩行を始めたことがわかっている。
					骨盤の形から二足歩行していたことが分かったが、脳の大きさはチンパンジーと変わらなかった。
					二足歩行のメリットは、四足歩行に比べて25%のエネルギーで移動できることだった。
					その後、240万年ほど前に、ホモ・ハピルスが登場し、肉を骨からそぎ落とす鋭利な石器を作り利用していた。
					ホモ・ハピルスの脳はルーシーの倍（ホモ・サピエンスの半分）に大きくなっていた。
					道具を作るには目と手を正確に連動させる必要がある。それが脳に刺激となり、脳の発達を促した。
					一方、大きな脳はたくさんのエネルギーを必要とする。たくさん食べる必要があり、狩猟してとった肉を食べた。
					肉をたくさん得るには、より高度な道具が必要となる。
					こうして、手と脳の進化の相乗効果の連鎖が始まった。
				</p>
				<p>
					脳はますます大きくなり、手指はますます器用になり、道具はますます精緻になった。
					200万年前ごろ、ホモ・ハピルスは、ホモ・エレクトスへ進化した。脳の大きさは、ホモ・ハピルスの1.5倍となった。
					ホモ・エレクトスは、槍を使い、火で食物を消化しやすいように変えられた。
					100人くらいの集団で暮らしていたとされる。
					170万年前頃に、ホモ・エレクトスはアフリカを出て、別々の地域に進出し、5種類のヒト属に分化したらしい。
					その後35万年前ほど、ホモ・サピエンスと同じくらいの脳を持つネアンデルタール人が現れた。
					頭蓋骨の底に発声に必要な神経の束を通す穴があり、多様な発声ができたと想定されている。
					また、ネアンデルタール人は、音楽、宗教、言語を持っていた。
					その後、19万5000年前に、ホモ・サピエンスが登場した。
					ホモ・サピエンスは、7から5万年前に、アフリカから出て世界中へ広がった。
				</p>
				<p>
					<div align="center">
						<img width=40% src="brain_capacity_of_primates.png"> 
						<p>[http://user.keio.ac.jp/~rhotta/hellog/lib/brain_capacity_of_primates.pngより]</p>
					</div>
				</p>
				<p>
					以上のように、手によってこそ、脳が大きくなった、と言われる。
					ほかの説もある（<a href="#n04">[脚注04]</a>）。
				</p>
				<p>
					あとで<a href="#penfield_map">[手は第2の脳]</a>に示すように、
					体性感覚および運動制御の中で、手指に関する脳機能は、確かに、大きな部分を占めている。
				</p>
			</details>

			<details open id=hand_dexterity><summary><strong>手指は器用</strong></summary>
				<p>
					ヒトの手は、器用である。
					ヒトの手には5本の指があり、指は3つの関節を持ち、動く。
					そして、親指は、ほかの指と独立して動き、ほかの指と対面して動作し、物をつかんだりできることできる。
					この対面動作できることが、ヒトの手指の特徴である。	
				</p>
				<p>
					<div align="center">
						<img width=40% src="fingers.png"> 
						<p><a href="#rYH2">[rYH2]より</a></p>
					</div>
				</p>
				<p>
					手指ができる運動は、以下のように分類されている。そに多様さに驚く。
					<ul>
						<li>握る(grip)</li>
						<li>つまむ(pinch): 指先(tip)、指腹(pulp)、側面(lateral)、ひっかけ(hook)、指間はさみ(finger)</li>
						<li>ねじる(twist)</li>
						<li>押す(push)</li>
						<li>すくう(scoop)</li>
					</ul>
					これらの組み合わせで、日常生活を送っている。
				</p>
				<p>
					<div align="center">
						<img width=40% src="finger_behavior.png"> 
						<p><a href="#rYH2">[rYH2]より</a></p>
					</div>
				</p>
				<p>
					ここで、コンピュータ相手には、ヒトは、「押す」（クリック、キータイプ、タップ、スワイプ）しか使っていないことに注意しよう。
					ほかの多様な手指の機能を、現在のコンピュータは利用していない。
				</p>
			</details>

			<details open id=body_supports_hand><summary><strong>身体と視覚が手指の器用さを支えている</strong></summary>
				<p>
					手指は、体幹が支えて身体がある姿勢をとって、肩や腕が支え、腕・肘・手首が動き、手首が支えることで、はじめて器用に動く。
					体性感覚と機械的効果器が、手指の器用さを支えている。
					まさに、手指の器用さは、全身運動の結果である。
				</p>
				<p>
					手指は、視覚に障がいがある方を除き、多くの場合、目に助けられてこそ機能する。
					例えば、ドアノブの位置を目にしながら、そこをつかんでひねりドアを開く。
					そこに、ドアを開けるという意図で行動した点に、あいまいさはない。
					例えば、左手に持った茶碗の位置を、目で感知しながら、右手の箸を動かして、茶碗のごはんを摘まみ上げる。
					例えば、机の上に置いた紙を左手で押さえて、その四角い方向を目で確認したうえで、右手のはさみで紙の一片を切り取る。
					例えば、キーボードがあってキートップの文字マークを見て、手指は動く。
					音声だとbaなのかpaなのかわかりにくいこともあるが、
					手指の動作は、目でキートップを確認しているため、コンピュータに対して、曖昧さなくpaという言語表現がされる。
					このように、手指は視覚と一緒に働くことで、様々な機能を果たす。
					ヒトの構築した人工的な構築物の中を動き回る際も、その手指の動作に曖昧性はない。
				</p>
			</details>

			<details open id=fitts_law><summary><strong>手指は距離に束縛される</strong></summary>
				<p>
					手を動かし、マウスで、別の場所のターゲットに移すという運動負荷に関し、
					その移動時間は、移動距離が大きいほど大きく、対象の大きさが大きいほど小さくなる。
					これをフィッツの法則という。
					手指は、機械動作なので、この距離の束縛を受ける。
				</p>
				<p>
					例えば、受信箱のメールのTriageを取り上げてみる。
					メールをざっと眺めて丁寧に読みたいメール以外は即削除する作業である。
					スマホでなら、指先の操作ですむので、素早くできる。
					しかし、デスクトップであると、画面が大きく、手から離れているので、マウスごしにGUI対象をポチポチするする必要がある。
					読む場所を設定する画面上の位置と、削除ボタンは離れているので、いちいちマウスポインターを移動する手間がある。
					そのため、メールのTriageは、スマホに比べて、デスクトップPCでの作業には、時間がかかる。
					手指の操作は、このように、距離の束縛を受ける。
				</p>
				<p>
					一方、視線の移動は、距離の束縛を受けない。
					移動は一瞬である。
					また、音声動作は、マイクが音を拾う限り、
					スマホでもデスクトップでも同じスピードでテキスト指定動作ができる。
					音の聞こえる範囲ならば、距離の束縛を受けない。
					現在のコンピュータのユーザインターフェイスは、ヒトが手指で道具を操作するという伝統にあるので、
					こういったヒトの体の特性が無視されている。
				</p>
			</details>
		</div>

		<div><h4>2.3.2 発声</h4>

			<details open id=vocal_organ><summary><strong>発声器官の進化</strong></summary>

				<p>
					ヒトの音声産出は、横隔膜・肺という呼吸器官から空気を吐き出し、咽頭・声帯で音源を作り、
					舌・咽頭・口唇で音に変化を与える、と3つの器官要素によって生産される
					（<a href="#rKH2">[rKH2]</a>）。
				</p>
				<p>
					<div align="center">
						<img width=50% src="resonance_cavity.jpg"> 
						<p>[https://band-knowledge.com/vocal-14/より]</p>
					</div>
				</p>
				<p>
					脊椎動物が陸に上がって肺呼吸をするに伴い、空気の振動を起こす能力が、生殖や警告などに利用されて進化したようである。
					一方、舌は、食べ物を飲み込むときに、精緻に、素早く動くように進化していた。
					咽頭を含む声道は、食べ物の摂取・嚥下を、不随意的に担うとともに、ヒトでは随意的に話し言葉を発声する役割を持つ。
				</p>
				<p>
					ヒトは、320万年前に直立歩行を始めた。
					そして、火を使うことで、やわらかい食事をとるようになった。
					そして、頭の重量のバランスをとるため頭の前後径が短くなり、柔らかい食事による顎の縮小とあいまって、脳が前にせり出し、
					舌は、前後に圧縮されて上下に厚みを持ち、丸い形状になった
					（<a href="#rFJ">[rFJ]</a>）。
					そして、類人猿以来、咽頭の位置は下がり始めた。
					そして、喉に大きな空間をつくり、多様な共鳴を生み出せるようになった。
					ヒトの声道は、口腔と咽頭腔という二つの共鳴腔がほぼ垂直に結合していて、それぞれ独立に変形させることができる、
					二共鳴管構造である。
					ヒトの舌は、丸みがかっていて、形状変化で多様な音調整を可能にした。
					また、ヒトは、発話の際、1秒間に5〜6回、口が開閉する
					（<a href="#rKH3">[rKH3]</a>）。
				</p>
				<p>
					ネアンデルタール人の舌骨は、ヒトと同様の形態をしていたことから、
					ネアンデルタール人もヒトと同様の発話が可能だったとされる。
				</p>
				<p>
					ヒトは話をする時に、一回息を吐くという瞬間で、多くの異なる音を発声するために
					声道形状を連続的に素早く変形させることができる点が、特異であるとされる
					（<a href="#rNT">[rNT]</a>）。
				</p>
			</details>

			<details open id=talkative_animal><summary><strong>ヒトはおしゃべり</strong></summary>
				<p>
					あとで<a href="#penfield_map">[手は第2の脳]</a>に示すように、
					体性感覚および運動制御の中で、発声器官周辺に対応する脳機能は、大きな部分を占めている。
					また、音響言語を専門に処理する部門も、大脳の大きな部分を占めている。
				</p>
				<p>
					また、ヒトは成長に伴って、言語を習得し、多様な音声生産ができるようになる。
					この音声生産の可塑性ないし学習という点も、特徴的である
					（<a href="#rKH2">[rKH2]</a>）。
					それを可能にする神経系の進化が、別途、ヒトの発声能力の背景にあった。
					ヒトの脳は、後で<a href="#rain_plasticity">[脳の可塑性]</a>で見るように、
					後天的に形成される部分が大きい。
					言語はそもそも社会活動である。
					ヒトは、手で道具を作ることで脳と相乗効果を持ったのと同じくらい、
					ヒトの社会活動とその言語活動が、脳の成長と相乗効果を持ってきたことは、容易に想像できる。
				</p>

			</details>

			<details open id=text_productivity><summary><strong>発声のテキスト生産速度は指の5倍</strong></summary>
				<p>
					ヒトの言語表現のスピードは、経験的におおよそ、
					しゃべりなら160語/分、手書きは30語/分、タイプなら40語/分である。
					しゃべりは、社会的な環境で育った健常者ならば誰でもできる。
					一方、手書きは教育が必要であり、キータイプなら機器操作に慣れが必要である。
					音声での言語表現は、習熟の必要がないばかりか、指よりも5倍速い。
				</p>
				<p>
					音響言語は、コンピュータ・ユーザー・インターフェイスとして、ようやく使い始められたばかりである。
					まだ、広範囲なアプリで活用されていない。
				</p>
			</details>

		</div>

	</div>

	<div id=brain  class="pagebreak"><hr><h3>2.4 脳・神経系</h3>

		<details open><summary><strong>脳の構成要素</strong></summary>
			<p>
				脳は、大脳、小脳、脳幹からなる。
			</p>
			<p>
				<div align="center">
					<img width=50% src="brain.jpg"> 
					<p>[https://atamanavi.jp/169/より]</p>
				</div>
			</p>
			<p>
				<ul>
					<li>大脳：
						大脳は、高度な機能をこなす。大脳には、皮質、辺縁系、基底核がある。
						<ul>
							<li>
								皮質には、前頭葉、運動関連領域、頭頂葉、後頭葉、側頭葉がある。
								<ul>
									<li>
										前頭葉は、前頭前野と運動関連領域からなる。
										前頭前野は、ほかの皮質部位と相互接続してし、他からの情報を得ては指示する関係を持つ。
										前頭前野は、一時作業記憶機能を中心とした認知機能を持ち、空間・形態・色記憶を処理する。
										前頭前野は、他人の心を理解する。辺縁系の本能的な情動を抑制・選択する。
									</li>
									<li>
										運動関連領域は、一次運動野、補足運動野、運動前野がある。
										一次運動野は、脊髄に指示を送る。
										ほかの運動野と接続している。
										運動前野は、外部刺激に応じて、手を伸ばし把握したり、両手を協力させるなど、運動を準備し企画構成する。
										補足運動野は記憶に基づいて運動する。
									</li>
									<li>
										頭頂葉は、体性感覚野、頭頂連合野、高次運動野などがある。
										体性感覚野は、身体部位ごとの局在性がある部分から、そこから高次な連合を担う部分へ、階層的につながっている。
										体性感覚野は、姿勢や自己身体を認識している。
										手を能動的に動かして探索するとき興奮する。
										この部位は、手で操作する道具を、手の延長としてイメージする。
									</li>
									<li>
										後頭葉は、視覚情報の中枢である。
									</li>
									<li>
										側頭葉は、形態情報を認識する部位を持つ。
										また表情など特定の視覚刺激に選択的に反応する部位を持つ。
										これらから海馬や偏桃体へ接続し、記憶と照合される。
										また、聴覚情報の処理を行う。
										聴覚系は、情報は、前頭葉へ送り何の認知を行い、頭頂葉へ送りどこの認知を行う。
									</li>
								</ul>
							</li>
							<li>
								辺縁系は古い脳であり、哺乳類で皮質のほうが徐々に大きくなり辺縁系を覆うようになった。
								辺縁系は、意欲や情動・本能行動の中心的司令塔である。
								辺縁系には、海馬、偏桃体、帯状回などがある。
								偏桃体は、外部刺激に対し、皮質での処理を待たずに、瞬間的な反応・行動を起こす。
								海馬は、記憶と空間認識に関与する。
								帯状回は、他者の心を想像する能力にかかわるらしい。これを「心の理論」という。
							</li>
							<li>
								大脳基底核は、(特に内発的な）随意運動の制御、認知・情動の制御、学習の強化を担っている。
								皮質の各部（運動領域、連合領域、辺縁系）と接続し、また脳幹と接続し、それらの機能を調整している。
							</li>
						</ul>
					</li>
					<li>小脳：
						小脳は、脊髄に伝わってきた体性感覚と視覚から、身体の姿勢を制御したり、外発的な運動を指令・学習する。
						例えば、足の動かし方を意識せずに歩いたりできる。
						首が回転したときに、反射的に眼球が逆回転し、視界のブレをなくす。
					</li>
					<li>脳幹：
						脳幹は、脊髄からシグナルを伝達して、基本的な体内の機能と反射を指令する。
						爬虫類脳とも呼ばれ、生命維持・繁殖に必須な機能を果たす。
						例えば、呼吸や心臓の拍動など不随意・自律的な機能をこなす。
						脳幹は、中脳、間脳（視床、視床下部など）を含む。
						間脳は、感覚を仲介し、感情を管理し、全体の内部システムを統括する。 
					</li>
				</ul>
			</p>
		</details>

		<details open id=小脳は所作の匠><summary><strong>小脳は所作の匠</strong></summary>
			<p>
				大脳の皮質には神経細胞が140億あるが、小脳には1000億個ある
				（<a href="#rMA">[rMA]</a>）。
				小脳は、ヒトでは脳全体の15%程度の容積しかないが、脳全体の神経細胞の約半分が存在する。
				末梢感覚器や大脳皮質からの入力を受けて、運動を学習する
				（<a href="#rHN">[rHN]</a>）。
				鋏を扱うときの動作、箸を扱うときの動作、話す動作、歩く動作、大工の技、庭師の技、などにこそ、目立たないが、実は大量の知能が、詰まっている。
				ヒトを知識、いわば見える氷山の一角、で比べたりする。
				が、それ以前の、目立たない、生活のための知能のほうが、はるかに大きく、ヒト共通である。
			</p>
			<p>
				ロボットに、ヒトや動物の所作をまねさせて、歩かせたりするアプローチがある。
				小脳世界を機械で再現しようとしている。
			</p>
		</details>

		<details open id=penfield_map><summary><strong>手は第2の脳である</strong></summary>
			<p>
				大脳皮質には、体性感覚野と運動野において、機能が特定の場所に関連付けられる箇所がある。
				運動野を見ると、発声関係と、手指の部分が大きいことに気づく。
				発声関係は言語機能と関係して大きな部分を占めるのは理解しやすい。
				一方、手は第2の脳といわれるほど、大きな運動知能を持っている。
				大脳皮質は、ほかの脳・神経部位を制御・指令する部位として、哺乳類になって発達した部分である。
				それ以前は、脊髄や小脳レベルで反応することで足りていた。
				また、哺乳類の中でも、人は特に皮質が発達した。
				ヒトの大脳皮質の、感覚と運動に局所的な部分のかなりが、手指と発生器官周りに対応することは、
				これらがヒト知能の本質的な部分であることを示す。
				<p>
					<div align="center">
						<img width=60% src="cerebral_penfield_map.jpg"> 
						<p>[https://www.akira3132.info/cerebral_cortex.htmlより]</p>
					</div>
				</p>
			</p>
		</details>

		<details open id=association_area><summary><strong>人は総合する動物</strong></summary>
			<p>
				感覚野と運動野という機能局在な部分を除くと、大脳皮質の約2/3にも相当する広い領域が、連合野と呼ばれる。
				連合野は、高次な脳機能を具現化している皮質領域である。
				感覚情報の高度な統合による認知、複数の感覚の総合、感覚と運動の統合、過去の経験（記憶）と関連、随意運動、
				情動行動、言語機能、精神機能、作業記憶（ワーキングメモリー）などである（<a href="#rKW">[rKW]</a>）。
				個々の感覚・運動機能よりも、それらを統合した部分が、ヒトのヒトたる部分である。そこが、ヒトの特徴である。
			</p>
			<p>
				現在のコンピュータのユーザ・インターフェイスは、手で操作し、目で知覚するのが、主である。
				しかし、このような特定のチャネルだけに頼るやり取りは、ヒトの脳の進化結果に照らしてみると、ヒトの生体機能に反している異常なことである。
			</p>
		</details>

		<details open id=magical_number><summary><strong>短期記憶は4個まで</strong></summary>
			<p>
				一度に記憶できるのは、4個までだそうである。
				長期記憶から、あるカテゴリーで想起できるのは、3個までだそうである。
				チンパンジーは、4個の数字までは95%の正確さで覚えられるが、5個で65%まで落ちるそうである。
				また、ヒトは、選択肢が3つか４つまでの場合に限り、選ぶことができる（<a href="#rSW">[rSW]</a>）。
			</p>
			<p>
				これ以上の選択肢が、電子機器のリモコンやコンピュータ・ユーザ・インターフェイスに、あふれている。
			</p>
		</details>

		<details open id=brain_plasticity><summary><strong>脳の可塑性</strong></summary>
			<p>
				ヒトの遺伝情報であるヒトゲノムは約30億個の塩基で構成される。
				一つの塩基はATGCの4種類の分子のいずれかで2ビットの情報をもつ。
				したがって、ヒトゲノムは2x30憶=60億ビットの情報量を持つ。
				一方、新皮質の神経細胞は100億個で、神経細胞当たりシナプスの結合数を1000個とし、結合係数は抑制と興奮の2値（1ビット）とすると、
				脳の情報量は約10兆ビット（100億X1000=10兆ビット）となる。
				ヒトが生まれる際に受け継いだ情報量よりも、ヒトが成人になって活用する情報量のほうが、1600倍大きいのである。
				つまり、脳の配線の大部分は遺伝ではなく、生後決定される
				（<a href="#rSO">[rSO]</a>）。
				つまり、ヒトは学習する。
			</p>
			<p>
				遺伝して得た情報量よりも、後天的に獲得する情報量が、1600倍というのは信じがたい。
				新しい知見が今後出てくるだろう。
				しかし、後天的な事柄、社会や文化というヒトの抽象物が、ヒトの生物としての生得物と比べて、大きな比重を持つという事実は、驚きである。
				これは、ヒトが今後どのような未来を持つことになるのか、生物的な進化よりも、もしかして社会的な思考の成果が、断然影響力を持つかもしれないことを、示唆する。
				ヒト集団は、生物の遺伝子の論理を超えて、歩み始めるかもしれない。
			</p>
		</details>

		<details open id=cognitive_interference><summary><strong>人は時分割でマルチタスクできる</strong></summary>
			<p>
				ヒトは、歩きながら、ものを考えることができる。
				今、そういう無意識的な行動でなく、ある程度注意力を要する作業のことを想定する。
				ヒトは、考えるという音響的言語活動と、文をタイプするという指の機械的・視覚的・空間的な言語活動を、
				うまく同時にこなせるように見える。
				認知活動と脳の資源の関係のモデルを<a href="#rCW">[rCW]</a>が提唱した。
			</p>
			<p>
				<ul>
					<li>
						知覚・認知のための資源と、反応の選択と実行の資源とは、独立である。
						例えば、パイロットは飛行機の込み具合を認識しながら、同時に適切な対応をとる。
					</li>
					<li>
						音響的作業と視覚的作業とは、それぞれの作業を複数やるよりは、2つの異なる種類の作業をより効率的に時分割できる。
						例えば、何か文章を考えているときに他人とおしゃべりはできない。
						しかし、車の運転手は、声で指示を受けて、ハンドル操作ができる。
					</li>
					<li>
						周辺視野と注目視野とは、異なる資源を使う。例えば歩きスマホができる。
					</li>
					<li>空間的過程と、音響的過程とは、効率的に時分割できる。
						例えば、運転中、ハンドル操作以外の手操作は運転を中断させるが、声で機器操作するのはより楽である。
						耳で捕まえた議論のキーワード（音響的言語活動）を、記録する（空間的言語活動）ことができる。
					</li>
				</ul>
			</p>
			<p>
				最近の研究では、ヒトが一度にできるのは一つだけである（<a href="#rSW">[rSW]</a>）とわかったという。
				ヒトは、素早く切り替え、時分割して、二つの作業を同時にこなしているように見えるらしい。
				時分割できるとはいえ、自動車の運転をしながら、着信した電話で会話をするのは、実は注意力を散漫にしている。
				音楽を聴きながら、勉強したり、仕事をしているのは、実は、作業効率を下げている。	
			</p>
			<p>
				<a href="#rYT">[rYT]</a>では、言語活動に、視覚的言語活動と、音響的言語活動とがあるという。
				音声言語と文字言語といってもよい。
				頭で、数を数えながら（音響的言語活動）、しゃべること（音響的言語活動）はできない。
				しかし、頭で数字カードで数字が増えていくのをイメージしながら（視覚的言語活動）、しゃべること（音響的言語活動）はできる。
				つまり、視覚的言語活動と、音響的言語活動とは、効率的に時分割できる。
			</p>
			<p>
				ヒトの言語活動は、視覚と音響とで効率的に時分割できる。
				ヒト対ヒトのコミュニケーションは、最初は身振り手振りの空間的な象徴だったかもしれない。
				その後、長く音響的言語が支配した。
				その後、文字、紙、ペン、印刷など、空間的な手段による言語を利用した。
				ヒトは、これら音響言語と視覚的言語の両方を、効率的に活用できる。
			</p>

		</details>
	</div>

</div>

<div class="pagebreak"><hr><h2>3. 言語</h2>

	<details open><summary><strong>ヒト</strong></summary>
		<p>
			ヒトの特徴について、振り返る。
		</p>
		<p>
			ヒトの脳は大きい。
			純粋な大きさでいえば、クジラのほうがヒトよりも脳は重い。神経細胞の数もクジラは1億を超え、人と大差ない。
			が、脳の重さを体重のある冪乗で割った指数だと、ヒトはほかの動物を引き離す。
			だが、脳の相対的大きさは、ほかの要因のために脳が大きくなったのであり、結果としての特徴である。
			それらの要因とは何か？
		</p>
		<p>
			400万年前の初期人類のアウストラロピテクスは、直立二足歩行を始めた。
			そして、ホモ・エレクトスで、直立姿勢が完成した。
			手が自由になったことが、手先の器用さを促した。
			すでに霊長類は、ほかの動物に比べて、手先が器用であった。
			ヒトでは、親指がほかの指と対面するようになって、上手にものをつかめた。
			次第に、ヒトはを使って複雑な作業ができるようになった。
			手先の器用さと、道具の利用と、脳の発達に、相乗作用があったということは、
			<a href="#hand_and_brain">[手と脳の進化の相乗効果]</a>で見た。
		</p>
		<p>
			一方、霊長類では、社会的関係が強く、複雑である（<a href="#rCP">[rCP, 第14章認知進化と脳]</a>）。
			それが、脳の発達を促したという説がある。
			社会脳仮説といわれる。
			社会関係があったために、毛づくろいなどのコミュニケーションが発達した。
			またほかの個体の道具使用を模倣できた。
			そして、他個体の心を推察することができた（心理学や脳科学で、「心の理論」を持っている、と言われる）。
		<p>
			類人猿でも、他個体の視線や指さしによって、他個体の注意している対象へ注意を向けるという、共同注意行動がみられるという。
			また、類人猿でも、他個体の表情に対し、脳のヒトと同様な場所が局所的に興奮するという。
			なお、心の理論は、自己意識の源でもある（<a href="#n07">[n07]</a>）。
			また、サルやヒトには、ミラーニューロンというものがあることが知られている。
			ある道具を使うとき、身体の一部とみなして興奮する神経細胞がある。
			他個体が、目の前でその道具を使うとき、自分が操作しているのでないにもかかわらず、同じ神経が興奮するという。
		</p>
		<p>
			手と道具ということと、社会脳という二つの話は、直立二足歩行を共通要因として、つながる。
			ハラリ（<a href="#rYH">[rYH]</a>）によると、直立二足歩行が、ヒトの社会性の一層の強化を招いたという。
			直立すると、腰周りを細める必要がある。参道が狭まった。
			そのため、子度は小さい、早い時期に出産したほうが有利だった。
			子供は、ほかの動物よりも、未熟な状態でうまれることになった。
			未熟な子供には、周りで守る中間が必要だった。
			子育てのために、大人の社会が必要であったと。
		<p>
			他方で、<a href="#vocal_organ">[発声器官の進化]</a>でみたように、ヒトは、発声器官を進化させていた。
			そして、上記のような発達した社会脳のもとに、音響言語でのコミュニケーションが発達した。
			コミュニケーションが、さらに社会脳を大きくしたことも想像できる。
			ここにも、社会とコミュニケーションと脳の成長の相乗作用があった。
		</p>
		<p>
			ハラリ（<a href="#rYH">[rYH]</a>）によると、さらに、30万年前ほどには火を使っていたことが、脳の進化の要因だという。
			火を使った調理によって、消化が楽になった。
			そのおかげで、小さな歯と短い腸で足りるようになった。
			そして、得たエネルギーを脳に使うことができた。
		</p>
	</details>

	<details open id=言語の発生><summary><strong>言語発生</strong></summary>
		<p>
			言語の発生については、諸説ある。
		</p>
		<p>
			マイケル・コーバリスは、身振り・手振りで表現することが、言語のもとになったと唱えた
			（<a href="#rMC">[rMC]</a>）。
			身振り・手振り以外に、赤ちゃんでも利用し理解する、表情、まなざし、指さしなども重要なコミュニケーション手段である。
			これらは、空間的な情報伝達手段である。
			ヒトの場合、40万年前ほどのころ、複雑な発生器官を持つにいたり、音声言語を使いだした。
			ヒトがコミュニケーションをとる際、身振り・目振り、手振りという、空間的な表現で弁別してきた意味を、
			生物の進化で体得した器官を活用することで、次第に音響的に表現することを獲得したのかもしれない。
		</p>
		<p>
			解剖学者は、ヒト言語の物理的な成り立ちに、驚異する。
			養老先生による（<a href="#rYT">[rYT]</a>）と、言語には時間的言語（音声）と空間的言語（文字)とがある。
			視覚は光という電磁波を感知し、聴覚は空気振動を感知し、独立に進化した。
			視覚は空間の中に時間と無関係にあり、音は時間の中に空間と無関係にある。
			ヒトは、それら異なるものを連合し統一した。
			それが、ヒトにおける言語の発生ということだと。
			ヒトの言語は、視聴覚が一体なのである（<a href="#n06">脚注06</a>）。
		</p>
		<p>
			歴史家は、ヒト言語特徴を指摘する。
			ハラリ（<a href="#rYH">[rYH]</a>）によると、ネアンデルタール人やデニソワ人でなくホモサピエンスだけが生き残ったのは、
			架空のことを語る柔軟な言語のせいだという。
			7万年前から3万年前にかけて、ヒトは、大人数で、アフリカ大陸を出て、
			ネアンデルタール人を絶滅させ、中東、ヨーロッパ、アジア、オーストラリアに広まった。
			ヒトは、そのころ、船、ランプ、弓矢、針などを発明した。
			宗教、交易、社会的階層も生まれた。
			この時期のヒトの変化を「認知革命」と呼んだ。
		</p>
		<p>
			どんな動物も、なにがしかの言語を持って、仲間とコミュニケーションする。
			例えば、ハチはダンスというジェスチャーで、餌の場所をコミュニケーションする。
			多くの動物は、フェロモンという匂いの化学物質で、生殖のためのコミュニケーションをする。
			ある魚は、電気でコミュニケーションするという。
			ある動物は、体表の色で異性にアピールする。
			カラスやシジュウカラは、鳴き声の種類で、仲間とコミュニケーションする。
			ある動物たちは、体臭を残すことで、縄張りを他個体にコミュニケーションする。
			これらは、生存・生殖に密着したコミュニケーションである。
			一方、サルは、声を、他個体を欺くためにさえ使うこともあり、
			類人猿は、社会的な関係を操作するのにも、言語を使い始めていた。
		</p>
			サルからさらに進化して、
			ハラリによれば、ヒトは、認知革命によって、実在しない架空の事物について語る柔軟な言語を持ったという。
		</p>
		<p>
			動物の世界では、社会的集団は、安定した関係を保つには、
			個体数150（ダンパー数）が限界だという（<a href="#rSW">[rSW]</a>）。
			ところが、ヒトが集団移動したときは、ダンパー数を越えて移動し、協力したに違いない。
			また、その後、都市などを建設したりもする。
			これを、ハラリは、ヒトは認知革命によって、架空の物語、つまり伝説、神話、宗教など、
			彼の言葉でいうと虚構を共有できる能力があったからこそだという。
		</p>
	</details>

	<details open><summary><strong>言語の効果</strong></summary>
		<p>
			言語の効果は明確である。
			ヒトは、動物的に知覚に反応する以上に、抽象的な概念、シンボルを思念する力を持っていた。
			ヒトは、言語によって、概念を組み合わせ、無限の種類の意味を表現し、理解することができるようになった。
			言語は、実在するあるいは抽象的な何かを指示し、構文構造を持って、組み立てる。
			構文構造は、再帰的なので、実質、文の種類は無限である。
			感覚から離れた複雑な概念をも表現できることが、ヒトの世界を広げた。
			歴史学者、ハラリの表現でいえば、虚構がヒト社会の本質となった（<a href="#rYH">[rYH]</a>）。
		</p>
	</details>

	<details open id=文字の発明><summary><strong>文字の発明</strong></summary>
		<p>
			およそ5000年前のシュメール文明に、ヒトが文字を使った初めての痕跡が残っている（<a href="#rCL">[rCL]</a>）。
			ヒトは、器用な手指と、それを導く高度な視覚があって、文字を操れるようになった。
			文字によって、ヒトは、時間と空間を超えて、言語を通して、様々な情報を伝達できるようになった。
		</p>
	</details>

	<details open><summary><strong>文字の効果</strong></summary>
		<p>
			それ以来、ヒトのコミュニケーションは、生活圏内の人との会話による日常的なものと、時空を超えた書き物によるものと、2種類のものに分かれた。
			ヒトは、集団を形成するのに、個体数150（ダンパー数）くらいが限界であるという（<a href="#rSW">[rSW]</a>）。
			この時点で、150人くらいの集団を超えて、コミュニケーションし、何かを共有する道が開けた。
			音声は、近場の人にしか伝わらない。
			しかし、文字によって、時空を超えて伝達されるということは、個体や生活空間の枠を超えることである。
			集団としての文化形成、集団としての教育、集団としての思考の深化、に役立った。
			構成個体数が多くばなれば、その相乗作用によって、いわばネットワーク効果が生まれる。
			インターネットで起きた変化に類似の爆発的な変化が、文字によってもたらされたのだろう。
		</p>
		<p>
			さらに文字は、時間的な次元でも効果をもたらした。
			書き物によるコミュニケーションでは、文字を認識するためにもっぱら目を使う。
			ヒトは、言語に文字という視覚的な要素を合わせた。
			それによって、ヒトは、文字として、外部に永続的に記憶を保持することができるようになった。
			時間とともに流れ去る音声言語と異なる点である。
			紙切れに書いたメモである。
			知識を記録した本である。
			そして、世界中の人に共有されるインターネットである。
			外部的な永続性は、個体にとっても、意義は大きい。
		</p>
		<p>
			外部に視覚的に文構造を保持できるため、言語表現も様変わりした。
			省略がしやすくなった。
			文字の発明の前、ゴータマ・ブッタの弟子が生きた時代、師の教えを受け継ぐには、口伝しか方法がなかった。
			音声表現は、韻を踏んだものだと、覚えやすいという。
			また、教えを伝えるには、言い間違えが起きないように、詳細を何度も繰り返したから、ともいう。
			しかし、文字が利用できるようになると、韻律は関係なくなった。
			また、先に書いたことは省略できるようになった。
			目で、即座に先の文章を確認できるから。
		</p>
		<p>
			視覚的言語なので、一度に多くの言葉を認知することができる。
			永続的な記録は、目で何度も確認できるため、記憶しやすい。
			省略もできるため、記憶効率もいい。
			永続的な記録言語は何度も見直して、思考を深めることができる。
			個人は、望めばいくらでも知識や思考を深めるようになったのである。
		</p>
	</details>

</div>

<div class="pagebreak"><hr><h2>4. コンピュータ</h2>

	<div><h3>4.1 コンピュータという操作道具</h3>

		<details open><summary><strong>コンピュータの恩恵</strong></summary>
			<p>
				ヒトは、動物的に知覚に反応する以上に、抽象的な概念、シンボルを思念する力を持った。
				ヒトは、言語によって、概念を組み合わせ、無限の種類の意味を表現し、理解することができるようになった。
				ヒトは、文字によって、時と空間を超えて、意味を共有できるようになった。
				ヒトは、コンピュータによって、記憶や計算を組み合わせてできることならなんでも、疲れ知らずに、どれほどでも、こなせる相棒をえた。
			</p>
			<p>
				コンピュータでディジタルデータが実在を主張し始めた。
				情報のディジタル化によって、記録、コピー、更新が楽になった。
				情報に対する検索やソートやチェックといった計算機能が難なく利用できるようになった。
				ディジタルになることで、紙の物理的な劣化から解放された。
				ハイパーリンクで、メディア間の関連付けが自由にできるようになった。
				さらに、人が使うコンピュータでネットワークを構成することで、インターネットが生まれた。
				このインターネットによって、ほぼ誰でも情報を発信し誰の発信内容もアクセスできるようになった。
				文字によってはじめられた外部の知識が、ほぼ誰でも生産し共有する巨大な情報倉庫になった。
				誰とでも即座につながり、いつでもどこでも巨大な情報倉庫に自由にアクセスできる。
			</p>
			<p>
				スマホの地図アプリを見てみよう。
				紙の地図と異なり、本屋へ出かけて買ってくる必要はない。
				紙の地図と異なり、スマホをポケットに入れておけば、かさばるものをカバンに入れて持ち歩く必要はない。
				紙の地図と異なり、探したい場所は、ズームインとズームアウトの組み合わせで、一瞬で見つかる。
				メモを付加することができる。
				スマホは、自分がいる場所をGPSで感知しているので、いまここから、目的までの道案内をしてくれる。
				近くのレストランをすぐに探せる。
				そこで人々が感じたことを読み、書気残す。
				近くの道路の混雑具合をすぐに調べられる。
				ヒトは、こんな素晴らしい道具を、だれで手にするようになった。
			</p>
		</details>

		<details open><summary><strong>エリートが知能の拡張を目指した</strong></summary>
			<p>
				これから、現在のコンピュータ及びそのヒトとのインターフェイスを振り返る前に、歴史を振り返っておく。
			</p>
			<p>
				コンピュータは、第2次大戦で、ミサイルの弾道計算などに利用され、成功をおさめた。
				そして、ヴァネバー・ブッシュが、1945年に、「私たちが考えるように」（As We May Think）という論文（<a href="#rVB2">[rVB2]</a> ）を公開した。
				それは、機械や安くて大量に生産できるハードの進歩を踏まえて、それらが人の物理的な力を拡張した。
				一方、ヒトの精神は拡張していない、と指摘する。
				そして、これからの科学者は、蓄積された知識を活用する作業に向かうべきだと唱えた。
				それは、以降のコンピュータ研究者の先人たちにインスピレーションを与え続けたという。
				その論文には、こうできる、ああできる、という様々な未来ストーリーが描かれている。
				その中に、情報の関連性をたどれる、現在のハイパーリンクのアイデアさえ、書かれている。
			</p>
				コンピュータは、その創成期には、<strong>『知能の拡張』</strong>が目標だった。
				単純だが膨大な計算を代わりにやってくれた道具なので、その延長である。
				頭脳労働を助けてくれる、知能を拡張する道具という発想である。
				現にその論文の終わりの部分には、現在、BMI（脳機械インターフェイス）と呼ばれる技術を理想とした記述がある。
				ここで、コンピュータのターゲットユーザ（ペルソナ）は、科学者や研究者という、インテリないし<strong>『エリート』</strong>だったことにも留意しておく。
			</p>
			<p>
				ブッシュの影響を受け、その後、いくつかの重要な概念が生まれた。
				それまでは、コンピュータとのやりとりは、一括してデータを与え、一括して結果を受け取るやり方だった。
				リックライダーという人は、1960年に、ディスプレィごしに対話式にやり取りすることを提唱した。
				エンゲルハートという人は、1962年、「Augmenting the Human Intellect: A conceptual framework」という論文を発表した。
				そして、1968年に学会で、マウス、ワードプロセサ、COPY&PASTE、ハーパーリンク、リアルタイムな共同作業、画面分割、ビデオ会議などを
				デモし（<a href="#rDE">[rDE]</a>）、参加者をびっくりさせた。
			</p>
			<p>
				その後、回路の集積度が高まり、ハードが小型化できる趨勢を眺め、アラン・ケイが、1970年代にパーソナルコンピュータの概念を発明した。
				ここに、今日のコンピュータのユーザー・インターフェイスが、ほぼ完成する。
				この時、アラン・ケイは、子供でも誰でも使えるコンピュータを狙った。
				つまり、コンピュータの歴史の中で、初めて、ペルソナの転換という画期的なことをやった。
				しかし、それまでの経緯から必然的に、そのユーザ・インターフェイスに盛り込まれたものは、エリートの知能を拡張する機能に基づいていた。
				パソコンは、あくまでも情報を処理する道具であった。
			</p>
			<p>
				コンピュータがさらに小型化できる流れを踏まえ、ユビキュタス・コンピューティングというビジョンや、
				タンジブルビッツというユーザー・インターフェイスの新しい考えも生まれた。
				しかし、エリートの知能拡張のための道具としての概念立てということに対し、エリートたちに批判的な思考は起きなかった。
				頭脳労働を助けてくれればよかったのである。
				そこに、ヒトが持つ意図とかヒトの身体性とかは、関心の外にあった。
			</p>
			<p>				
				そして、スマートフォーンが生まれた。
				ペルソナは、万人である。
				用途は、情報の流通である。
				もはや、エリートの知能拡張という発想のインターフェイスでは、限界があるのは、明らかである。
			</p>
		</details>

		<details open><summary><strong>コンピュータの操作のための概念は抽象的である</strong></summary>
			<p>
				認知心理学によると（<a href="#rCP">[rCP]</a>）、ピアノ、蛇、時計などの具体的なものの単語は、
				正義、能力、自我などの抽象的な単語よりも、記憶として保持しやすいという。
				具体的なものは、実世界の中で、目で見、耳で聞くものである。
				抽象的なものは、ヒトの頭の中でのみ存在するものである。
				具体的なものは、日常の活動で触れる。
				視覚、聴覚、触覚、体性感覚、脳・神経系という身体の各部位で、理解している対象である。
				一方、抽象的なものは、ある程度の社会的な訓練ののちに、理解できるものである。
				大脳皮質以外に、理解している部位はないのではないだろうか。
			</p>
			<p>
				コンピュータという道具を使って行うことは、ハサミのような具体性がない。
				いくつかの抽象的なステップをたどる。
				行う操作は、ハサミのように、結果がすぐに出るのではない。
				さらに、結果は、電子的な変化に過ぎず、具体的に見えない場合もある。
			</p>
			<p>
				ドナルド・ノーマンは、行為は7段階の手順を踏むと分析した（<a href="#rDN">[rDN]</a>）。
				「(1) ゴールがまずある。(2) 実行しようという意図が起きる。(3) 行為系列へ展開する。(4)行為系列を実行する。」 => 外界を操作し、結果が返る
				=>「(5) 外界の状態を知覚する。(6) 知覚したものを解釈する。 (7) 解釈を評価する。」 => (1)へ戻る。
			</p>
			<p>
				<div align="center">
					<img width=25% src="seven_steps_of_action.png"> 
					<p><a href="#rDN">[rDN]</a>より</p>
				</div>
			</p>
			<p>
				コンピュータを使う場合に当てはめてみる。
				行為系列へ展開する(3)がコンピュータ寄りで、ヒトの日常の概念より抽象的である。
				また、結果も抽象的なので、(6)の結果の解釈の段階も、抽象的である。
			</p>
			<p>
				例えば、スマホの通知が鳴ったり鳴らなかったり、変えようとするところ、(1)、(2)は明確である。
				鳴ったか鳴らないか、(7)も明確である。
				一方、どうすれば鳴ったり鳴らなかったりを変更できるのかの(3)が、コンピュータの操作のための概念を理解していないと難しい。
				また、どういう設定になっていればどうなるかを確認する(6)も、コンピュータの操作概念を理解していないと難しい。
			</p>		
			<p>
				こういう抽象的な過程は、どんなユーザーインターフェイスをかぶせても、ヒトには記憶しにくい。
				それらの組み合わせを理解するには、認知負荷がかかる。
			</p>
		</details>

		<details open><summary><strong>理想的な道具とは、誰でもすぐに目的達成できること</strong></summary>
			<p>
				現在のコンピュータは、理想的な道具なのであろうか？
			</p>
			<p>
				ドナルド・ノーマンは、スニーカーのマジックテープを技術の進歩のお手本とした（<a href="#rDN">[rDN]</a>）。
				ヒトは、靴の紐を結ぶという習慣に慣れていた。
				マジックテープがでてから、それは一瞬の簡単なことに変わった。
				障がい者、子供も、マジックテープの恩恵を受けた。
				また、自動運転は、別のお手本である。
				車の運転は、手段である。
				目的は、ある場所へ移動することである。
				自動運転は、苦痛なく、目的達成を果たしてくれる。
			</p>
			<p>
				目的とは何か。
				ドリルを買う人は、ドリルが欲しいのではなく、穴が欲しい。
				PC が欲しいのは、PC自体が欲しいのではなく、PCでできるきれいな文章作成できるから。
				またスプレッドシートにパスワードをメモして保存しておけるから。
				スマホが欲しいのはいつでもどこでも情報を検索できるから。
				スケジュールをいつでも変更したり参照したりできるから。
			</p>
			<p>
				道具は、抵抗なく受け入れられ、かつ、中間でない最終目標を達成できることが、理想である。
				コンピュータは、道具として、利用するのに認知負荷があり、理想ではない。
				また、目的達成の中間の手順を、ユーザに強いるので、理想ではない。
			</p>
		</details>
	</div>

	<div><h3>4.2 ユーザ・インターフェイス</h3>

		<details open><summary><strong>目と手指での操作</strong></summary>
			<p>
				日常的なコミュニケーションを含め、ヒトはそもそも、いろんな知覚を総合して環境とやり取りをしている。
				そして、ヒトが視覚的動物であるといわれるように、主に視覚を使っている。
				現在のコンピュータ・ユーザ・インターフェイスにおいても、情報の入手はもっぱらモニターを目で見ることで行われている。
				他方、情報の生産は、ほぼ手で行っている。
				テキストをディジタル的に生産するときも、コンピュータに指示（コマンド）するときも、指を使う。
				位置指定・対象選択も、指で行う。
			</p>
			<p>
				手は器用である。目と親和性が高い。
				手で操作し、目でモニターする、ということに慣れてきた。
				そのためコンピュータの時代でも、その延長上にいる。
				コンピュータは、エリートが知能を拡張するための道具として利用されてきた。
				エリートには、目と手指だけのインターフェイスでも、すぐに慣れて、苦痛ではない。
			</p>
			<p>
				石井裕は、マウスとモニターだけで、人がサイバー空間に触れないのは、情けないと言った(<a href="#rIY">[rIY]</a>)。
				しかし、それは道具が未熟ということに過ぎない。
				そういった道具を使う人の能力の面から見ると、目と手指だけでサイバー空間とやり取りすることが、情けないのである。
			</p>
		</details>

		<details open><summary><strong>人の能力を生かしていない</strong></summary>
			<p>
				グラフィカル・ユーザー・インターフェイスは、ヒトの身体能力を生かしていない。
				<ul>
					<li>
						ヒトの大脳皮質の2/3は、諸情報を総合する連合野である（<a href="#association_area">[人は総合する動物]</a>）。
						ヒトは感覚や運動を特定の部分に頼って生活してはおらず、総合して環境に対処している。
						指と目だけのインターフェイスは、不自然に限定されたものである。
					</li>
					<li>
						手指は、ヒトの体によって器用さを得て（<a href=#body_supports_hand>[身体と視覚が手指の器用さを支えている]</a>）、
						多様な器用さを発揮できる（<a href="#hand_dexterity">[手指は器用]</a>）。
						しかし、手の一部の機能しか利用していない。
					</li>
					<li>
						手は、機械動作するため、遅い（<a href="#fitts_law">[距離の制約]</a>）。
						言語生産（<a href="#text_productivity">発声のテキスト生産速度は指の5倍</a>）とか、
						注目を示したり（<a href="#fast_eye_sight">[視線は速い]</a>）とかの動作に関しては、遅い。
					</li>
					<li>
						ヒトは、視聴覚融合して考える（<a href="#言語の発生">[言語の発生]</a>）のに、耳は遊んでいる。
					</li>
					<li>
						ヒトは3次元の住民なの（<a href="#three_d_space">[2次元と3次元]</a>）に、
						2次元の光る画面を相手に、コンピュータを操作する。
					</li>
					<li>
						ヒトの小脳（<a href="#小脳は所作の匠">[小脳は所作の匠]</a>）とはかかわらない。
					</li>
				</ul>
				コンピュータのグラフィック・ユーザ・インターフェイスは、目と手指での特定の機能に頼りすぎ、いびつである。
			</p>
		</details>

		<details open><summary><strong>コンピュータのユーザインターフェイス設計は、制約が少ないため、難しい</strong></summary>
			<p>
				コンピュータのユーザ・インターフェイスをデザインするのは、水道の蛇口やドアのノブのデザインとは、かなり異なる。
				コンピュータは計算という目に見えない抽象的なレベルで動くからである。
				抽象的な操作によって、抽象的な結果を返すので、ヒトはそれに慣れなければならない。
				どういう操作オプションを提供し、どういう結果提示をすればよいか、それらをデザインするのはアートである。
			</p>
			<p>
				ドナルド・ノーマンによると、日常生活の道具は、物理的な制約、論理的な制約、社会・文化的な制約、意味的な制約などによって、
				操作できることが絞り込まれていると（<a href="#rDN">[rDN]</a>）。
				<ul>
					<li>
						物理的な制約とは、例えば、あるプラグはその形状にあったコンセントにしか差し込めない。
						大きな突起は小さな穴に差し込めない。鍵は鍵穴に上下逆さに入れると回らない、などである。
					</li>
					<li>
						社会的文化的な制約とは、ネジは時計回りに回すと締り、逆回しにすると緩む。
						車の右側のサイドランプを点灯すると右へ曲がると言う印になる。
						時計の1時と2時の間の時間は、2時と3時の間の時間と同じ長さである、などである。 
					</li>
					<li>
						論理的な制約とは、棒を右に倒せば対面した相手からは左に倒すことになる。
						電灯は点灯しているか消灯しているかのいずれかである。
						飛行機の到着時間は、出発時間のあとである、などである。
					</li>
					<li>
						意味的な制約とは、りんごは歩かない。 オートバイに乗る時に前方は決まっている、などである。
					</li>
				</ul>
				一方で、コンピュータのユーザ・インターフェイスは、意味的・論理的な制約くらいしか、利用できない。
				抽象的な世界（コンピューターを作っている人の頭の世界、コマンド用語）の中で、
				必ずしもコンピュータを理解していないユーザ向けにデザインしなければならないとき、利用できる制約が少ない。
				非常に難しい領域である。
			</p>
		</details>

		<details open><summary><strong>アイコンは非力</strong></summary>
			<p>
				現在、グラフィカル・ユーザ・インターフェイスが主流である。
				グラフィカル・ユーザーインターフェイスの、物理的に見える操作の側面は、わかりやすい。
				操作は、マウスやタッチで行う。
				マウスは、動かすとカーソルが動き、操作と結果の対応が明確である。
				マウスカーソルを対象の上でクリックすると、対象が選択され、それも操作と結果が明確である。
				タッチは、手が届く範囲内ならば、カーソルを動かすという手間がなく、対象選択が素早くできる。
			</p>
			<p>
				一方、グラフィカル・ユーザ・インターフェイスの表示は、メニューとともにアイコンを多用する。
				アイコンは、視覚的な象徴である。
				[<a href="visual_symbol">象徴を認識できる</a>]でみたように、視覚的な象徴は間接的である。
				水道の蛇口やドアのノブにはあった、何ができるかを示す支持機能が、弱い。
				グラフィカル・ユーザ・インターフェイスでは、そういうアイコンを対象として操作する。
			</p>
			<p>
				当初は、デスクトップ・メタファーと言って、デスクにあるペン、文書、ファイルキャビネットなどを図示するという発想があった。
				しかし、機能が、豊かになり、拡大するにつれ、物理的なものから離れた抽象を表現しなければならなくなった。
				インスタグラムを意味する絵って何だろう？　
				具体的な対象を示す非言語イメージは、記憶に残りやすいという（<a href="#rCP">[rCP]</a>）。
				しかし、具体を離れたイメージは、曖昧で記憶しにくい。
			</p>
			<p>
				現在のスマホのホーム画面のアイコンのラベルがもしもなかったとしましょう。
				使えるだろうか？ アプリのアイコンは、ラベルで説明を追加していなければ、利用するのは無理である。
				アイコンという象徴は、何ができるかを示す表現手段としては非力である。
				グラフィカル・ユーザ・インターフェイスは、こういった基本的な問題を持つ。
			</p>
		</details>

		<details open><summary><strong>内部の抽象を露出させている</strong></summary>
			<p>
				うまくアイコン経由でアプリを起動できたとする。
				内部の機能を見てみよう。
				電話アプリ、スプレッドシート、地図アプリ、ワードプロセッサ、電卓アプリなど、対象が豊かで明確な意味を備えている。
				そういうアプリは、できることもわかりやすい。
				やったことが目に見えて返ってくる。
				ショートメッセージ、ニュースアプリなど、ユーザの意図が明確で単純なアプリも、わかりやすい。
				例えば、高齢者が初めてスマホを使い始めた時、他に何もできなくても、電話アプリは使える。
				昔の黒電話、ガラケーの電話アプリ、で、概念モデルがしっかりとあるからである。
				数字パッドを打つと、ツーツーと音が鳴り、相手が出る、ないし「つながりませんでした」とくる。
				操作も知っているし、結果もすぐに出て、明確である。
			</p>
			<p>
				しかし、そういう利点を持たないアプリ、提供機能自体がほぼ抽象的なものも多い。
				それらは、コンピュータ特有の抽象的な用語でしか説明できない。
				例えば、スプレッドシートで、ユーザがやりたいのは表計算である。
				そのファイルを上書き保存や、名前を付けて保存というのは、なにか？
				表は、後で取り出せさえすれば、ユーザにとっては、保存方法など詳細は、どうでもいいことである。
				ファイル・フォルダー体系というコンピュータの概念を、ユーザに押し付けている。
				目的以外の抽象概念を、そのままユーザに見せている。
				機能が抽象的な場合、その結果も抽象的である。
				それもそのまま見せている。
				そして、抽象的なことと抽象的なことの対応関係は、なおさら抽象的である。
			</p>
			<p>
				石井裕も、「いまのパソコンのユーザー・インターフェイスは抽象化しすぎである」と言った(<a href="#rIY">[rIY]</a>)。
				そこから、情報という見えない存在を、環境の具体的なものを通して表現する、というタンジブルビッツという考えに至った。
				しかし、そういった抽象的な存在は、ヒトに表現されてほしいものだろうか？　
				ヒトがドリルを買うとき、欲しいのは、ドリルではなく、穴なのである。
			</p>
		</details>

		<details open><summary><strong>メニューは掃きだめ</strong></summary>
			<p>
				[<a href="#magical_number">短期記憶は4個まで</a>]でみたように、3個か4個までであれば、認知負荷が小さい。
				メニューは、機能が多いときに詰め込む、いい掃きだめになっている。
				メニューの項目が、PCの一画面の底まで並んでいることは珍しくない。
				しかも、メニューの用語は、多くの場合、コンピュータエンジニアの用語である。
				また、コンピュータ内部の抽象的な用語である。
				あるいは、ユーザがめったに使わない。
				あるいは、ユーザがやりたいこと以上に、ユーザに見つけてほしい広告的なメニュー項目だったりする。
				メニュー、つまりあるアプリでできることに関して、デザイナーはユーザに必要なことだけに絞り込むことに多くが失敗している。
			</p>
			<p>
				しかも、メニューは、簡単に項目数が増える。
				メニューは、別メニューを項目として持つこともある。
				こうして、ヒトがやりたいことを実行するのに、広くて深い探索空間を相手にすることになる。
				理想は、狭くて浅い選択肢のみであってほしいのに。
			</p>
		</details>

		<details open><summary><strong>複雑になりすぎた</strong></summary>
			<p>
				グラフィカル・ユーザ・インターフェイスは、ヒトの概念的な構築物である。
				時間を経て発展するうちにどんどん複雑になる。
				スマホが登場したとき、当然、グラフィカル・ユーザ・インターフェイスが応用された。
				広い画面のユーザーインターフェイスが、小さい画面のものへと変化し、マウスはタッチという直接操作へ変わった。
				しかし、グラフィカルユーザーインターフェイスをもとに、その進化を重ねたため、複雑さはそのまま、ないし、より増した。
				対応関係が複雑怪奇となった。
				地図アプリを開き、スクロールしたり、つまんで広範囲を表示したり、など、ユーザのジェスチャー操作と操作対象の反応が
				直感的に対応している場合は、いい。
				が、そういう直感的な対応ができることばかりではない。
				一つの操作で、複数の意味がある。
				例えば、タップは、アプリの選択＋起動であり、項目のタップは選択＋メニューの起動でもあり、
				入力フィールドの選択でもあり、などなど。
				一つの意味なのに、その操作は複数ある。
				例えば、スマホでアプリを削除するのはアプリアイコンを長押ししてから行う。
				しかし、写真ギャラリーで写真を削除するには、タップして行う。
				ドナルド・ノーマンの言う、機能の数がスイッチの数を超えている状態である。
				慣れない人が慣れるのは至難である。
			</p>
		</details>

	</div>

</div>

<div class="pagebreak"><hr><h2>5. 操作からコミュニケーションへ</h2>

	<div><h3>5.1 コミュニケーションモデル</h3>
		<details open><summary><strong>操作からコミュニケーションへ</strong></summary>
			<p>
				コンピュータは、道具の一つである。 
				ヒトは、道具を操作する。
				対象を目で把握し、道具を手で操作し、結果を目でモニターする。
				しかし、コンピュータは、操作される道具として、あまりにも具体性がなく、抽象的である。
				そのため、人側に、認知負荷がかかる。
				コンピュータが、エリートの知能拡張の道具という役割ならば、それでもかまわない。
				エリートは、すぐに使いこなせる。
				しかし、コンピュータは、万人が使うものになった。
				コンピュータは、ヒトとの関係で、モノ道具を操作するという関係性ではなく、
				コミュニケーションの相棒という関係性を持たせたほうがよい。
			</p>
			<p>
				操作ではなく、ヒト相手のコミュニケーションをモデルとしてみた場合、コンピュータの道具としての要件が変わってくる。
			</p>
			<p>
				ヒトは、身体のしぐさの一つとして、音声で言語表現する。
				それは、日常的な用語で、意図を表現する。
				ヒトとコミュニケーションするとは、ヒトの意図レベルでやり取りをするということである。
				ヒトの脳だけで構築された抽象的なコンピュータ特有の中間概念は、そもそも不要である。
				ヒトが、電気ドリルを買うとき、欲しいのは穴であり、電気ドリルではない。
				コンピュータの内部の抽象的な概念をそのままさらすのでなく、ヒトの意図した目的の水準で、ヒトとやり取りする。
			</p>
				人が意図をコンピュータとやり取りするとき、その関係は、ヒトが手と目だけで操作する一方的な関係でない。
				ヒトは連合野で考え、行動する。
				環境に対し、五感を総合して、反応する。
				ヒトは、環境を認知し反応するために、精緻な全身能力を進化させてきた。
				機械・道具のほうも、ヒトの生得的な身体能力を尊重するのが自然である。
				ヒトの能力をあるがままに引き出し、ヒトの発する身体からの言語を受け止め、反応するのが自然である。
				ヒトの身体に反応するとは、機械側がヒトの口振り（発話）、目振り（注目）、身振り・手振り、表情を、受け止め、やり取りすることである。
				コンピュータ側が、ヒトの身体性を含めて設計されるべきである。
				これは、ヒトの生得的な身体能力を、インターフェイスにすることである。
			</p>
			<p>
				それでは、コンピュータは、もっとハイテクでないといけないか？ 
				そうではない、すでに技術はある。
				音声ユーザー・インターフェイスの普及が鍵である。
				口振りに反応するとは、機械側がヒトの音声を認識することである。
				また、ヒトの音声言語は、日常的なレベルで意図を表現する。
				意図表現は、一見、曖昧に見える。
				音声認識で、アプリが組めるのか?
				組み方を変えればいいのである。
				すでにある技術を、ちょっと視点を変えて、デザインをすればよい。
				さらに、身振り、目ぶり、手振りに反応するとは？
				ヒトの身振り、目ぶり、手振りは、日常的な意図を表現し、コンピュータに構築された抽象的な概念階層とは無縁である。　
				コンピュータに、目と耳をつければよい。
				また、スマホはカメラとマイクを持つ。
				モニター付きスマートスピーカーもある。
				目と耳を持つ、サービスロボットあるいはコミュニケーションロボットもある。
				すでに、ハードのパーツはある。
				掃除ロボットに目をつけて、ヒトがあっちを掃除してと指示することは、今でも実現できる。
			</p>
		</details>
	</div>

	<div><h3>5.2 音声による意図表現の利用</h3>

		<details open><summary><strong>意図レベルのやりとり</strong></summary>
			<p>
				ヒトとコンピュータが、道具を手と目で操作するという関係でなく、相棒とコミュニケーションするという関係モデルでは、
				音声が重要な役割を果たす。
			</p>
			<p>
				音声言語は日常生活空間で使われるため、意図を自然に表現できる。
				一見、曖昧と見える部分は、話す相手や周囲の状況などのコンテキストで、実は明確である。
				ヒトの意図は、周りのコンテキストがあれば、言語音声に自然に表現されている。
				コンピュータは、それを利用すべきだ。
				グラフィカル・ユーザ・インターフェイスで、やりたいことを満たすアプリを選ぶのは、視覚的象徴経由である。
				間接的で、意図を伝達するにしては、最適ではない。
				絵を見て、何を意味するのか想起して、アプリの機能を想起する、複雑な認知過程が必要となる。
				一方、音声だと、意図を、日常語彙で、直接、表現できる。
				音声で意図を伝え、それに加えて質問などによるやり取り、インタラクションを利用して、意図解釈をする。
				音声ならば、意図がすでに包含されているので、道具のほうで何ができるかを示すための設計というのが不要である。
				音声認識で意図を表現し、コンピュータがそれを解釈すれば、ドナルド・ノーマンの行為7段階説で行為系列への展開という部分がなくせる。
				また、結果も意図のレベルに合わせれば、結果の解釈という中間段階も消せる。
				ヒトは意図を表現し、結果を評価する。
			</p>
		</details>

		<details open><summary><strong>視聴覚融合</strong></summary>
			<p>
				コンピュータが、ヒトの身体の動作である口振りに反応しようというのが、音声認識である。
			</p>
			<p>
				スマートスピーカーが出て、音声だけでやり取りするアプリが試されている。
				スマホの音声アシスタントもある。
				いずれも、当初、音声のみのユーザーインターフェイスを目指していた。
				その後、画像情報も援用するようになってきた。
				そもそも、人は<a href="#association_area">「連合野」</a>で行動する。
				ヒトが環境に対するとき、複数の感覚と効果器を総合して、機能する。
				とりわけ、人の言語は<a href="#言語の発生">「言語の発生」</a>にみたように、発生からして視聴覚が融合している。
				音声のみのユーザーインターフェイスは、初めから不自然であった。
			</p>
			<p>
				無理に音声のみのやり取りでアプリを組もうとしても、以下の欠点が出る。
				<ul>
					<li>モードの制御がやりにくい。
						<br>音声のみだと、音声をコンピュータに聞かせている状態なのかそうでないのかの区別ができない。
							また、コマンドなのかテキストなのかの区別ができない。
							そういった区別状態のことをを、IT用語ではモードという。
							音声のみでは、モードの制御がやりにくい。
							「OK Google」とか、「Hey Siri」とか言って、音声をコンピュータに聞き取らせるのを始めるが、不格好である。
							聞き取ったことに対し、音声で返すしか手段がないとすると、アプリも作りにくい。
							音声をコンピュータに聞き取らせるのは、マイクの絵をたたいて始めるほうが自然である。
							またコンピュータが聞き取ったよというフィードバックも、視覚的な反応もあったほうが、アプリは組みやすい。
					</li>
					<li>音声のみでは、そもそも空間内の位置指定ができない。
						<br>
							ヒトは、指差しや、マウスやで、空間の位置指定を容易に行うことができる。
							しかし、それを音声でやるとなると、あいまいな指示か、相当冗長な指示しか表現できない。
					</li>
					<li>ボリューム調整など、アナログ量の制御が苦手である。
						<br>
							アナログ量は、空間的な概念である。
							指つまみで簡単に指定できるボリューム量などは、音声言語で制御するのは難しい。
					</li>
					<li>構造的な情報を扱うのが困難。
						<br>
						視覚は複数個の並列処理ができる。
						一方、聴覚は逐次情報を対象とし、
						一度にたくさんことを相手にすることは苦手である（<a href="#anti_structure">[聴覚認知は構造保持が苦手]</a>）。
						構造は複数の要素と関係性からなる。
						構造的な情報を扱うのは音声＋聴覚は苦手である。
						例えば、フライトを予約したい。
						日時を指定する、人数を指定する。出発場所と到着場所を指定する。
						その上で、値段込みの選択オプションを検索したい。
						それら関連した情報をコンピュータに指定する過程で、ある時点までに何の指定を済ませたか、何がまだなのか、
						を意識していないと、情報の支持がやりにくいであろう。
						すでに指定したものは、画面上で、目に見えておいてほしい。
					</li>
					<li>多数からの選択が困難。
						<br>
							上記と同じ理由で、2、3個以上の選択肢がある場合、視覚的な補助なしに選択を行うことは困難である。
					</li>
					<li>同音語で困難。
						<br>
							例えば、音声による言語表現では、コンピュータのほうに、キーボードのような選択・修正UIが完備されていない。
							そのため、人名入力や地名入力など同音語が多く、表記を選ぶ必要があるケースでは、コンピュータが音声だけで同音語を識別するのは難しい。
					</li>
				</ul>
			</p>
			<p>			
				こうして、音声のみでコンピュータを操作しようとしても無理である。
				音声は意図を表現する。
				その水準でアプリを組もうとしたら、実は、指によるコントロール・空間指示と、視覚による構造把握と、併用せざるをえない。
				ヒトは、そもそも特定のチャネルに限定せずに、連合野でコミュニケーションする。
				同様に、ヒトのパートナーたるコンピュータも、複数のチャネルを融合して、人とコミュニケーションすべきである。
				視聴覚融合で、一歩、自然なユーザー・インターフェイスに近づく。
			</p>
		</details>

		<details open><summary><strong>音声アプリも支持と制約を利用すればよい</strong></summary>
			<p>
				音声でのやり取りは、意図レベルでのやり取りである。
				それは、ヒトの身体レベルのやり取りである。
				ヒト同士のコミュニケーションに近い。
				すると、高度なテクノロジーを使わないとできないのでは？
				そうではない。
			</p>
			<p>
				ドナルド・ノーマンによれば<a href="#rDN">[rDN]</a>、
				日常的な道具は、アフォーダンス（支持、何ができるかをヒトに示す）、制約、概念モデルを利用しているという。
				例えば、はさみの穴は指を入れる場所を示し、指を入れることを支持（アフォード)している。
				穴の大きさは、1本指を入れるという制約を課している。
				ハサミは、二つの刃が交わって紙などを切るという仕組みが目に見えているため、
				何をする道具なのかというハサミの概念モデルは、ヒトにとっては容易に理解できる。
				アフォーダンスは何ができるかを示し、制約は選択肢を制限する。
				アフォーダンスと制約があり、概念モデルが明確であるために、
				生活の中に無数に道具があって使い方を丁寧に教わらなくても、ヒトは使えるのだと。
			<p>
				コンピュータのグラフィカル・ユーザ・インターフェイスでは、見えているものが、手での操作の支持であり制約となる。
				キーを下に押し下げること自体は、何のための動作か曖昧である。
				しかし、Aと刻印されたキーを押し下げることは、Aの言語表現として、曖昧性がない。
				そして、ヒトは、キーボードを見るとキーAがどこにあるかをすぐに思い出すので、素早くキーボードを操作できる。
				また、グラフィッカル・ユーザ・インターフェイスでは、メニューや画面遷移というコンテキストがある。
				そのために、ある対象をクリックして選択することの意味には、曖昧性がない。
				そのように、視覚情報やコンテキストによって制約されて、手指動作の曖昧性がなくなる。
				そのような曖昧でない動作を前提に、アプリが編み上げられる。
				アプリが組みやすいのである。
			</p>
			<p>
				音声による言語表現は、グラフィカル・ユーザーインターフェイスと同様に、
				メニューや画面遷移や問い返しという、視覚やコンテキストによる支持と制約を利用すればよい。
				同様な制約を利用すれば、曖昧性をなくすことができ、アプリの構成要素にできる。
				視覚やコンテキストによる支持と制約を利用するというデザインをとれば、音声による意図レベルの表現に曖昧性はない。
				視覚が得意なことは視覚に任せる。
				手指が得意なことは、手指に任せる。
				音声が得意なことは音声に任せる。
				特定の単純なタスクでは、音声対話システムが実用されている。
				もっと複雑なアプリも、このようなデザインの考え方で、実現できる。
			</p>
			<p>
				また、今のコンピュータがさらしている、抽象的なコンピュータ内部概念群は、意図レベルでやりとりすることで、
				より隠巣ことができる。無駄に複雑な概念のモデルとは離れられる。
				意図レベルの機能的な概念モデルは明らかだろう。
			</p>
		</details>

		<details open><summary><strong>音声ワープロ？</strong></summary>
			<p>
				「<a href="#cognitive_interference">マルチタスクは事実上不可能</a>」のところで見たように、
				ヒトは、考えながらしゃべるのは難しい。
				そのため、音声認識は使えないという考えがある。
				しかし、一瞬考えて、それをしゃべる、それを繰り返す、という時分割なら、うまくできる。
			</p>
			<p>
				そもそも、ヒトにとって言語は、視覚的でありかつ音響的である。
			</p>
			<p>
				<a href="#text_productivity">[発声のテキスト生産速度は指の5倍]</a>なため、
				音声を使うと、文書を作成する時間が短くできるという誤解もある。
				しかし、文章を考えるのは熟考が必要なので、実は
				音声言語表現は、文書作成の時間を短くしない。
				しかし、アイデアを素早く完全な形で記録する。
				そして、たとえ誤認識でノイズが多くても、文であるため、後で編集するときに、想起しやすい。
				それで、音声でスケッチした後の文書作成はやりやすい。
				音声言語表現は、頭の中にある整理されていないモヤモヤした概念を、忘れないうちに、目に見える形で取り出して、
				編集可能な形にし、考えを発展させられるようにするための手段である<a href="#rNY">[rNY]</a>。
				音声を一度視覚的なテキストとして保存してしまえば、それは外部の記憶となる。
				外部の記憶として何回でも再認できるので、じっくり構成・構成する素材となる。
			</p>
			<p>
				このように、音声表現を介在させて、視覚的言語を生産するのは、効率的なのである。
			</p>
		</details>

	</div>

	<div><h3>5.3 注目を利用する</h3>

		<details open><summary><strong>注目は重要な制約</strong></summary>
			<p>
				ヒトは、視線で注目する。
				ヒトは、指さしで、注目対象を示したりする。
				このような注目行動は、コミュニケーションの中で、意図を解釈するときの重要な制約となる。
				コンピュータが、ヒトとコミュニケーションするとき、この制約を利用しない手はない。
			</p>
		</details>

		<details open><summary><strong>視線は操作手段ではない</strong></summary>
			<p>
				ヒトの視線は速い（<a href="#fast_eye_sight">[視線は速い]</a>）。
			</p>
			<p>
				このために、視線をマウスカーソルとして使おうという発想があった。
				視線を追跡することで、位置指定の操作手段として使おうと。
				手指が動かせないハンディを持ったユーザでも、目を動かせられるヒトはいる。
				そういうヒトのための表現手段となる。
				また、健常者でも、指とマウスは指の機械的速度と距離に制約されるが、視線は素早いので距離に束縛されない。
				そこで、ゲームの発射コマンド、画面の位置選択などに利用されたことがある。
			</p>
			<p>
				しかし、ヒトの目は受容器官としての役割で進化したものである。
				それを無理に操作手段として使うと、以下の不具合が出る。
				<ul>
					<li>
						受容器官としての動き以外の動きを期待するのは、ユーザに不自然な動作を強いることになる。
						不自然な動作は、疲労に導くし、慣れるまで学習を要する。
					</li>
					<li>
						また目だけを操作手段とすると、位置指定という視線を使った操作なのか、単に探索しているための目の移動なのか、
						状態の区別を機械に伝えるのが難しい。
					</li>	
				</ul>
			</p>	
		</details>
		
		<details open><summary><strong>視線は注目を示す</strong></summary>
			<p>
				目に効果器としての役割を求めるのでなく、進化してきた受容器のまま生かすべきである。
				視線は、空間的な注目箇所を示す。
				また、視線は、コミュニケーションにおいて「まなざし」として、情緒的な情報を伝える重要要素である。
				動物でさえ、まなざしで意思を伝える。
				機械から見れば、ユーザの意図を受け取る際に重要な情報となる。
				知能を持つ機械にとっての、制約をヒトが与えるのである。
				例えば、以下のようなユース・ケースがありうる。
			</p>
			<p>
				<ul>
					<li>
						スマホでニュース記事を読んでいる。
						画面上部のテキストを読みつつ、下にスクロールするため画面下部の画面に触れる。
						たまたま指が触れたところに、広告枠が表示されていた。
						画面が切り替わり広告が表示されて、びっくりする。
						この時は、意図はスクロールである。
						もしも、広告を見ながら、そこに触れたなら、広告に興味を持ったのである。		
					</li>
					<li>
						画面に連絡先の人物の写真がいくつか表示されている。
						視線を追跡することで、きょろきょろしているかどうかで、ユーザが現在探索中かどうかが推定できる。
						探索中ならば、探索を助けるように反応する。
						視線がある連絡先に注目し、停留したならば、この連絡先を選択するかと返す。
					</li>
					<li>
						部屋にいくつか電化製品がある。
						あるいはPCがあり、いずれかが目と耳を持っているとする。
						その時、エアコンを見ながら、「つけて」といったら、エアコンをつけるという意図である。
						部屋の明かりをつけるという意図ではない。
					</li>
				</ul>
		</details>
	</div>

	<div><h3>5.4 ジェスチャー</h3>

			<details open><summary><strong>ジェスチャーはコミュニケーションの一部である</strong></summary>
				<p>
					表情、身振り、手振りは、重要なコミュニケーション手段である。
					ヒト画像から、それらを読み取るのは、すでに実現できている。
					音声による言語表現と総合して意図を読み取るのは、技術的にもう可能である。
				</p>
				<p>
					掃除ロボットに目をつけて、ヒトがあっちを掃除してと、指差しで、指示する。
					実三次元世界という物理的な存在があると、意図の解釈を助ける制約が増える。
					例えば、ヒトがここにいて、「あっち」と指さしたら、そっちのエリアである。
					コンピュータが、このように、ヒトのジェスチャーを見るように変われば、ヒトはコンピュータと、実三次元世界で豊かなコミュニケーションができる。
					コンピュータは、二次元のモニターでなく、三次元の実世界の中で、ヒトの身体まるごととやり取りをする。
				</p>
				<p>
					コンピュータが、目と耳を持ち、ヒトと視聴覚でやり取りする。
					さらに、ヒトの身体を包む三次元で、やり取りをする。
					コンピュータにとって、ヒトは大脳皮質の抽象物の中で概念をこねくり回す主では、なくなる。
					小脳、脊髄を含む脳神経系と身体を持った主となる。
					それを想像すると、コンピュータがどう反応すべきかが、全く変わってくる。
					技術の進歩の方向が変わる。
				</p>
			</details>

	</div>

</div>

<div class="pagebreak"><hr><h2>6. まとめ</h2>

	<details open><summary><strong>コンピュータのデザインを変える</strong></summary>
		<p>
			ヒトは、ほかの道具同様に、コンピュータを操作してきた。
			当初、コンピュータはエリートの知能の拡張のための道具だった。
			そのため、ヒトとコンピュータの間のインターフェイスの負荷は、問題視されなかった。
			しかし、万人がコンピュータを使う時代になった今、インターフェイスが変わらないといけない。
			ペルソナに沿ったインターフェイスであるべきである。
		</p>
		<p>
			ヒトがヒトとコミュニケーションするかのように、コンピュータとやり取りしたい。
			意図のレベルでやり取りする。
			コンピュータがヒトの発話や身体動作を意識する。
			そうすれば、ヒト側の認知負荷とストレスはなくせる。
		</p>
		<p>
			しかし、それを実現するのに、新しい技術開発やハイテクが必要かというとそうではない。
			すでにある技術で十分に実現できる。
			問題は、システムやアプリをデザインするときの考え方である。
			目と手でのインターフェイスという過去からの延長で考えるのでは、課題が先鋭化する。
			そうではなく、音声と視覚を融合したデザインを最初から目指すべきである。
			音声での意図解釈も、グラフィカル・インターフェイズと同様にコンテキストや制約を利用すれば、
			アプリを組むに足る曖昧性のないパーツになる。
		</p>
		<p>
			また、スマホ、モニター付きスマートスピーカー、サービスロボットあるいはコミュニケーションロボットなどは、目と耳を持つ。
			すでに、ハードのパーツはある。
			それらを利用して、ヒトの目振り、身振り、手振りなども感知し、
			実三次元の制約も利用して、ヒトの意図を三次元の身体込みで解釈する。
		</p>
	</details>

	<details open><summary><strong>仮想現実・メタバースとドラえもん</strong></summary>
		<p>
			頭部にディスプレィを装着し、現実にサイバー世界を重ね合わせたり、
			仮想的な世界にいるかのような臨場感を持たせる技術がある。
			サイバー空間で得られるリッチな世界を、自分の身体と一体化したかのように感じさせる。
			ヒトの身体を、仮想的な世界に取り込む、ようなことである。
			人の脳は可塑性があるので、そういう技術にヒトが慣れたら、どんなことが起きるか、想像できない。
			ただ、こっちの方向は、エリートの知能の強化の線、頭でっかちの路線のような気がする。
		</p>
		<p>
			一方、現実の世界と、その中の生身のヒト身体は、またリッチな世界である。
			ヒトの身体と脳神経は、生物の進化の結果である。
			そこを生かすことは、十分開拓されていない。
			それを生かし、意図レベルで、生世界で、ヒトと会話をし、生活する存在は、ドラえもんである。
			ドラえもんが誰にとってもパートナーになったら、どんなことが起きるかわからない。
			人は社会的動物で、生まれて以降の社会的教育で、脳内のいろんな神経をつなぐ。
			実世界のパートナーであるので、大脳皮質だけのパートナーではなく、脊髄や小脳レベルでも付き合うことになる。
			そこのパートナーがドラえもんだ。
			ワクワクしないだろうか？
		</p>

	<details open><summary><strong>人体を拡張する</strong></summary>
		<p>
			ヒトの脳・神経は、環境とのやり取りで、生物として、受容・効果器官との協同作業のために進化した。
			そのしくみは、未知なことが多い。
			一方、脳に直接機械・道具を接続することで、道具を自在に操ることが、昔から夢見られてきた。
			脳に直接機械・道具を接続したり、脳の信号を直接解読しようとする技術を、BMI、ブレーン・マシン・インターフェイスという。
		</p>
		<p>
			一方、大脳には可塑性（<a href="#brain_plasticity">［脳の可塑性］</a>）という特質がある。
			つまり、生得の知能よりは、生まれた後で学習して得る知能のほうが、圧倒的に大きい。
			手に第6の指というのを装着し、腕の筋肉の動きでコントロールするように、少し訓練すると、
			自分の体の一部であるかのような感覚で、動かせるという。
			大脳の可塑性のおかげで、人の生体機能さえも機械を使って拡張(進化)できる。
			脳に直接接続するのが近道になるかわからない。
			脳は身体とともに進化してきた。身体から切り離して機会とつなげるよりは、
			むしろ、ヒトの身体と協調するという方向が現実的かもしれない。
		</p>
	</details>
</div>

</div> <!--End of TOC areas-->

<div class="pagebreak"></div><hr>
<h2>脚注</h2>
<details open><summary>注</summary>
<ul>
	<li id=n01>
		[n01] 別のソースでは、視覚は10の8乗ビット/秒、触覚は10の6乗ビット/秒、聴覚と嗅覚はそれぞれ10の5乗ビット/秒、味覚は10の3乗ビット/秒、とも言われる。
	</li>
	<li id=n02>
		[n02] これらに、厳密な根拠はないとも言われる<a href="#rKH">[rKH]。</a>
	</li>
	<li id=n03>
		[n03] gaを発音する唇を見せて、同時時にbaと言う音声を聞かせると、被験者は中間の調音位置をもった「da」を知覚する。
		これをMcGurk効果という。
		<a href="#rSO">[rSO]</a>
		聴覚情報は、知覚レベルになると視覚情報と融合、ないし引っ張られて、知覚される。
	</li>
	<li id=n04>
		[n04] 養老先生による<a href="#rYT">[rYT]</a>と、脳が大きくなったのには、手との相互作用ではなく、内在的な理由があるという。
				知覚系の末端となる脊髄神経細胞は、発生の段階では成人になったときに残る細胞数の数倍、余剰な細胞があるという。
				ヒト以外の動物では、支配している末梢領域を持たない神経は、間引かれるという。
				ヒトではそうでない。
				ヒトの脳が大きくなったのは、知覚に対応しない神経が、互いに接続して支配領域を自前で持ち、
				かつ、互いに、知覚以外から、入力しあう関係を持ったからだという。
				それが意識だと。
	</li>
	<li id=n05>
		[n05] コンピュータと人の情報のやり取りの観点では、
		コンピュータからの出力が知覚したり認知する対象となる。
		また、人からコンピュータへ情報を入力したりする。
		本文書では、コンピュータの入出力という言い方ではなく、ヒトを中心にした言い方をする。
		コンピュータに対して、ヒトは意図的動作をしたり言語表現をする。
		コンピュータからの情報を、ヒトが知覚し認知する。
	</li>
	<li id=n06>
		[n06] 養老先生は、視覚的言語と聴覚的言語の連合を、ヒトの大脳の接続でも解説する。
		ウェルニッケ中枢という聴覚的言語中枢がある。
		そこから、神経が伸びて、角回という視覚的言語中枢に入る。
		聴覚的言語中枢と、視覚的言語中枢との、双方から、神経が伸びて、ブローカ中枢という運動性言語中枢に入る。
		つまり、聴覚と視覚からの入力が、音響発生神経に接続している、と。
		ただし、最近の研究によれば、特定の言語機能はモジュール化されているのではなく、
		広範囲の神経ネットワークによって処理されているらしい、という（<a href="#rCP">[rCP]</a>）。
	</li>
	<li id=n07>
		[n07] 「心の理論」が生まれると、他個体の注意がどこに向いているかを意識できる。
		すると、たまたまそれが自己の身体に向かっているかも、意識できるようになる。
		他個体の心が注意を向けている「じぶん」という意識が、自己意識の源である。
		なお、チンパンジー、ゴリラなどは、鏡を見て自己認知できるという<a href="#rCP">[rCP]</a>。
	</li>
</ul>
</details>

<div class="pagebreak"></div><hr>
<h2>参考文献</h2>
<details open><summary>出典</summary>
<ul>
<li id=rBD>[rBD] Multimodal Interfaces: A Survey of Principles, Models and Frameworks、Bruno Dumas, Denis Lalanne, Sharon Ovian、2009. </li>
<li id=rBS>[rBS] The Limits of Speech Recognition. s.l. : Communication of ACM、Shneiderman, Ben、2000.</li>
<li id=rCL>[rCL] 「137億年の物語」（What On Earth Happendd?)、クリストファー・ロイド（Christopher Lloyd)</li>
<li id=rCP>[rCP] 「認知心理学」、箱田、都築、川端、萩原、有斐閣、ISBN978-4-641-05374-8</li>
<li id=rCW>[rCW] Multiple resources and performance prediction、Wickens, Cristopher D、 2002</li>
<li id=rDE>[rDE] 1968 “Mother of All Demos” by SRI’s Doug Engelbart and Team, https://www.youtube.com/watch?v=B6rKUf9DWRI </li>
<li id=rDN>[rDN] 「誰のためのデザイン？」（The Psychlogy of Everyday Things）、D.A.ノーマン、新曜社認知科学選書,1988</li>
<li id=rFJ>[rFJ] http://fujiidental.jp/clinic/archives/18 </li>
<li id=rFT>[rFT] 「生体情報システム論」、福田忠彦、1995、産業図書、ISBN978-4-7828-5303-0C335</li>
<li id=rHK>[rHK] 「視覚と聴覚はどうちがうか」、樋渡涓二（ひわたり　けんじ）、1997、NHK 第31巻第11号</li>
<li id=rHN>[rHN] 廣野守俊 永雄総一 小脳 脳科学辞典　https://bsd.neuroinf.jp/wiki/%E5%B0%8F%E8%84%B3 (2021)</li>
<li id=rIN>[rIN] 「図解・感覚器の進化 原始動物からヒトへ水中から陸上へ」、岩堀修明（いわほり・のぶはる）著、2011、講談社、ISBN978-4-06-257712-0</li>
<li id=rIY>[rIY] Tangible Bits: サイバースペースと人間との物理的な接点、石井裕インタビュー記事　http://www.rm2c.ise.ritsumei.ac.jp/tamura/maindoc/ishii.html</li>
<li id=rKH>[rKH] 『「視覚は人間の情報入力の８０％」説の来し方と行方』、加藤宏、筑波技術大学テクノレポート Vol.25 (1) Dec. 2017</li>
<li id=rKH2>[rKH2] 「霊長類の音声の運動基盤及び多様性とその進化的な背景」、香田啓貴（こだ　ひろき）、日本音響学会誌71巻7号、2015
<li id=KH3> [rKH3] サルの発声から見るヒトの言語の起源、香田啓貴 https://www.brh.co.jp/publication/journal/102/rp/research01/ </li>	
<li id=rKK>[rKK] Eye Tracking in Human-Computer Interaction and Usability Research; Ready to Deliver the Promises、Karn, J. K. Jacob and Keith S.、2003</li>
<li id=rKW>[rKW] 蔵田潔、渡辺雅彦 大脳皮質 脳科学辞典 https://bsd.neuroinf.jp/wiki/%E5%A4%A7%E8%84%B3%E7%9A%AE%E8%B3%AA (2021)</li>
<li id=rMA>[rMA] 「脳の神経細胞の数」、三上章允（みかみ あきちか）、http://web2.chubu-gu.ac.jp/web_labo/mikami/brain/10/index-10.html</li>
<li id=rMC>[rMC] https://www.ted.com/talks/michael_corballis_evolution_s_great_mystery_language/transcript?language=ja</li>
<li id=rMK>[rMK] 『ヒトとは視覚を発達させ、嗅覚を退化させた「か弱きサル」である』、三谷宏治（みたに こうじ）、https://www.careerinq.com/blog/mitani/2015/05/post-6.shtml</li>
<li id=rMS>[rMS] 「皮膚感覚の情報処理」、下条誠、計測と制御、第４１巻、第１０号、２００２年１０月。
<li id=rNT>[rNT] 「霊長類の音声器官の比較発達ー言葉の系統発生」、西村剛(（にしむら　たけし）, The Japanese Journal of Animal Psychology, 60, 1 49-58 (2010)</li>
<li id=rNY>[rNY] 野口悠紀雄『「超」書く技術』(プレジデント社)</li>
<li id=rPN>[rPN] 「生命とは何か？」、ポール・ナース、ダイヤモンド社、ISBN978-4-478-11107-9 C0045</li> 
<li id=rSO>[rSO] 「生体情報処理」、杉江昇、大西昇、昭晃堂、2001年、ISBN4-7856-9060-7</li>
<li id=rST>[rST] 橘木 修志 視細胞 脳科学辞典　https://bsd.neuroinf.jp/wiki/%E8%A6%96%E7%B4%B0%E8%83%9E (2019)</li>
<li id=rSW>[rSW] 「インターフェイスデザインの心理学」(100 Things Every Designer Needs to KNow ABout People)、スーザン・ワインチェンク(Suzan Weinschenk)、O’REILLY、ISBN978-4-87311-557-3</li>
<li id=rTK>[rTK] 「嗅覚の匂い受容メカニズム」、東原和成（とうはら かずしげ）、2015</li>
<li id=rYH>[rYH] 「サピエンス全史」、ユヴァル・ノア・ハラリ、2016</li>
<li id=rYH2>[rYH2] 「指の機能」、米満弘之、1973、精密機械、40巻1号、https://www.jstage.jst.go.jp/article/jjspe1933/40/468/40_468_18/_pdf</li>
<li id=rYT>[rYT]「唯脳論」養老孟司、1998、ISBN4-480-08439-8</li>
<li id=rUT>[rUT] 上村朋子 空間記憶 脳科学辞典 https://bsd.neuroinf.jp/wiki/%E7%A9%BA%E9%96%93%E8%A8%98%E6%86%B6 (2018)</li>
<li id=rVB>[rVB] 「ヒトの脳 : 解剖学的構造と機能」、https://www.visiblebody.com/ja/learn/nervous/brain</li>
<li id=rVB2>[rVB2] 「考えてみるに As We May Think」、Vannevar Bush、山形浩生訳</li>
</li>
</ul>
</details>

<!--https://shu-sait.com/mokuji-jidou-seisei/-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="toc.js"></script>
<script>
    $(function () {
        $(".toc-contents").toc({
			startLevel: 'h2',
		});
    });
</script>

</body>
</html>