<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="This site is to promote the thought that uses the daily behavior of people across the human-machine interactions.">
    <meta name="author" content="Yoshiharu Sato">
	<title>ヒトの生体機能とコンピュータ</title>
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Josefin+Slab:100,300,400,600,700,100italic,300italic,400italic,600italic,700italic" rel="stylesheet" type="text/css">

<style>
p, li { line-height: 1.75;  }
table { margin: auto; }
.pagebreak { break-before: page; }
.printfriendlyblock { page-break-inside: avoid; }
</style>
	
</head>

<body>
<h1>ヒトの生体機能とコンピュータ</h1>
<hr>

<details open><summary>目次</summary>
	<!--https://shu-sait.com/mokuji-jidou-seisei/-->
	<div id="toc" class="l-toc"></div>
</details>

<div class="toc-contents"> <!--Start of TOC areas-->

<div class="pagebreak"><hr><h2>1. このメモの目的</h2>

	<details open><summary><strong>目的</strong></summary>
			<p>
				このメモでは、ヒトが生物として世界に対処するときの、生体情報処理の特徴を見ていく。
				そうすることで、道具としてのコンピュータのユーザー・インターフェイスを振り返る。
			</p>
	</details>

	<details open><summary><strong>道具がヒトの能力と調和したとき、道具は有効なものとなり、ヒトの能力を拡大する</strong></summary>
			<p>
				ヒトは、その能力によって道具を発明し、自分ができることを拡大してきた。
				例えば、ヒトは、文字と紙という道具を発明した。
				それによって、ヒトは、記憶したり伝達したりする能力を、拡張した。
				また、ヒトは、紙という平面の物体に、3Dの物体の見取り図を表現する。
				ヒトは、紙とペンを操り、3Dモデリングができる。
				これは生身の目では見通せない俯瞰的な視覚である。
				自分の能力の拡張である。
				紙に文字や図を書くとき、ヒトは、器用な手指を操作する。
				高性能な目で指の軌跡を確認する。
				手指の内部的な感覚とともに動きに修正をかける。
				といったことを、瞬時に連続的に繰り返し行っている。
				ヒトは、その高度な目の機能と手指の器用さによって、道具を使いこなしている。
				このように、道具が人の能力と調和したとき、道具は有効なものとなる。
				そして、有効な道具は、ヒトの能力を拡大する。
				顕微鏡や望遠鏡が、見えるものを広げたように。
				車が、ヒトの移動距離を変えたように。
				インターネットが、コミュニケーションする集団の規模を変えたように。
				拡大されたヒトの能力によって、道具はさらに高度になる。
				道具とヒト能力の好循環は、石器時代の昔からヒトを変えてきた。
				コンピュータがこれからどんな循環をヒトにもたらすのかは、まだわからない。
			</p>
	</details>

	<details open><summary><strong>コンピュータのユーザ・インターフェイスはヒトの能力と調和していない</strong></summary>
			<p>
				現在の人間とコンピュータの間のユーザー・インターフェイスはどうか。
				そこではヒトが機械に合わせている。
				それは、機械の技術が未熟だからである。
				技術が、ヒトに制約を与えているということである。
				ヒトは、不自然な重荷を負わされている。
				現状のコンピュータの技術は、ヒトの能力と調和していない。
			</p>
			<p>
				コンピュータに限らず、道具一般を考えてみる。
				ヒトが文字を発明する前までは、コミュニケーションは、話し聞くものだった。
				文字が生まれて以降、そういう日常的な生活空間でのコミュニケーション以外に、
				文字を手で刻み読み取るというコミュニケーションが生まれた。
				文字とその記録ごしのコミュニケーションは、個人の生活空間を超え、時空を超越した。
				以来、ヒトは、話し聞くコミュニケーションと、手・目で刻み目で認識するコミュニケーションを、使い分けてきた。
				現代において、コンピュータのユーザーインターフェイスは、もっぱら手と目によるコミュニケーションに属する。
				このところの音声認識技術の発達で、このコミュニケーションの形態が、変わっていくのかどうか、まだ明らかでない。
				ここで、ヒトの生態機能を見つめることを通して、道具のインターフェイスを考えることで、方向が見える。
			</p>
	</details>
</div>

<div class="pagebreak"><hr><h2>2. ヒト生体の情報処理</h2>
	<details open><summary><strong>ヒトは8つの感覚器と2つの作用効果器で情報処理している</strong></summary>
		<p>
				ポール・ナースによれば、「あらゆる生命には、自分と子孫を永続させるという目的がある。
				あらゆる生命の中心には、情報がある。
				目的のための行動に、情報は利用される。
				<a href="#rPN">[rPN]</a>」。
				生体は、外の世界と自分の体の内側の世界との両方に関して、情報を絶えず集めて利用している。
				内外の環境の状況を把握するものを<strong>受容器官</strong>という。
				それらに応じて外部に働きかけるものを<strong>効果器官</strong>という。
				受容器官と効果器官とを連結し統括するものは、<strong>脳・神経系</strong>である。
		</p>
		<p>
			受容器官は、特殊感覚と体制感覚がある。
			<strong>特殊感覚</strong>は、特定の刺激に対して局所的な器官が反応する。
			<strong>体性感覚</strong>は、身体に分散して存在し環境への反応を助ける。
			一般的に五感と言われるものは、平衡感覚と固有感覚を除外した、視覚、味覚、嗅覚、聴覚、触覚である。
		</p>
		<p>
			一方、ヒトの効果器官には、機械系と音響系がある。
		</p>
		<p>
			<ul>
			<li>受容器官</li>
				<ul>
				<li>特殊感覚器官</li>
					<ul>
					<li>視覚器</li>
					<li>味覚器</li>
					<li>嗅覚器</li>
					<li>平衡・聴覚器（組織的に同居）</li>
					</ul>
				<li>体性感覚器官</li>
					<ul>
					<li>外部から受容する皮膚感覚</li>
					<li>筋、腱、関節内で感知する固有感覚</li>
					</ul>
				</ul>
			<li>効果器官</li>	
				<ul>
				<li>筋肉や骨格からなる手指や身体の機械的運動系</li>
				<li>発声器官</li>
				</ul>
			</ul>
		</p>
	</details>

	<details open><summary><strong>情報媒は、光、振動、科学的・物理的刺激である</strong></summary>
		<p>
			視覚は、光という電磁波を感知する。
			聴覚は、ヒトを含む陸生動物の場合、空気振動を感知する。
			触覚（皮膚感覚）は物理的刺激を感知する。
			そして味覚と嗅覚は化学的物質を感知する。
			運動系は物理的な効果を持つ。
			音声発生は、空気振動を起こす。
		</p>
		<div class="printfriendlyblock">
			<p>
			<table border="1">
			<tr><td>受容器官</td><td>特殊感覚</td><td>視覚</td><td>光</td></tr>
			<tr><td></td><td></td><td>味覚</td><td>化学的物質</td></tr>
			<tr><td></td><td></td><td>嗅覚</td><td>化学的物質</td></tr>
			<tr><td></td><td></td><td>平衡・聴覚</td><td>重力、空気振動</td></tr>
			<tr><td></td><td>体性感覚</td><td>皮膚感覚</td><td>物理的</td></tr>
			<tr><td></td><td></td><td>筋、腱、関節内固有感覚</td><td>物理的</td></tr>
			<tr><td>効果器官</td><td></td><td>機械的運動系</td><td>物理的</td></tr>
			<tr><td></td><td></td><td>発声</td><td>空気振動</td></tr>
			</table>
			</p>
		</div>
	</details>

	<details open><summary><strong>近接感覚と遠隔感覚がある</strong></summary>
		<p>
			どんな生物も例外なく重力を感じる。
			動物は自分の体の傾きを、平衡器官で感知している
			<a href="#rIN">[rIN]</a>。
			感覚には遠くからのことを感知するものと、近いもことを感知するものがある。
		</p>
		<p>
			味覚、接触感覚は、近くのもののの感覚である。
			動物の進化の中で、これらの近接感覚がまずあったと思われる。
			味覚は、化学物質を感知する。
			接触感覚は物理的な圧力を感知する。
			これらが、まずは、食べ物を識別し、仲間と生殖・交信するためにあったと思われる。
			また、運動するために、体の状態を感知する体性感覚も必須だったろう。
		</p>
		<p>
			一方、生物が行動範囲を広げる際に、より広い環境を感知し、よりうまく生存・生殖したい。
			嗅覚は、遠くからの化学物質を感知する。
			聴覚は、遠くからの水・空気振動を感知する。
			視覚は、遠くからの光電磁波刺激を感知する。
		</p>

		<div class="printfriendlyblock">
		<p>
			<table border="1">
			<tr><td>受容器官</td><td>特殊感覚</td><td>視覚</td><td>遠隔</td></tr>
			<tr><td></td><td></td><td>味覚</td><td>近接</td></tr>
			<tr><td></td><td></td><td>嗅覚</td><td>遠隔</td></tr>
			<tr><td></td><td></td><td>平衡・聴覚</td><td>遠隔</td></tr>
			<tr><td></td><td>体性感覚</td><td>皮膚感覚</td><td>近接</td></tr>
			<tr><td></td><td></td><td>筋、腱、関節内固有感覚</td><td>近接</td></tr>
			<tr><td>効果器官</td><td></td><td>機械的運動系</td><td>近接</td></tr>
			<tr><td></td><td></td><td>発声</td><td>遠隔</td></tr>
			</table>
			</p>
		</div>
	</details>

	<details open id=通信容量><summary><strong>それぞれの器官の通信容量</strong></summary>
		<p>
			人間の全受容器から、感覚神経を経由して中枢神経系へ伝送される情報量は、10の9乗ビット/秒と言われる。
			うち、視覚は、10の6から8乗ビット/秒、聴覚は10の4から6乗/秒、触覚は10の6乗/秒と言われる。
			一方、中枢神経系から、運動神経を経由して効果器へ伝送される情報量は、10の7乗ビット/秒と言われる
			<a href="#rSO">[rSO]</a>、<a href="#rFT">[rFT]</a>。
			また、別のソースでは、視覚は10の8乗ビット/秒、触覚は10の6乗ビット/秒、聴覚と嗅覚はそれぞれ10の5乗ビット/秒、味覚は10の3乗ビット/秒、とも言われる。
		</p>
		<p>
			視覚は人間の情報獲得の80%ともいわれる。
			これらに、厳密な根拠はないとも言われる<a href="#rKH">[rKH]</a>。
		</p>

		<div class="printfriendlyblock">
			<p>
			<table border="1">
			<tr><td>受容器官</td><td></td><td></td><td>1000000000 bit/sec</td></tr>
			<tr><td></td><td>特殊感覚</td><td>視覚</td><td>100000000 bit/sec</td></tr>
			<tr><td></td><td></td><td>味覚</td><td>10000 bit/sec</td></tr>
			<tr><td></td><td></td><td>嗅覚</td><td>100000 bit/sec</td></tr>
			<tr><td></td><td></td><td>聴覚</td><td>100000 bit/sec</td></tr>
			<tr><td></td><td>体性感覚</td><td>皮膚感覚</td><td>1000000 bit/sec</td></tr>
			<tr><td></td><td></td><td>筋、腱、関節内固有感覚</td><td></td></tr>
			<tr><td>効果器官</td><td></td><td></td><td>10000000 bit/sec</td></tr>
			<tr><td></td><td></td><td>機械的運動系</td><td></td></tr>
			<tr><td></td><td></td><td>発声</td><td></td></tr>
			</table>
			</p>
		</div>
		<p>
			いずれにせよ、ヒトは環境を認識するのに、主に視覚を使っている。
			また、環境に対する反応の情報量は、感覚よりも桁違いに小さい。
			つまり、ヒトという生物は、環境から多くの情報を仕入れて、生存・繁殖に有効な選んで反応している。
		</p>
	</details>

	<details open><summary><strong>感覚、知覚、認知の違い</strong></summary>
		<p>
			受容器官に刺激が与えら脳に伝えられたもの感覚という。
			熱いとか、音が聞こえるとかである。
		</p>
		<p>
			感覚に、対象の構造や特徴が加えられて、意識されたものが知覚である。
			長いとか、強いとか。
			感覚はその一部が知覚となる。
			意識に上らないことは多い。
			無意識の過程により、感覚はフィルターされる。
			これをカラーバス効果や、カクテルパーティ効果という。
		</p>
		<p>
			さらに、知覚が過去の経験や学習に基づいて解釈されたものが認知である。
			犬であるとか、母であるとか。
			<a href="#rIN">[rIN]</a>	
			認知になると、文化や社会の影響が濃厚に出る。
			社会の文化によって、虫の鳴き声を、雑音と感じるか、秋の風情と感じるか、が異なってくる。	
		</p>
		<p>
				感覚、知覚、認知は、ヒトが環境から情報を仕入れる、階層的な分類である。
				反応に関しての分類は、どうか？ 不随的・随意的、無意識的・意図的などの分類が考えられる。
		</p>
		<p>
			コンピュータと人の情報のやり取りの観点では、
			コンピュータからの出力が知覚したり認知する対象となる。
			また、人からコンピュータへ情報を入力したりする。
			本文書では、コンピュータの入出力という言い方ではなく、ヒトを中心にした言い方をする。
			コンピュータに対して、ヒトは意図的動作をしたり言語表現をする。
			コンピュータからの情報を、ヒトが知覚し認知する。
		</p>
	</details>
</div>

<div class="pagebreak"><hr><h2>3. 受容器官</h2>
<h3>3.1 視覚</h3>

	<details open><summary><strong>人は視覚的動物として進化した</strong></summary>

		<p>
			人の得る情報の80%は視覚からといわれるくらい、ヒトは視覚的動物である。
		</p>
		<p>
			光という情報媒体は、遠くまで届く、高速に伝わる、という特徴を持つ。
			生物が光を感知できるとしたら、瞬時に、遠方まで、敵ないし見方、餌を識別でき、生存に有利である。
			光は高速なので、どこに物があっても瞬時に把握できるという意味で、距離に左右されない。
		</p>
		<p>
			英人生物学者のアンドリュー・パーカー（Andrew Parker、1967～）は、2003年、「光スイッチ説」を唱えた。
			カンブリア紀に登場した三葉虫は、目を進化させた結果、食べ食べられる関係で優位に立つことで、
			それが、淘汰圧として、ほかの生物の多様な進化を促した、と主張した。
			カンブリア紀というのは、その時代からいきなり化石が出始めた時代である。
			それまでは、化石になるような骨や外殻がない生物しか存在していなかったが、資格の登場が生存競争を激烈にして、
			突如、骨や外殻を備えた多様な生物が進化した、という。
			<a href="#rMK">[rMK]</a>
		</p>

		<p>
			その後、生物の長い歴史の中、器官の発達とともに、視覚は機能的に進化してきた。
			まず、原始的な生物では、明暗識別ができた。
			そして、明暗の方向視、形態視、動きの感知、色認識、両眼視による遠近を含む探索・位置同定、ができるようになった。
		</p>

		<p>
			一方で、光は他のものによって遮られるという欠点がある。また、夜には光がなくなる。
			そのため、光あふれた昼間、地表での生存競争を避けた生物は、別の感覚を伸ばす必要があった。
			化学物質である臭いは、風に左右されるが、昼夜を問わず、どんな隙間にも入り込む。 
			中生代の恐竜の全盛期には、ヒトの先祖である哺乳類は、夜に活動し、光のないところで嗅覚を発達させて、生き延びた。
			陸上動物だけでなく、海生動物を含めても、視覚器が退化した動物は多いが、聴覚器を持たない動物は少ないという。
			それ以降の動物は、ヒトのような視覚型と、イヌのような嗅覚型に大別される
			<a href="#rIN">[rIN]</a>。
			やがて、恐竜がいなくなり、類人猿が森から草原に降りてきた。
			そのころ、ヒトの先祖である狭鼻猿類は、それまでの赤・青の2色視でなく、赤・青・緑の三色視ができるように進化し、弁別できる色情報が格段に増えた
			<a href="#rMK">[rMK]</a>。
		</p>
	</details>

	<details open><summary><strong>ヒトの視覚の高性能の仕組み</strong></summary>
		<p>
			光刺激を瞬時に処理するため、ヒトの視覚は、情報圧縮と並列処理を活用している。
		</p>
		<p>まず情報圧縮である。</p>
		<ul>
			<li>
				脊椎動物の視細胞は、錐体(cone)と粁体(rod)の2種類ある。
				粁体(rod)は明暗に反応し、錐体は異なる波長の光(色)に反応する。
				ヒトでは、網膜に中心窩(fovea)と呼ばれる錐体だけが密集した部位があり、この部分での視覚が視野の中心部となる。
				人間には錐体が約600万個、 粁体が約1億2000万個存在する。
				一方、視細胞の情報を受け取る視神経は約100万個である。従って網膜は光刺激の情報を1/100ほどに圧縮して脳に送っていることになる。
				また視覚は、網膜像の時間的差分だけを脳へ送るというデータ圧縮を行っている<a href="#rST">[rST]</a>。
			</li>
			<li>
				視覚は、光刺激を電気信号へ変換して処理する。刺激が同じならば、神経内で電気信号が発火されない。
				つまり、同じ映像であるかぎり、刺激としての画像情報は消える。
				そこで、眼球を不随意に微動させて、注視したときの網膜像を絶えずリフレッシュしている。<a href="#rSO">[rSO]</a>
			</li>
		</ul>
		<p>ヒトは瞬時に目から多くの情報を把握できるが、いくつかの並列処理を行っている。</p>
		<ul>
			<li>
				視細胞のレベルでは、錐体は色や空間的情報処理、杆体は明暗情報処理･時間的情報処理を分担している。
				また、注目しているところの注目視と、別に周辺視が、独立に機能している。
				歩きながらスマホを見ることができるのもそのせいである。
				明暗の変化や運動など時間的な変化を伴うものが、周辺視野で感知される。
				その後、注意すべきかどうかの判断のために、眼球運動で注目視し、知覚・認知が行われて、対処が判断される
				<a href="#rFT">[rFT]</a>。
				周辺視野は、素早く反応する。
				恐ろしい物体を中心視野で観察すると脳が反応するまでに140-190ミリ秒、周辺視野では80ミリ秒かかるという<a href="rSW">[rSW]</a>。
				周辺視野は、詳細認識ではなく、状況の概略を把握するのに使われる。
				台所の写真で、写真の周辺部を隠すとどこの写真かわからなくなるが、中央部を隠してもどこの写真が想像できる<a href="rSW">[rSW]</a>。
			</li>
			<li>
				さらに、視覚情報は、まず2つのルートで処理される。一つは、脳へ情報が送られて眼球運動を制御するのに使われる。
				もう一つは、パターン認知に使うため脳（大脳皮質第1視覚野、視覚前野）へ送られる。
				そこでは、網膜上の位置に依存した情報抽出を行ったあと、位置に依存しない空間・携帯情報を抽出する。
				まず、線分の方位、長さ、色、動き、両眼視差などの特徴に選択的に反応し、網膜上の位置に依存した要素情報を抽出する。
				そして、そこから更に二つのルートに分割され、空間知覚処理部（側頭連合野）、形態知覚処理部（頭頂連合野）に送られる。
				そこでは、位置に依存しない、人の顔の認識などパターン処理が行われる。
				このように、視細胞から大脳にかけて、階層的な処理が並行して動く。
				<a href="#rSO">[rSO]</a>
			</li>
		</ul>
		
	</details>

	<details open><summary><strong>認知的なショートカット</strong></summary>
		<p>
			視覚認知レベルでも、生物的な効率化の仕組みを持っている。
			以下にカニッツアの三角形という図がある。
			ヒトは、知覚した情報を処理する際、すでに記憶に持っている認知パターン分類で解釈する<a href="rSW">[rSW]</a>。
			素早く対象を理解するための効率化である。
		</p>
		<p>
			<div align="center">
				<img width=30% src="Kanizsa_triangle.png"> 
				<p>[https://ja.wikipedia.org/wiki/カニッツァの三角形より]</p>
			</div>
		</p>
		また、ヒトは、実世界の3D物体を、すでに記憶している基本的な立体（ジオン）パターンを組み合わせて識別しているという<a href="rSW">[rSW]</a>。
		<p>

		</p>
	</details>

	<details open id=eyeball_movement><summary><strong>眼球の動き</strong></summary>
		<p>
			眼球は、直径24mmから25mmの球体である。
			眼窩の中で、脂肪に囲まれて、3対6種類の筋肉で支えられ、上下、左右、視軸回りの回転運動を行う<a href="#rFT">[rFT]</a>。
		</p>
		<p>
			<div align="center">
				<img width=80% src="eyeball_movement.jpg"> 
				[https://plaza.umin.ac.jp/jikei-np/symptoms/01_01_13.htmlより]
			</div>
		</p>
		<p>
			中心視をするために，左右の眼は連動して動く。
			2種類の連動運動がある。
			一つは、移動する対象を追う運動で、両眼は同じ方向へ運動する（共同運動、conjugate）。
			これには滑らかな成分（最高25から30度/秒）と跳躍性の運動成分（ザッカード、300から600度/秒）がある。
			<a href="#rFT">[rFT]</a>、<a href="#rSO">[rSO]</a>
		</p>
		<p>
			ヒトが、随意的に中心視野を動かすのは、一瞬である。
			ヒトがあるものに注目するとき、それに対する身体の動作を起こす前に、目はすでにそれを見ている。
			ヒトの効果器のどれよりも、眼のほうが早く位置情報を認知している。
			ほかの手段のおよそ倍、速いといわれる<a href="#rKK">[rKK]</a>。
			このために、視線を効果器のように扱い、操作手段としようとする誘惑があった。
			しかし、ヒトの目は受容器官としての役割で進化したものなので、その企ては失敗してきた。
		</p>
		<p>
			もう一方の連動運動は、両眼が逆方向に運動する（幅そう運動、disjunctive, vergence）。
			これは、左右のわずかに異なった像を融合して一つの像として知覚し、
			立体視のデータを得るためにある。
			ヒトは、三次元の世界に住んでいるのである。
		</p>
		<p>
			一方、眼球は、固視微動といって、注目視野内の微小な不随意の動きを行い、静止した物体の網膜像が消えないようにしている。
		</p>
	</details>

	<details open><summary><strong>視覚は時間も見ている</strong></summary>
	<p>視覚は主に空間的情報を感知する。さらに、対象の動きという時間的な情報も感知する。雲は風に流される。遠くから見ればその動きは微々たるものである。しかし、ヒトの目は、雲が連続的に確実に動いていると感知する。</p>
	</details>

	<details open><summary><strong>文字の読み取り速度がすごい</strong></summary>

		<p>
			視覚の性能の高さは、ヒトが処理できる言語情報の統計に表れている。
		</p>
		<p>
			注目視野は20から30ビットを一度に把握できる。これはアルファベットは5文字、ひらがなは4文字、漢字は2文字に相当する
			<a href="#rFT">[rFT]</a>。
			英語の場合、ヒト一度の15文字を読み進むという。先頭の1から7文字で意味を取り、次の8-15文字は周辺視野でみている（予測している）という
			<a href="#rSW">[rSW]</a>。
			またヒトは、聞き取りであれば1分間に160語程を把握できるが、読み取りは1分間に300語ほど把握できる。
		</p>
		<p>
			目は平行処理できるのに対し、耳で聞き取るためには、文字が時系列に並んでいるのでそれらを逐次処理しないといけないことが、
			聞き取りが遅い主因である。
		</p>
	</details>

	<details open><summary><strong>空間的に記憶できる</strong></summary>
		<p>
			動物には、餌の場所や住処をめぐって行動するために、周囲の空間と自身を関連付ける認知機能、空間記憶がある<a href="#rUT">[rUT]]</a>。
			聞いたことを記憶するのと比べて、見えたものは繰り返し確認できる。それが記憶保持を助ける。
		</p>
		<p>
			空間記憶は、連想記憶に似ている。
			キーボード操作に慣れた人は、キーボードを見なくても操作できる。
			しかし、キーボードがないところで、キーボードのキー配列を思い出そうとするとできない。
			つまり、頭に記憶しているのではないのである。
			しかし、キーボードを見ると、指が覚えていたかのように、すぐに上手にタイプできる。
			視覚的な連想記憶が働いている。
			記憶は神経細胞の結合パターンとして保持される。
			何度もキーボードを見て触っていると、神経細胞結合の発火の痕跡が残る。
			キーボードを見たという刺激だけで、あるキーがこの辺にあったよなという残りの記憶が活性化される。
			例えば、以下のようなことに思い当たるのではないか。
			ある事柄が、本の分厚い厚みの中でどのあたりのページの、そのページの中のどのあたりに書いてあったか、ぼんやりと思えていたりする。
			いくつも書類が乱雑に積み重なって置かれている。しかし、どこに何があるか、思い出すことができる。
			ピアノである曲を暗譜で弾くことが出来る。
		</p>
	</details>

	<details open><summary><strong>構造を把握できる</strong></summary>
		<p>
			視覚は、いくつかの情報を同時に把握できるために、構造的な情報を把握できる。
			逆に、この利点があるために、視覚向けにデザインされた情報は、複雑となり、直感的に把握しがたいことも起きる。
		</p>
	</details>

	<details open id=visual_symbol><summary><strong>象徴を認識できる</strong></summary>
		<p>
			ヒトは言語を駆使する。音響の連鎖が、概念を伝える。
			一方で、ヒトは、視覚的な形状でほかの何かを象徴することも行ってきた。壁画、象形文字、表意文字、アイコン、ピクトグラムなどである。
			表意文字が言語の要素であるように、視覚的な象徴の表現力は、言語に比べて、限られている。
			言語は、感覚を指示したり、実在物を指示したり、環境を自在に利用できる。
			言語は、構文構成で概念を自在に組み合わせる表現力がある。
			しかし、視覚的な象徴は、写実画とかでもなければ、特定の実在物を指示する力はない。
			概念の組み合わせも、並置くらいしかできない。
			視覚的な象徴は、表現力が限定される。
			視覚的な象徴は、間接的である。
		</p>
	</details>

	<h3>3.2 聴覚</h3>

	<details open><summary><strong>聴覚の能力</strong></summary>
		<p>
			ヒトの聴覚は、空気の振動を感知する遠隔感覚である。 空気の振動は、距離によって、また障害物があると減衰しやすい。
		</p>
		<p>
			ヒトの聴覚受容細胞の数は23,500個（視細胞は1億以上）、聴神経は3万本（視神経は100万本）である。
			<a href="#rHK">[rHK]</a>
		</p>
		<p>
			視覚がおおむね空間情報を処理するのに対し、聴覚はおおむね時間的情報を処理する。
			会話の相手の話し声、赤ちゃんの泣き声、音楽のリズムやメロディ鳥の鳴き声、など、時間的な流れの中に存在する。
		</p>
		<p>
			精度は視覚より低いが、両耳により、距離と方向を感知する音源定位ができる。
			車を運転中に、サイレンの音が聞こえる。どちらの方向からを確かめるために、よく聞こうとする。
			野鳥の鳴き声がきこえてきたら、どこにいるか方角の見当をつけて探す。
			ただ、目でそれを確かめないと、満たされない気がする。
		</p>
	</details>

	<details open><summary><strong>聴覚は発話と連動する</strong></summary>
		<p>
			聴覚に障害のある人は発話障害を伴うことが多い。
			情報は、言葉を聞く聴覚器官から、発話するための調音器官へ流れ、自分の音声を聞きながら発話する
			<a href="#rSO">[rSO]</a>。</p>
			目から得た情報に基づき、手指が動くように、聞いた音に基づき、発話するのである。
		</p>
	</details>

	<details open><summary><strong>聴覚認知の特徴</strong></summary>
		<p>
			話したことを聞き、話返す、というのが原初のヒトのコミュニケーションの方法だった。
			そこで交わされる言語情報は、直観的で、ヒトは努力なしに理解できる。
			子供が大人へ成長する間、周囲の大人の会話を学習し、歩いたり走ったりするのと同じように、しゃべれる。
		</p>
		<p>
			一方、言語情報は、時系列情報である。そして、音声情報は消え去る。
			短期記憶に入っても、再確認できないし、しばらくたつと消える。
			そのため、ヒトは、聴覚からは、少ない量しか情報を把握できない。
			複数の情報を安定的に保持できない。
			そのため、聴覚は、フォームや手順といった複数の情報からなる構造の把握が苦手である。
		</p>
		<p>
			gaを発音する唇を見せて、同時時にbaと言う音声を聞かせると、被験者は中間の調音位置をもった「da」を知覚する。
			これをMcGurk効果という。
			<a href="#rSO">[rSO]</a>
			聴覚情報は、知覚レベルになると視覚情報と融合、ないし引っ張られて、知覚される。
		</p>
	</details>

	<h3>3.3 嗅覚</h3>

	<details open><summary><strong>ヒトは嗅覚を退化させた</strong></summary>
		<p>
			嗅覚は、揮発性ないし水溶性の化学物質を感知する。味覚は、同じ化学物質でも接触感覚である。
		</p>
		<p>
			ヒトの嗅覚受容体数（種類数）は、396個あり、その組み合わせで数十万種類のにおいを感知する。
			遺伝子レベルで見ると、哺乳類の嗅覚に関係する遺伝子は大きなファミリーをなしていて、動物にとって環境探知の重要な手段であることが示されている。
			また、匂い情報は、大脳の感情や記憶をつかさどる部分に流れ、内分泌で即座に反応できるようになっている。
			素早い反応によって生存するために重要な機能を果たしていた時代の名残である。
			その由来によって、匂いは長期記憶を呼び覚ます。
			<a href="#rTK">[rTK]</a>
		</p>
	</details>

	<h3>3.4 体性感覚</h3>

	<details open><summary><strong>内外を感知する</strong></summary>
		<p>
			体性感覚器は外部を感知するものと内部の固有の情報を感知するものに大別される。 
		</p>
		<p>
			外部を感知するものは皮膚感覚である。人の場合皮膚は1.8平方メートルもあり皮膚感覚の受容器は散在している。
			皮膚表面には触覚があり、皮膚の深部には圧力を感じる圧覚がある。
			その他、温覚、冷覚、痛覚の受容器がある。 
			<a href="#rIN">[rIN]</a>
		</p>
		<p>	
			一方、筋、腱、関節などに、自分の状態を感知する固有受容器がある。
			筋がどれだけ伸びているか、どれだけの力で引っ張られているか、角度はどうか、を感知している。
			これは姿勢を制御したり体を動かすためにある。
			<a href="#rIN">[rIN]</a>
		</p>
	</details>
	
	<details open><summary><strong>指先は鋭い</strong></summary>
		<p>
			皮膚感覚受容器は10の7乗個あり、神経は10の6乗個ある。指先には1平方ミリメートル当たりに1個の神経線維が大脳に接続している。
			2点を弁別する能力は、手のひらでは1センチメールだが、指先は2ミリメートルである。
			<a href="#rMS">[rMS]</a>
		</p>
		<p>このような手指の神経の細かさが、ヒトが箸やハサミを上手に扱う基礎となっている。</p>
	</details>
</div>

<div class="pagebreak"><hr><h2>4. 効果器官</h2>

<h3>4.1 手、骨、筋</h3>

	<details open><summary><strong>手と脳の進化の相乗効果</strong></summary>
		<p>
			手、骨、筋という効果器官は、内部状態を感知しつつ、機械動作する。
			手には優れた皮膚感覚がある。
			一方で、視覚は手の動き周辺を観察するのに強力な機能を備えている。
		</p>
		<p>
			320万年ほど前、ルーシーと呼ばれる化石により、類人猿が二足歩行を始めたことがわかっている。
			骨盤の形から二足歩行していたことが分かったが、脳の大きさはチンパンジーと変わらなかった。
			二足歩行のメリットは、四足歩行に比べて25%のエネルギーで移動できることだった。
			その後、240万年ほど前に、ホモ・ハピルスが登場し、肉を骨からそぎ落とす鋭利な石器を作り利用したた。
			ホモ・ハピルスの脳はルーシーの倍（ホモ・サピエンスの半分）に大きくなっていた。
			道具を作るには目と手を正確に連動させる必要がある。それが脳に刺激となり、脳の発達を促した。
			一方、大きな脳はたくさんのエネルギーを必要とする。たくさん食べる必要があり、狩猟してとった肉を食べた。
			肉をたくさん得るには、より高度な道具が必要となる。
			こうして、手と脳の進化の相乗効果の連鎖が始まった。脳はますます大きくなり、手指はますます器用になり、道具はますます精緻になった。
			200万年前ごろ、ホモ・ハピルスは、ホモ・エレクトスへ進化した。脳の大きさは、ホモ・ハピルスの1.5倍となった。
			ホモ・エレクトスは、槍を使い、火で食物を消化しやすいように変えられた。
			100人くらいの集団で暮らしていたとされる。
			170万年前頃に、ホモ・エレクトスはアフリカを出て、別々の地域に進出し、5種類のヒト属に分化したらしい。
			その後35万年前ほど、ホモ・サピエンスと同じくらいの脳を持つネアンデルタール人が現れた。
			頭蓋骨の底に発声に必要な神経の束を通す穴があり、多様な発声ができた。
			また、音楽、宗教、言語を持っていた。
			その後、19万5000年前に、ホモ・サピエンスが登場した。ホモ・サピエンスは、
			7から5万年前に、アフリカから出て世界中へ広がった。
			<a href="#rCL">[rCL]</a>
		</p>
		<p>
			<div align="center">
				<img width=40% src="brain_capacity_of_primates.png"> 
				<p>[http://user.keio.ac.jp/~rhotta/hellog/lib/brain_capacity_of_primates.pngより]</p>
			</div>
		</p>
	</details>

	<details open><summary><strong>手指の器用さ</strong></summary>
		<p>
			ヒトの手には5本の指があり、指は3つの関節を持ち、動く。
			そして、親指は、ほかの指と独立して動き、ほかの指と対面して動作し、物をつかんだりできることできる。	
		</p>
		<p>
			<div align="center">
				<img width=40% src="fingers.png"> 
				<p><a href="#rYH2">[rYH2]より</a></p>
			</div>
		</p>
		<p>
			手指は、以下の運動ができる。
			<ul>
				<li>握る(grip)</li>
				<li>つまむ(pinch): 指先(tip)、指腹(pulp)、側面(lateral)、ひっかけ(hook)、指間はさみ(finger)</li>
				<li>ねじる(twist)</li>
				<li>押す(push)</li>
				<li>すくう(scoop)</li>
			</ul>
			これらの組み合わせで、日常生活を送っている。
		</p>
		<p>
			<div align="center">
				<img width=40% src="finger_behavior.png"> 
				<p><a href="#rYH2">[rYH2]より</a></p>
			</div>
		</p>
	</details>

	<details open><summary><strong>手指の器用さを支えるもの</strong></summary>
		<p>
			手指は、身体がある姿勢をとっていて体幹が支え、肩や腕が支え、腕・肘・手首が動き、手首が支えることで、はじめて器用に動く。
			体性感覚と機械的効果器が、手指の器用さを支えている。
			まさに、手指の器用さは、全身運動の結果である。
		</p>
		<p>
			手指は、視覚に障がいがある方を除き、多くの場合、目に助けられてこそ機能する。
			例えば、ドアノブの位置を目にしながら、そこをつかんでひねりドアを開く。そこに、ドアを開けるという意図で行動した点にあいまいさはない。
			例えば、左手に持った茶碗の位置を目で感知しながら、右手の箸を動かして、茶碗のごはん摘まみ上げる。
			例えば、机の上に置いた紙を左手で押さえて、その四角い方向を目で確認したうえで、右手のはさみで紙の一片を切り取る。
			例えば、キーボードがあってキートップの文字マークを見て、手指は動く。
			音声だとbaなのかpaなのかわかりにくいこともあるが、
			手指の動作は目でキートップを確認しているため、コンピュータに対して、曖昧さなくpaという言語表現ができる。
			空間的な記憶もある。
		</p>

	</details>

	<details open><summary><strong>距離の束縛</strong></summary>
		<p>
			手を動かし、マウスで、別の場所のターゲットを補足するという運動負荷に関し、
			その移動時間は、移動距離が大きいほど大きく、対象の大きさが大きいほど小さくなる。
			これをフィッツの法則という。
			手指は、機械動作なので、この距離の束縛を受ける。
			受信箱のメールのTriageを取り上げてみる。
			メールをざっと眺めて丁寧に読みたいメール以外は即削除する作業である。
			スマホでなら、指先の操作ですむので、素早くできる。
			しかし、デスクトップであると、画面が大きく、手から離れているので、マウスごしにGUI対象をポチポチするする必要がある。
			読む場所を設定する画面上の位置と、削除ボタンは離れているので、いちいちマウスポインターを移動する手間がある。
			そのため、スマホに比べて、デスクトップPCでの作業には時間がかかる。
			手指の操作は、こういう意味で、距離の束縛を受ける。
			これに対し、視線の移動は、距離の束縛を受けない。
			移動は一瞬である。
			また、音声動作は、マイクが音を拾う限り、
			スマホでもデスクトップでも同じスピードでテキスト指定動作ができる。
			音の聞こえる範囲ならば、距離の束縛を受けない。
		</p>
	</details>

	<h3>4.2 発声</h3>

	<details open><summary><strong>発声器官の進化</strong></summary>

		<p>
			ヒトの音声産出は、横隔膜・肺という呼吸器官から空気を吐き出し、咽頭・声帯で音源を作り、
			舌・咽頭・口唇で音に変化を与える、と3つの器官要素によって生産される
		</p>
		<p>
			<a href="#rKH2">[rKH2]</a>。
			脊椎動物が陸に上がって肺呼吸をするに伴って、そこで空気の振動を起こす能力が生殖や警告などに利用されて進化したようである。
			一方、舌は、食べ物を飲み込むときに、精緻に、素早く動くように進化していた。
		</p>
		<p>
			咽頭を含む声道は、食べ物の摂取・嚥下 を不随意的に担うとともに、ヒトでは随意的に話し言葉を発声する役割を持つ。
			ヒトは、320万年前に直立歩行を始めた。そして、火を使うことで、やわらかい食事をとるようになった。
			そして、頭の重量のバランスをとるため頭の前後径が短くなり、柔らかい食事による顎の縮小とあいまって、脳が前にせり出し、
			舌は、前後に圧縮されて上下に厚みを持ち、丸い形状になった
			<a href="#rFJ">[rFJ]</a>。
			そして、40万年前ほど、ヒトの咽頭の位置が下がった。そして、喉に大きな空間をつくり、多様な共鳴を生み出せるようになった。
			ヒトの声道は、口腔と咽頭腔という二つの共鳴腔がほぼ垂直に結合していて、それぞれ独立に変形させることができる。
			ヒトの舌は、丸みがかっていて、形状変化で多様な音調整を可能にした。
			また、ヒトは、発話の際、1秒間に5〜6回、口が開閉する。これは、類人猿にも共通するという
			<a href="#rKH3">[rKH3]</a>。
			ヒトは話をする時に、一回息を吐くという瞬間で、多くの異なる音を発声するために
			声道形状を連続的に素早く変形させることができる点が、特異であるとされる
			<a href="#rNT">[rNT]</a>。
		</p>
		<p>
			<div align="center">
				<img width=50% src="resonance_cavity.jpg"> 
				<p>[https://band-knowledge.com/vocal-14/より]</p>
			</div>
		</p>
		<p>
			また、ヒトは成長に伴って、言語を習得し、多様な音声生産ができるようになるという、音声生産の可塑性ないし学習という点が特徴的であるとされる
			<a href="#rKH2">[rKH2]</a>。
			それを可能にする神経系の進化が背景にあった。
		</p>

	</details>

	<details open><summary><strong>テキスト生産速度は指の5倍</strong></summary>
		<p>
			ヒトのコンピュータに対する言語表現のスピードは、経験的に、それぞれおおよそ、
			しゃべりなら160語/分、手書きは30語/分、タイプなら40語/分である。
			しゃべりは、社会的な環境で育った健常者ならば誰でもできる。
			一方、手書きは教育が必要であり、キータイプなら機器操作に慣れが必要である。
			音声での言語表現は、習熟の必要がないばかりか、指よりも5倍速い。
		</p>
	</details>
	</div>

<div class="pagebreak"><hr><h2>5. 脳・神経系</h2>

	<details open><summary><strong>脳の構成要素</strong></summary>
		<p>
			脳は、大脳、間脳、小脳、脳幹からなる。
			大脳は、高度な機能をこなす。
			大脳は、皮質、辺縁系(海馬、偏桃体など)、基底核がある。
			間脳は、感覚を仲介し、感情を管理し、全体の内部システムを統括する。 
			脳幹は、脊髄からシグナルを伝達して、基本的な体内の機能と反射を指令する。
			爬虫類脳とも呼ばれる。
			例えば、呼吸や心臓の拍動など不随意・自律的な機能をこなす。
			小脳は身体運動、発声の協調およびバランスを調整する。例えば、足の動かし方を意識せずに歩いたりできる。
			首が回転したときに、反射的に眼球が逆回転し、視界のブレをなくす。小脳は、運動パターンを学習するといわれる。
			<a href="#rVB">[rVB]</a>
		</p>
	
		<p>
			大脳の皮質には神経細胞が140億あるが、小脳には1000億個ある。
			<a href="#rMA">[rMA]</a>
			小脳は、ヒトでは脳全体の15%程度の容積しかないが、脳全体の神経細胞の約半分が存在する。
			末梢感覚器や大脳皮質からの入力を受けて、運動を学習する。
			<a href="#rHN">[rHN]</a>
			鋏を扱うときの動作、箸を扱うときの動作、話す動作、歩く動作、大工の技、庭師の技、などにこそ、目立たないが、実は大量の知能が、詰まっている。
			ヒトを知識、いわば見える氷山の一角、で比べたりする。
			が、それ以前の、目立たない、生活のための知能のほうが、はるかに大きく、ヒト共通である。
		</p>

		<p>
			大脳皮質には機能が特定の場所に関連付けられる箇所がある。
			運動野を見ると、発声関係と、手指の部分が大きいことに気づく。
			発声関係は言語機能と関係して大きな部分を占めるのは理解しやすい。
			一方、手は第2の脳といわれるほど、大きな運動知能を持っている。
			<p>
				<div align="center">
					<img width=70% src="cerebral_penfield_map.jpg"> 
					<p>[https://www.akira3132.info/cerebral_cortex.htmlより]</p>
				</div>
			</p>
		</p>

	</details>

	<details open id=association_area><summary><strong>ヒトは総合する動物</strong></summary>
		<p>
			感覚野と運動野という機能局在な部分を除くと、大脳皮質の約2/3にも相当する広い領域が、連合野と呼ばれる。
			連合野は、高次な脳機能を具現化している皮質領域である。
			感覚情報の高度な統合による認知、複数の感覚の総合、感覚と運動の統合、過去の経験（記憶）と関連、随意運動、
			情動行動、言語機能、精神機能、作業記憶（ワーキングメモリー）などである<a href="#rKW">[rKW]</a>。
			個々の感覚・運動機能よりも、それらを統合した部分が、ヒトのヒトたる部分である。そこが、ヒトの特徴である。
			つまり、ヒトはマルチモダルである。
		</p>
	</details>

	<details open><summary><strong>可塑性</strong></summary>
		<p>
			ヒトの遺伝情報であるヒトゲノムは約30億個の塩基で構成される。
			一つの塩基はATGCの4種類の分子のいずれかで2ビットの情報をもつ。
			したがって、ヒトゲノムは2x30憶=60億ビットの情報量を持つ。
			一方、新皮質の神経細胞は100億個で、神経細胞当たりシナプスの結合数を1000個とし、結合係数は抑制と興奮の2値（1ビット）とすると、
			脳の情報量は約10兆ビット（100億X1000=10兆ビット）となる。
			ヒトが生まれる際に受け継いだ情報量よりも、ヒトが成人になって活用する情報量のほうが、1600倍大きいのである。
			つまり、脳の配線の大部分は遺伝ではなく、生後決定される。
			<a href="#rSO">[rSO]</a>
			ヒトは学習する。
		</p>
	</details>

	<details open id=magical_number><summary><strong>記憶の容量</strong></summary>
		<p>
			一度に記憶できるのは、4個までだそうである。
			長期記憶から、あるカテゴリーで想起できるのは、3個までだそうである。
			チンパンジーは、4個の数字までは95%の正確さで覚えられるが、5個で65%まで落ちるそうである。<a href="#rSW"></a>
		</p>
	</details>

	<details open id=cognitive_interference><summary><strong>マルチタスクは事実上、可能だと</strong></summary>

		<p>
			認知資源の干渉という現象がある。
			ヒトは、考えるという言語的・音響的作業と、タイプするという指の機械的・視覚的で空間的な作業を、うまく同時にこなせる。
			それを説明する理論である。
			<a href="#rCW">[rCW]</a>、<a href="#rBD">[rBD]</a>、<a href="#rBS">[rBS]</a>。
			そこでは、経験的に、以下のことなどが主張された。
			<ul>
				<li>(a) 認知のための資源と反応するための資源とは独立である。
					例えば、パイロットは飛行機の込み具合を認識しながら同時に適切な対応をとる。</li>
				<li>(b) 音響的作業と視覚的作業とは、それぞれの作業を複数やるよりは、2種類の作業をより効率的に時分割できる。
					例えば車の運転手は、声で指示を受けて、ハンドル操作ができる。</li>
				<li>(c) 言語的活動と、音響的活動を、同時にこなすことはできない。
					何か文章を考えている（言語的活動）ときに他人とおしゃべり（音響的活動）はできない。
					また、議事録を作成（言語的活動）しながら、議論に参加する（音響的活動）ことはできない。</li>
				<li>(d) 空間的認知過程と、言語的音響的認知過程とは、独立である。
					例えば、ハンドル操作以外の手操作は運転を中断させるが、声で機器操作するのはより楽である。
					耳で捕まえた議論のキーワード（音響的活動）を、記録する（機械的空間的活動）ことができる。</li>
			</ul>
		</p>
		<p>
			心理学の世界で、その後、ヒトが一度にできるのは一つだけである、ということを示された<a href="#rSW">[rSW]</a>。
			(a)は、まだよくわからない。
			(b)が、正しく、ヒトは、素早い切り替え、時分割ができる。
			(c)は、正しい。
			(d)は、正しくない。時分割が、二つの行為を同時に実行できるように見せていたようである。
			自動車の運転をしながら、着信した電話で会話をするのは、実は注意力を散漫にしている。
			音楽を聴きながら、勉強したり、仕事をしているのは、実は、作業効率を下げている。
		</p>

	</details>

</div>

<div class="pagebreak"><hr><h2>6. 言語</h2>

	<details open id=言語の発生><summary><strong>言語発生</strong></summary>
		<p>
			言語の発生については、諸説ある。
			マイケル・コーバリスは、身振り・手振りで表現することが、言語のもとになったと唱えた
			<a href="#rMC">[rMC]</a>。
			身振り・手振り以外に、赤ちゃんでも利用し理解する、表情、まなざし、指さしなども重要なコミュニケーション手段である。
			これらは、空間的な情報伝達手段である。
			ヒトの場合、40万年前ほどのころ、複雑な発生器官を持つにいたり、音声言語を使いだした。
		</p>
		<p>
			その効果は明確である。ヒトは、言語によって、無限の種類の意味を表現し、理解することができるようになった。
			言語は、実在するあるいは抽象的な何かを指示し、構文構造を持って、組み立てる。
			感覚から離れた概念をも表現できることが、ヒトの世界を広げた。
			虚構がヒト社会の本質となった<a href="#rYH">[rYH]。</a>
			構文構造は、再帰的なので、実質、文の種類は無限である。
		</p>
	</details>
</div>

<div class="pagebreak"><hr><h2>7. 文字</h2>

	<details open id=文字の発明><summary><strong>文字の発明と二つのコミュニケーション形態</strong></summary>
		<p>
			およそ5000年前、ヒトは、シュメール文明で文字を発明した<a href="#rCL">[rCL]</a>。
			器用な手指と、それを導く高度な視覚があって、文字を操れるようになった。
			その結果、ヒトは、時間と空間を超えて、言語を通して、様々な情報を伝達できるようになった。
		</p>
		<p>
			それ以来、ヒトのコミュニケーションは、生活圏内の人との会話による日常的なものと、時空を超えた書き物によるものと、2種類のものに分かれた。
			書き物によるコミュニケーションでは、文字を認識するためにもっぱら目を使う。
		</p>
		<p>
			ヒトは、言語に文字という視覚的な要素を合わせた。
			それによって、ヒトは、文字にして外部に記憶を保持することができるようになった。
			紙切れに書いたメモである。
			知識を記録した本である。
			そして、世界中の人に共有されるインターネットである。
		</p>
		<p>
			外部に視覚的に文構造を保持できるため、言語表現も様変わりした。省略がしやすくなった。
			文字の発明の前、ゴータマ・ブッタの弟子が生きた時代、師の教えを受け継ぐには、口伝しか方法がなかった。
			音声表現は、韻を踏んだものだと、覚えやすいという。
			また、教えを伝えるには、言い間違えが起きないように、詳細を何度も繰り返したから、ともいう。
			しかし、文字が利用できるようになると、韻律は関係なくなった。
			また、先に書いたことは省略できるようになった。
			目で、即座に先の文章を確認できるから。
		</p>
	</details>
</div>

<div class="pagebreak"><hr><h2>8. コンピュータ</h2>

<h3>8.1 コンピュータという道具</h3>

	<details open><summary><strong>コンピュータという道具は素晴らしい</strong></summary>
		<p>
			スマホの地図アプリを見てみよう。
			紙の地図と異なり、本屋へ出かけて買ってくる必要はない。
			紙の地図と異なり、スマホをポケットに入れておけば、かさばるものをカバンに入れて持ち歩く必要はない。
			紙の地図と異なり、探したい場所は、ズームインとズームアウトの組み合わせで、一瞬で見つかる。
			メモを付加することができる。
			スマホは、自分がいる場所をGPSで感知しているので、いまここから、目的までの道案内をしてくれる。
			近くのレストランをすぐに探せる。
			近くの道路の混雑具合をすぐに調べられる。
			ヒトは、こんな素晴らしい道具を、だれで手にするようになった。
		</p>
	</detail>

	<details open><summary>コンピュータの概念<strong></strong></summary>
		<p>
			コンピュータという道具を使って行うことは、ハサミのような具体性がない。
			ファイルなど、コンピュータ以降に生み出された抽象概念を扱う、いくつかの抽象的なステップをたどる。
			行う操作は、ハサミのように、結果がすぐに出るのではない。
			さらに、結果は、電子的な変化に過ぎないので、具体的に見えるものでもない。
		</p>
		<p>
			ノイマンは、行為は7段階の手順を踏むと分析した<a href="#rDN">[rDN]</a>。
			「(1) ゴールがまずある。(2) 実行しようという意図が起きる。(3) 行為系列へ展開する。(4)行為系列を実行する。」 => 外界に操作し、結果が返る
			=>「(5) 外界の状態を知覚する。(6) 知覚したものを解釈する。 (7) 解釈を評価する。」 => (1)へ戻る。
		</p>
		<p>
			<div align="center">
				<img width=40% src="seven_steps_of_action.png"> 
				<p><a href="#rDN">[rDN]</a>より</p>
			</div>
		</p>
		<p>
			コンピュータを使う場合、一般に、行為系列へ展開する(3)がコンピュータ寄りで、ヒトの日常の概念より抽象的である。
			また、結果も抽象的なので、(6)の結果の会社の段階も、抽象的である。
			スマホの通知が鳴ったり鳴らなかったり、変えようとするところ、(1)、(2)は明確である。
			鳴ったか鳴らないか、(7)も明確である。
			一方、どうすれば鳴ったり鳴らなかったりを変更できるのかの(3)が、コンピュータの概念を理解していないと難しい。
			また、どういう設定になっていればどうなるかを確認する(6)も、コンピュータの概念を理解していないと難しい。
		</p>		
		<p>
			こういう抽象的な過程を、ヒトの脳の進化の結果の概念体系として、ヒトが慣れていくのかどうかわからない。
			現状、抽象的な過程は、壁として、どんなユーザ・インターフェイスも、苦しむ。
		</p>
	</details>

	<details open><summary><strong>理想的な道具とは？</strong></summary>
		<p>
			ドナルド・ノーマンは、スニーカーのマジックテープを技術の進歩のお手本とした。
			ヒトは、靴の紐を結ぶという習慣に慣れていた。
			マジックテープがでてから、それは一瞬の簡単なことに変わった。
			障がい者、子供も、マジックテープの恩恵を受けた。
			また、自動運転は、別のお手本である。
			車の運転は、手段である。
			目的は、ある場所へ移動することである。
			自動運転は、苦痛なく、目的達成を果たしてくれる。
		</p>
		<p>
			技術は、抵抗なく受け入れられ、かつ、中間でない最終目標を達成できることが、理想である。
			ITでの、コンピュータの概念は、認知負荷を課すので、理想ではない。
			目的達成の中間の手順を、ユーザを強いるので、理想ではない。
		</p>
	</details>

<h3>8.2 グラフィカル・ユーザ・インターフェイス</h3>

	<details open><summary><strong>従来のコンピュータ・ユーザー・インターフェイスは、目と手指だけ</strong></summary>
		<p>
			日常的なコミュニケーションを含め、ヒトはそもそも、いろんな知覚を総合して環境とやり取りをしている。
			一方、現在のコンピュータ・ユーザ・インターフェイスにおいても、情報の入手はもっぱらモニターを目で見ることで行われている。
			それだけ、ヒトは、文明が生まれて以降、目のスーパーな力を享受してきた。
		</p>
		<p>
			他方、現在のコンピュータ・ユーザ・インターフェイスでは、情報の生産は、ほぼ手で行っている。
			それだけ、ヒトは、文明が生まれて以降、器用な手の力を享受してきた。
			テキスト生産だけではない。コンピュータに指示（コマンド）するときも、指を使う。
			位置指定・対象選択も、指で行う。
			手を使う限り、手指は機械的動作で効果を生み出すので、機械動作の性質とスピードに制限される。
			例えば、対象を選択する際、現在のマウスの位置から、遠くの対象へマウスカーソルを移動させようとすると、
			そのための動作の時間は、その距離に比例し、対象の大きさに反比例する。これをフィッツの法則という。
		</p>
		<p>
			手指にそのような制限があるにもかかわらず、なぜ、現在、目と手が主役なのか？
			手は器用である。目と親和性が高い。文字を発明して以降、手で作成し、目で消費する、ということに慣れてきた。
			そのためコンピュータの時代でも、その延長上にいる。
		</p>
		<p>
			そもそも<a href="#association_area">ヒトは総合する動物</a>で見たように、ヒトは感覚や運動を特定の部分に頼って生活してはおらず、
			総合して環境に対処している。コンピュータに対して、なぜそれができないか? 
		</p>
	</details>

	<details open><summary><strong>グラフィカル・ユーザ・インターフェイス</strong></summary>
		<p>
			目と手で道具を扱うという古来の伝統の延長で、コンピュータも発達した。
			今のユーザ・インターフェイスは、グラフィカル・ユーザ・インターフェイスと言われる。
			それを指で操作し、目で結果を得て、ヒトはコンピュータを利用する。
		</p>
		<p>
			コンピュータのユーザ・インターフェイスをデザインするは、水道の蛇口やドアのノブのデザインとは、異なる。
			それらは、効果が目に見える。
			しかし、コンピュータは計算という目に見えない抽象的なレベルで結果を出す。
			それを、操作をしたヒトに、理解できるように提示しなければならない。
			アートである。
		</p>
		<p>
			ノイマンによると、日常生活の道具は、物理的な制約、論理的な制約、社会・文化的な制約、意味的な制約などによって、
			操作できることが絞り込まれていると。
			物理的な製薬とは、例えば、あるプラグはその形状にあったコンセントにしか差し込めない。
			大きな突起は小さな穴に差し込めない。鍵は鍵穴に上下逆さに入れると回らない、などである。
			社会的文化的な制約とは、ネジは時計回りに回すと締り、逆回しにすると緩む。
			車の右側のサイドランプを点灯すると右へ曲がると言う印になる。
			時計の1時と2時の間の時間は、2時と3時の間の時間と同じ長さである、などである。 
			論理的な制約とは、棒を右に倒せば対面した相手からは左に倒すことになる。
			電灯は点灯しているか消灯しているかのいずれかである、などである。
			意味的な制約とは、りんごは歩かない。 オートバイに乗る時に前方は決まっている、などである。
			一方で、コンピュータのユーザ・インターフェイスは、意味的・論理的な制約くらいしか、利用できない。
			抽象的な世界（コンピューターを作っている人の頭の世界コマンド用語）の中で、
			必ずしもコンピュータを理解していないユーザ向けにデザインしなければならないとき、利用できる制約が少ない。
			非常に難しい領域である。
		</p>
		<p>
			現在、グラフィカル・ユーザ・インターフェイスが主流である。
			メジャーな企業は、デザインガイドを公開し、標準的な提示の仕方を開発者に教育した。
		</p>
		<p>
			グラフィカル・ユーザ・インターフェイスの操作は、マウスやタッチで行う。
			マウスは、動かすとカーソルが動き、操作と結果の対応が明確である。
			マウスかーするを対象の上でクリックすると、対象が選択され、それも操作と結果が明確である。
			タッチは、手が届く範囲内ならば、カーソルを動かすという手間がなく、対象選択が素早くできる。
		</p>
		<p>
			一方、グラフィカル・ユーザ・インターフェイスの表示は、メニューとともにアイコンを多用する。
			アイコンは、視覚的な象徴である。
			それは、<a href="visual_symbol">象徴を認識できる</a>でみたように、視覚的な象徴は間接的である。
			水道の蛇口やドアのノブにはあった、何ができるかを示す支持機能が、弱い。
			グラフィカル・ユーザ・インターフェイスでは、そういうアイコンを対象として操作する。
			当初は、デスクトップ・メタファーと言って、デスクにあるペン、文書、ファイルキャビネットなどを図示するという発想があった。
			しかし、機能が拡大するにつれ、物理的なものを象徴するだけではない、抽象的・間接的な表現となった。
			現在のスマホのホーム画面のアイコンのラベルがもしもなかったとしましょう。
			使えるだろうか？ アプリのアイコンは、ラベルで説明を追加していなければ、利用しにくい。
			アフォーダンス(支持)がずぶずぶである。
			対象は抽象的である。
			操作の結果も、電子的な変化なので、目に見えにくい。
			操作とその結果の対応付けが分かりにくい。
			グラフィカル・ユーザ・インターフェイスは、こういった基本的な問題を持つ。
			Windows PCのスタートボタン、スマホのいわゆるLauncherのところは、この問題を持っている。
		</p>
		<p>
			うまアプリを起動できたとする。
			内部の機能を見てみよう。
			電話アプリ、スプレッドシート、地図アプリ、ワードプロセッサ、電卓アプリなど、対象が豊かで明確な意味を備えている。
			そういうアプリは、できることもわかりやすい。
			やったことが目に見えて返ってくる。
			ショートメッセージ、ニュースアプリなど、ユーザの意図が明確で単純なアプリも、わかりやすい。
			例えば、高齢者が初めてスマホを使い始めた時、他に何もできなくても、電話アプリは使える。
			昔の黒電話、ガラケーの電話アプリ、で、概念モデルがしっかりとあるからである。
			数字パッドを打つと、ツーツーと音が鳴り、相手が出る、ないし「つながりませんでしたでした」とくる。
			操作も知っているし、結果もすぐに出て、明確である。
			しかし、そういう利点を持たないアプリ、提供機能自体がほぼ抽象的なものも多い。
			それらは、コンピュータ用語でしか説明できない。
			コンピュータ用語が忍び込んでしまうこともある。
			例えば、スプレッドシートで、ユーザがやりたいのは表計算である。
			そのファイルを上書き保存や、名前を付けて保存というのは、なにか？
			表は、後で取り出せさえすれば、ユーザにとってはどうでもいいことである。
			ファイル・フォルダー体系というコンピュータの概念を、ユーザに押し付けている。
			さらに、機能が抽象的な場合、その結果も抽象的である。
			抽象的なことと抽象的なことの対応関係は、なおさら抽象的である。
		</p>
		<p>
			<a href="#magical_number">記憶できる個数</a>でみたように、3個か4個までであれば、認知負荷が小さい。
			メニューは、機能が多いときに詰め込む、いい掃きだめになっている。
			メニューの項目が、PCの一画面の底まで並んでいることは珍しくない。
			しかも、メニューの用語は、多くの場合、コンピュータエンジニアの用語である。
			また、コンピュータ内部用語である。
			あるいは、ユーザがめったに使わない機能である。
			あるいは、ユーザがやりたいこと以上に、ユーザに見つけてほしい広告的なメニュー項目が多い。
			メニュー、つまりあるアプリでできることに関して、IT業界は整理することに失敗している。
		</p>
		<p>
			しかも、メニューは、簡単に項目数が増える。
			メニューは、別メニューを項目として持つこともある。
			こうして、ヒトがやりたいことを実行するのに、広くて深い探索空間を相手にすることになる。
			理想は、狭くて浅い選択肢のみであってほしいのに。
		</p>
		<p>
			また、グラフィカル・ユーザ・インターフェイスも、ヒトの概念的な構築物である。
			時間を経て発展するうちにどんどん複雑になる。
			スマホが登場したとき、当然、グラフィカル・ユーザ・インターフェイスが応用された。
			広い画面のユーザーインターフェイスが、小さい画面のものへと変化し、マウスはタッチという直接操作へ変わった。
			しかし、グラフィカルユーザーインターフェイスをもとに、その進化を重ねたため、複雑さはそのまま、ないし、より増した。
			対応関係が複雑怪奇となった。
			地図アプリを開き、スクロールしたり、つまんで広範囲を表示したり、など、ユーザのジェスチャー操作と操作対象の反応が
			直感的に対応している場合は、いい。
			が、そういう直感的な対応ができることばかりではない。
			一つの操作で、複数の意味がある。
			例えば、タップは、アプリの選択＋起動であり、項目のタップは選択＋メニューの起動でもあり、
			入力フィールドの選択でもあり、などなど。
			一つの意味なのに、その操作は複数ある。
			例えば、スマホでアプリを削除するのはアプリアイコンを長押ししてから行う。
			しかし、写真ギャラリーで写真を削除するには、タップして行う。
			ドナルド・ノーマンの言う、機能の数がスイッチの数を超えている状態である。
			慣れない人が慣れるのは至難である。
		</p>

	</details>
	
	<p><font color="red">
		ヒトは三次元に住んでいる。コンピュータは、紙と同じく、モニターという二次元の表示装置に頼っている。なぜ三次元のインタラクションがないのか？ 
		実世界の3次元は2次元というモニターに押し込められている。 
	</font></p>

	<h3>8.3 音声によるユーザ・インターフェイス</h3>

	<details open><summary><strong>音声を使ったコンピュータ操作は視覚にも頼らざるを得ない</strong></summary>
		<p>
			音声による言語表現は、指によるコントロール・空間指示と、視覚による構造把握と、併用しなければ、応用は広がらない。
		</p>
		<p>
			スマートスピーカーが出て、音声だけでやり取りするアプリが試されている。
			スマホの音声アシスタントもある。
			いずれも、当初音声のみのユーザーインターフェイスを目指していた。
			その後、画像情報も援用するようになってきた。
			そもそも、ヒトが環境に対するとき、複数の感覚と効果器を総合して、機能する。
			その意味で、音声のみのユーザーインターフェイスは不自然である。
		</p>
		<p>
			無理に音声のみのやり取りでアプリを組もうとしても、以下の欠点が出る。
			<ul>
				<li>モードの制御がやりにくい。</li>
				<li>音声のみでは、そもそも空間内の位置指定ができない。</li>
				<li>ボリューム調整など、アナログ量の制御が苦手である。</li>
				<li>構造的な情報を扱うのが困難。</li>
			</ul>
		<p>
			音声のみだと、音声をコンピュータに聞かせている状態なのかそうでないのかの区別ができない。
			また、コマンドなのかテキストなのかの区別ができない。
			そういった区別状態のことをを、IT用語ではモードという。
			音声のみでは、モードの制御がやりにくい。
			「OK Google」とか、「Hey Siri」とか言って、音声をコンピュータに聞き取らせるのを始めるが、不格好である。
			聞き取ったことに対し、音声で返ししか手段がないとすると、アプリもつ作りにくい。
			音声をコンピュータに聞き取らせるのは、マイクの絵をたたいて始めるほうが自然である。
			またコンピュータが聞き取ったよというフィードバックも、視覚的な反応もあったほうが、アプリは組みやすい。
		</p>
		<p>
			ヒトは、指差しや、マウスやで、空間の位置指定を容易に行うことができる。
			しかし、それを音声でやるとなると、あいまいな指示か、相当冗長な指示しか表現できない。
			指つまみで簡単に指定できるボリューム量も、同じである。
		</p>
		<p>
			構造的な情報を扱うのも音声＋聴覚は苦手である。例えば、フライトを予約したい。
			日時を指定する、人数を指定する。出発場所と到着場所を指定する。
			その上で、値段込みの選択オプションを検索したい。
			それら関連した情報をコンピュータに指定する過程で、ある時点までに何の指定を済ませたか、何がまだなのか、
			を意識していないと、情報の支持がやりにくいであろう。
			すでに指定したものは、画面上で、目に見えておいてほしい。
			また、検索結果が聴覚のみでは、把握できず、洗濯もできない。
			2、3個以上の選択肢がある場合、視覚的な補助なしに選択を行うことは困難である。
		</p>
		<p>
			例えば、音声による言語表現では、コンピュータのほうに、キーボードのような選択・修正UIが完備されていない。
			そのため、人名入力や地名入力など同音語が多く、表記を選ぶ必要があるケースでは、コンピュータが対応するのは難しい。
			ある音で検索したある同じ姓名漢字を、いつも返すしかすべがない。
		</p>
	</details>

	<details open><summary><strong>音声言語は意図を直観的に表現する</strong></summary>
		<p>
			音声言語は日常生活空間で使われるため、意図を自然に表現できる。
			あいまいな部分は、話す相手や周囲の状況などのコンテキストで、実は明確である。
			ヒトの意図は、周りのコンテキストがあれば、言語音声に自然に表現されている。
			コンピュータは、それを利用すべきだ。
			ユーザは、グラフィカル・ユーザ・インターフェイスで、やりたいことを満たすアプリを選ぶのは、視覚的象徴経由である。
			間接的で、意図を伝達するにしては、最適ではない。
			絵を見て、何を意味するのか想起して、アプリの機能を認知する。
			そういう複雑な認知過程が必要となる。
			一方、音声だと、意図を、日常語彙で、直接、表現できる。
			音声で意図を伝え、それに加えて質問などによる制約を利用して、意図解釈をするとよい。
			音声ならば、意図がすでに包含されているので、ユーザインターフェイスの支持（アフォーダンス）の設計というのが不要である。
			音声認識で糸を表現し、コンピュータがそれを解釈すれば、ノイマンの行為7段階説で行為系列への展開という部分が
			なくせる。
		</p>
	</details>

	<details open><summary><strong>音声アプリも、支持と制約を利用すべきである</strong></summary>
		<p>
			ドナルド・ノーマンによれば<a href="rDN">[rDN]</a>、
			日常的な道具は、アフォーダンス、制約、概念モデルを利用しているという。
			例えば、はさみの穴は指を入れる場所を示し、指を入れることを支持（アフォード)
			穴の大きさは、1本指を入れるという制約を課している。
			ハサミの機能は、二つの刃が交わって紙などを切るという仕組みが目に見えているため、
			何をする道具なのかヒトにとっては容易に理解できる。
			アフォーダンスは何ができるかを示し、制約は選択肢を制限する。
			アフォーダンスと制約があるために、生活の中に無数に道具があって使い方を丁寧に教わらなくても、ヒトは使える。
		<p>
			コンピュータのグラフィック・ユーザ・インターフェイスでは、見えているものが、手での操作の支持であり制約となる。
			キーを下に押し下げること自体は、何のための動作か曖昧である。
			しかし、Aと刻印されたキーを押し下げることは、Aの言語表現として、曖昧性がない。
			これは、ドナルド・ノーマンの言う外界の知識<a href="rDN">[rDN]</a>を利用している。
			また、グラフィック・ユーザ・インターフェイスでは、メニューや画面遷移というコンテキストがあるために、ある対象のクリックには、曖昧性がない。
			そのように、視覚情報やコンテキストによって制約されて、手指動作の曖昧性がなくなる。
			そのような曖昧でない動作を前提に、アプリが編み上げられる。
			アプリが組みやすいのである。
		</p>
		<p>
			音声による言語表現は、手と同様に、視覚やコンテキストによる支持と制約を利用して曖昧性をなくし、アプリの構成要素にできる。
			音響系と空間視覚系とは、効果的に時分割できることを、利用すればよい。	
		</p>
	</details>

	<details open><summary><strong>文書作成に音声言語表現は使えるか？</strong></summary>
		
		<p>
			「<a href="#cognitive_interference">マルチタスクは事実上不可能</a>」のところで見たように、
			ヒトは、考えながらしゃべるのは難しい。しかし、一瞬考えて、それをしゃべる、それを繰り返す、という時分割なら、うまくできる。
		</p>
		<p>
			音声言語表現は、文書作成の時間を短くしない。しかし、アイデアを素早く完全な形で記録する。
			そして、たとえご認識でノイズが多くても、文であるため、後で編集するときに、想起しやすい。
			それで、音声でスケッチした後での文書作成はやりやすい。
			音声言語表現は、頭の中にある整理されていないモヤモヤした概念を、忘れないうちに、目に見える形で取り出して、
			編集可能な形にし、考えを発展させられるようにするための手段である<a href="#rNY">[rNY]</a>。
		</p>
		<p>
			本を読んでいるときに、触発されて思いついたことを、音声でメモする。
			フルな文章で記録する。
			本に、指で、そのキーワードを書き込むよりは、後で、想起しやすい。
		</p>
		<p>
			音声を一度視覚的なテキストとして保存してしまえば、それは外部の記憶となる。
		</p>
	</details>

	<h3>8.4 脳・人・インターフェイス</h3>

	<details open><summary><strong>BMIは夢のインターフェイスか？</strong></summary>
		<p>
			ヒトの脳・神経は、環境とのやり取りで、生物として、受容・効果器官との協同作業のために進化した。そのしくみは、未知なことが多い。
			一方、脳に直接機械・道具を接続することで、道具を自在に操ることが、昔から夢見られてきた。
			脳・神経系と受容・効果器官を一体のものとして、ブラックボックスでもいいので、それ、つまりヒトの身体と協調する道具というものを追求すべきだ。
			BMIという近道を探るよりは。
		</p>
	</details>
</div>

	<p><font color="red">？？？生体機能の加齢による影響？？？？？？シニアスマホデザインガイドの導出？？？</font></p>

	<p><font color="red">見えないコンピューター。 ドリルを買う人はドリルが欲しいのではなく穴が欲しい。
		PC が欲しいのは PC が欲しいのではなく PC でできるきれいな文章作成できるから。 
		またスプレッドシートにパスワードをメモして保存しておけるから。
		スマホが欲しいのはいつでもどこでも情報を検索できるから。 
		スケジュールをいつでも変更したり参照したりできるから。
	</font></p>

</div> <!--End of TOC areas-->

<div class="pagebreak"></div><hr>
<h2>参考文献</h2>
<details open><summary>出典</summary>
<ul>
<li id=rBD>[rBD] Multimodal Interfaces: A Survey of Principles, Models and Frameworks、Bruno Dumas, Denis Lalanne, Sharon Ovian、2009. </li>
<li id=rBS>[rBS] The Limits of Speech Recognition. s.l. : Communication of ACM、Shneiderman, Ben、2000.</li>
<li id=rCL>[rCL] 「137億年の物語」（What On Earth Happendd?)、クリストファー・ロイド（Christopher Lloyd)
<li id=rCW>[rCW] Multiple resources and performance prediction、Wickens, Cristopher D、 2002</li>
<li id=rDN>[rDN] 「誰のためのデザイン？」（The Psychlogy of Everyday Things）、D.A.ノーマン、新曜社認知科学選書,1988</li>
<li id=rFJ>[rFJ] http://fujiidental.jp/clinic/archives/18 </li>
<li id=rFT>[rFT] 「生体情報システム論」、福田忠彦、1995、産業図書、ISBN978-4-7828-5303-0C335</li>
<li id=rHK>[rHK] 「視覚と聴覚はどうちがうか」、樋渡涓二（ひわたり　けんじ）、1997、NHK 第31巻第11号</li>
<li id=rHN>[rHN] 廣野守俊 永雄総一 小脳 脳科学辞典　https://bsd.neuroinf.jp/wiki/%E5%B0%8F%E8%84%B3 (2021)</li>
<li id=rIN>[rIN] 「図解・感覚器の進化 原始動物からヒトへ水中から陸上へ」、岩堀修明（いわほり・のぶはる）著、2011、講談社、ISBN978-4-06-257712-0</li>
<li id=rKH>[rKH] 『「視覚は人間の情報入力の８０％」説の来し方と行方』、加藤宏、筑波技術大学テクノレポート Vol.25 (1) Dec. 2017</li>
<li id=rKH2>[rKH2] 「霊長類の音声の運動基盤及び多様性とその進化的な背景」、香田啓貴（こだ　ひろき）、日本音響学会誌71巻7号、2015
<li id=KH3> [rKH3] サルの発声から見るヒトの言語の起源、香田啓貴 https://www.brh.co.jp/publication/journal/102/rp/research01/ </li>	
<li id=rKK>[rKK] Eye Tracking in Human-Computer Interaction and Usability Research; Ready to Deliver the Promises、Karn, J. K. Jacob and Keith S.、2003</li>
<li id=rKW>[rKW] 蔵田潔、渡辺雅彦 大脳皮質 脳科学辞典 https://bsd.neuroinf.jp/wiki/%E5%A4%A7%E8%84%B3%E7%9A%AE%E8%B3%AA (2021)</li>
<li id=rMA>[rMA] 「脳の神経細胞の数」、三上章允（みかみ あきちか）、http://web2.chubu-gu.ac.jp/web_labo/mikami/brain/10/index-10.html</li>
<li id=rMC>{rMC] https://www.ted.com/talks/michael_corballis_evolution_s_great_mystery_language/transcript?language=ja</li>
<li id=rMK>[rMK] 『ヒトとは視覚を発達させ、嗅覚を退化させた「か弱きサル」である』、三谷宏治（みたに こうじ）、https://www.careerinq.com/blog/mitani/2015/05/post-6.shtml</li>
<li id=rMS>[rMS] 「皮膚感覚の情報処理」、下条誠、計測と制御、第４１巻、第１０号、２００２年１０月。
<li id=rNT>[rNT] 「霊長類の音声器官の比較発達ー言葉の系統発生」、西村剛(（にしむら　たけし）, The Japanese Journal of Animal Psychology, 60, 1 49-58 (2010)</li>
<li id=rNY>[rNY] 野口悠紀雄『「超」書く技術』(プレジデント社)</li>
<li id=rPN>[rPN] 「生命とは何か？」、ポール・ナース、ダイヤモンド社、ISBN978-4-478-11107-9 C0045</li> 
<li id=rSO>[rSO] 「生体情報処理」、杉江昇、大西昇、昭晃堂、2001年、ISBN4-7856-9060-7</li>
<li id=rST>[rST] 橘木 修志 視細胞 脳科学辞典　https://bsd.neuroinf.jp/wiki/%E8%A6%96%E7%B4%B0%E8%83%9E (2019)</li>
<li id=rSW>[rSW] 「インターフェイスデザインの心理学」(100 Things Every Designer Needs to KNow ABout People)、スーザン・ワインチェンク(Suzan Weinschenk)、O’REILLY、ISBN978-4-87311-557-3</li>
<li id=rTK>[rTK] 「嗅覚の匂い受容メカニズム」、東原和成（とうはら かずしげ）、2015</li>
<li id=rYH>[rYH] 「サピエンス全史」、ユヴァル・ノア・ハラリ、2016</li>
<li id=rYH2>[rYH2] 「指の機能」、米満弘之、1973、精密機械、40巻1号、https://www.jstage.jst.go.jp/article/jjspe1933/40/468/40_468_18/_pdf</li>
<li id=rUT>[rUT] 上村朋子 空間記憶 脳科学辞典 https://bsd.neuroinf.jp/wiki/%E7%A9%BA%E9%96%93%E8%A8%98%E6%86%B6 (2018)</li>
<li id=rVB>[rVB] 「ヒトの脳 : 解剖学的構造と機能」、https://www.visiblebody.com/ja/learn/nervous/brain</li>
</li>
</ul>
</details>

<!--https://shu-sait.com/mokuji-jidou-seisei/-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="toc.js"></script>
<script>
    $(function () {
        $(".toc-contents").toc({
			startLevel: 'h2',
		});
    });
</script>

</body>
</html>